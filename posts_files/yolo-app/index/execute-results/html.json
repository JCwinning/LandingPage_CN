{
  "hash": "efda1f0b2cb7bdf1e4d8847c895ca6c2",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"使用 Streamlit 构建的 YOLO 目标检测应用\"\nauthor: \"Tony D\"\ndate: \"2025-11-05\"\ncategories: [AI, API, tutorial]\nimage: \"images/0.png\"\n\nformat:\n  html:\n    code-fold: true\n    code-tools: true\n    code-copy: true\n    \nexecute:\n  eval: false\n  warning: false\n  \n  \n---\n\n\n# 项目概览\n\n该应用是一个全面的 Streamlit Web 应用程序，利用 YOLO11（Ultralytics 框架）提供目标检测功能，支持多种输入源和处理后端。该项目的特别之处在于其多模型架构和生产级别的特性。\n\n\n在线演示: [https://yolo-live.streamlit.app/](https://yolo-live.streamlit.app/)\n\nGithub: [https://github.com/JCwinning/YOLO_app](https://github.com/JCwinning/YOLO_app)\n\n\n::: {.panel-tabset}\n\n## 目标检测\n\n![应用程序截图 - 主界面](images/0.png){width=\"100%\"}\n\n## 物体识别\n\n![应用程序截图 - 检测结果](images/1.png){width=\"100%\"}\n:::\n\n\n## 核心特性\n\n### 多输入支持\n应用支持多种输入方式：\n- **文件上传**：从本地存储上传图像和视频。\n- **URL 输入**：直接从网络输入图像 URL。\n- **实时相机**：使用设备相机进行实时照片捕获。\n\n### 多模型架构\n其最突出的特性之一是支持不同的 AI 模型：\n\n#### 1. 本地 YOLO11 模型\n- 五种不同的模型变体（nano, small, medium, large, extra-large）。\n- 自动设备检测，支持 Apple Silicon 的 MPS 加速。\n- 在不支持加速的情况下自动回退至 CPU，确保更广的兼容性。\n\n#### 2. 云端模型\n- 通过 DashScope API 调用 **Qwen-Image-Edit** 进行高级图像标注。\n- 通过 OpenRouter API 调用 **Gemini 2.5 Flash Image** 进行前沿的图像处理。\n\n### 高级功能\n- **双语界面**：完整的英文/中文支持，包含 113+ 个翻译字段。\n- **智能 UI 管理**：处理后自动隐藏输入图像。\n- **下载功能**：支持将标注后的结果保存到本地。\n- **进度追踪**：视频处理过程中的实时进度更新。\n- **会话管理**：在用户交互过程中保持持久化状态。\n\n## 技术架构\n\n```{mermaid}\n%%| fig-cap: \"系统架构图\"\nflowchart LR\n    A[用户界面<br/>Streamlit] --> B[输入源]\n\n    B --> C[文件上传]\n    B --> D[图像 URL]\n    B --> E[实时相机]\n\n    A --> F[处理模型]\n\n    F --> G[本地 YOLO11<br/>n/s/m/l/x]\n    F --> H[Qwen-Image-Edit<br/>DashScope API]\n    F --> I[Gemini 2.5 Flash<br/>OpenRouter API]\n\n    G --> J[设备检测<br/>MPS/CPU]\n\n    J --> K[结果<br/>标注后的图像/视频]\n    H --> K\n    I --> K\n\n    A --> L[功能特性]\n    L --> M[双语 UI<br/>EN/ZH]\n    L --> N[下载结果]\n    L --> O[会话管理]\n```\n\n### 核心依赖\n\n```toml\n[project]\nname = \"yolo-app\"\nrequires-python = \">=3.12\"\ndependencies = [\n    \"dashscope>=1.17.0\",      # 阿里云 API\n    \"opencv-python>=4.11.0.86\", # 计算机视觉\n    \"streamlit>=1.50.0\",       # Web 框架\n    \"torch>=2.2\",              # 深度学习\n    \"ultralytics>=8.3.0\",      # YOLO 框架\n]\n```\n\n### 应用程序结构\n\n主应用程序 (`app.py`) 由 1,000 多行结构良好的 Python 代码组成，主要分为以下几个组件：\n\n#### 1. 国际化系统\n\n::: {#e9a018b1 .cell execution_count=1}\n``` {.python .cell-code}\nfrom language import translations\n\ndef get_translation(key, **kwargs):\n    \"\"\"使用当前会话语言的翻译函数\"\"\"\n    lang = st.session_state.get(\"language\", \"en\")\n    text = translations[lang].get(key, translations[\"en\"].get(key, key))\n    return text.format(**kwargs) if kwargs else text\n```\n:::\n\n\n#### 2. 设备优化\n\n::: {#0fc36c3e .cell execution_count=2}\n``` {.python .cell-code}\ndef get_device():\n    \"\"\"自动检测最佳可用设备\"\"\"\n    if torch.backends.mps.is_available():\n        return \"mps\"  # Apple Silicon GPU 加速\n    return \"cpu\"      # 回退至 CPU\n \n# 模型加载与设备优化\ndevice = get_device()\nmodel = YOLO(selected_model).to(device)\nst.info(f\"Using device: {device.upper()}\")\n```\n:::\n\n\n#### 3. 图像处理流水线\n\n::: {#cbbc6a43 .cell execution_count=3}\n``` {.python .cell-code}\ndef encode_image_to_base64(image):\n    \"\"\"将 PIL 图像编码为 base64 字符串并进行尺寸压缩\"\"\"\n    max_size_bytes = 8 * 1024 * 1024  # 8MB 限制\n\n    formats_and_qualities = [\n        (\"JPEG\", 95), (\"JPEG\", 85), (\"JPEG\", 75),\n        (\"WEBP\", 95), (\"WEBP\", 85), (\"WEBP\", 75),\n    ]\n\n    for fmt, quality in formats_and_qualities:\n        # 尝试不同的压缩策略\n        # ... 压缩逻辑\n```\n:::\n\n\n### 多模型处理\n\n#### 本地 YOLO 处理\n应用支持所有 YOLO11 模型变体，并具备自动性能优化：\n\n::: {#0288c7d6 .cell execution_count=4}\n``` {.python .cell-code}\n# 模型选择界面\nmodel_options = [\"yolo11n.pt\", \"yolo11s.pt\", \"yolo11m.pt\", \"yolo11l.pt\", \"yolo11x.pt\"]\nmodel_descriptions = {\n    \"yolo11n.pt\": \"Nano - 最快，精度最低\",\n    \"yolo11s.pt\": \"Small - 均衡性好\",\n    \"yolo11m.pt\": \"Medium - 推荐使用\",\n    \"yolo11l.pt\": \"Large - 精度较高\",\n    \"yolo11x.pt\": \"Extra Large - 精度最高\"\n}\n\nselected_model = st.sidebar.selectbox(\n    get_translation(\"model_selection\"),\n    model_options,\n    index=model_options.index(\"yolo11s.pt\"),\n    format_func=lambda x: f\"{model_descriptions[x]} ({x})\"\n)\n\n# 带进度追踪的检测过程\ndef detect_objects(image, model, confidence_threshold=0.5):\n    \"\"\"执行带进度追踪的目标检测\"\"\"\n    with st.spinner(get_translation(\"processing\")):\n        results = model.predict(image, conf=confidence_threshold)\n\n        # 处理结果\n        detections = []\n        for result in results:\n            boxes = result.boxes\n            for box in boxes:\n                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n                conf = box.conf[0].cpu().numpy()\n                cls = int(box.cls[0].cpu().numpy())\n                class_name = model.names[cls]\n\n                detections.append({\n                    'class': class_name,\n                    'confidence': conf,\n                    'bbox': [x1, y1, x2, y2]\n                })\n\n    return detections, results\n```\n:::\n\n\n#### 云端 API 集成\n对于云端模型，应用负责 API 身份验证和请求格式化：\n\n::: {#3217db15 .cell execution_count=5}\n``` {.python .cell-code}\ndef process_with_qwen(image, api_key):\n    \"\"\"使用阿里云 DashScope 提供的 Qwen-Image-Edit 处理图像\"\"\"\n    try:\n        response = MultiModalConversation.call(\n            model='qwen-image-edit',\n            input=[\n                {\n                    'role': 'user',\n                    'content': [\n                        {'image': f\"data:image/jpeg;base64,{image_b64}\"},\n                        {'text': 'Please identify and label all objects in this image.'}\n                    ]\n                }\n            ]\n        )\n        return response\n    except Exception as e:\n        st.error(f\"API Error: {str(e)}\")\n        return None\n```\n:::\n\n\n## 用户界面设计\n\n### 布局结构\n应用程序采用专业的三个分栏布局：\n\n1. **侧边栏**：模型选择、置信度阈值、语言设置。\n2. **主区域**：输入方式选择、图像/视频显示、结果展示。\n3. **结果面板**：检测统计、下载选项。\n\n### 双语支持\n翻译系统管理所有的 UI 元素：\n\n::: {#34a243be .cell execution_count=6}\n``` {.python .cell-code}\ntranslations = {\n    \"en\": {\n        \"title\": \"YOLO11 Object Detection\",\n        \"upload_file\": \"Upload File\",\n        \"camera_input\": \"Use Camera\",\n        # ... 更多字段\n    },\n    \"zh\": {\n        \"title\": \"YOLO11 目标检测\",\n        \"upload_file\": \"上传文件\",\n        \"camera_input\": \"使用相机\",\n        # ... 对应的中文翻译\n    }\n}\n```\n:::\n\n\n## 性能优化\n\n### 模型性能对比\n\n| 模型 | 参数量 | mAP | 推理时间 (CPU) | 推理时间 (MPS) |\n|-------|------------|-----|---------------------|---------------------|\n| YOLO11n | 2.6M | 37.2 | 15ms | 3ms |\n| YOLO11s | 9.4M | 45.5 | 28ms | 6ms |\n| YOLO11m | 25.4M | 51.2 | 52ms | 12ms |\n| YOLO11l | 43.7M | 53.4 | 84ms | 18ms |\n| YOLO11x | 68.2M | 54.7 | 126ms | 26ms |\n\n### Apple Silicon 加速\n该应用会自动检测并在 Apple Silicon 设备上利用 Metal Performance Shaders (MPS)：\n\n::: {#99a3bce5 .cell execution_count=7}\n``` {.python .cell-code}\ndevice = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\nmodel = YOLO(selected_model).to(device)\n\n# 性能监控\nimport time\nstart_time = time.time()\nresults = model.predict(image)\ninference_time = (time.time() - start_time) * 1000\n\nst.metric(f\"推理时间 ({device.upper()})\", f\"{inference_time:.1f}ms\")\n```\n:::\n\n\n### 云端 API 的图像压缩\n为了满足 API 的大小限制，应用实现了智能图像压缩：\n\n::: {#1df2e271 .cell execution_count=8}\n``` {.python .cell-code}\ndef compress_image_for_api(image, max_size=8*1024*1024):\n    \"\"\"压缩图像以满足 API 要求\"\"\"\n    for quality in [95, 85, 75, 65]:\n        for fmt in [\"JPEG\", \"WEBP\"]:\n            buffer = BytesIO()\n            image.save(buffer, format=fmt, quality=quality)\n            if buffer.tell() <= max_size:\n                return buffer.getvalue()\n    return None\n```\n:::\n\n\n## 部署与生产特性\n\n### 会话管理\n应用程序维护着全面的会话状态：\n\n::: {#e939fe1f .cell execution_count=9}\n``` {.python .cell-code}\nsession_state_vars = [\n    \"current_image\", \"uploaded_image_bytes\",\n    \"current_video\", \"uploaded_video_bytes\",\n    \"camera_active\", \"camera_frame\",\n    \"qwen_processed\", \"gemini_processed\",\n    \"language\", \"input_method_index\"\n]\n```\n:::\n\n\n### 错误处理\n健壮的错误处理确保了优雅的降级服务：\n\n::: {#d8a1421f .cell execution_count=10}\n``` {.python .cell-code}\ntry:\n    result = model.predict(image, conf=confidence_threshold)\n    st.success(get_translation(\"detection_success\"))\nexcept Exception as e:\n    st.error(f\"检测失败: {str(e)}\")\n    # 回退至备选处理方法\n```\n:::\n\n\n## 快速开始\n\n### 前提条件\n- Python 3.12 或更高版本\n- 现代包管理器（推荐使用 uv）\n- 对于云端模型：需要 DashScope 和 OpenRouter 的 API 密钥\n\n### 安装步骤\n```bash\n# 克隆仓库\ngit clone <repository-url>\ncd YOLO_app\n\n# 使用 uv 同步依赖（推荐）\nuv sync\n\n# 备选：使用 pip 安装\npip install -r requirements.txt\n\n# 运行应用\nstreamlit run app.py\n```\n\n### API 配置\n创建一个包含 API 密钥的 `.env` 文件：\n```bash\n# 阿里云 DashScope API\nDASHSCOPE_API_KEY=您的密钥\n\n# OpenRouter API (用于 Gemini)\nOPENROUTER_API_KEY=您的密钥\n```\n\n### 快速使用示例\n\n#### 基础图像检测\n1. 启动应用程序。\n2. 上传图像或提供图像 URL。\n3. 选择您偏好的 YOLO11 模型（推荐使用 yolo11s.pt）。\n4. 根据需要调整置信度阈值。\n5. 点击“开始检测”。\n6. 查看结果并下载标注后的图像。\n\n#### 实时相机检测\n1. 选择“使用相机”输入方式。\n2. 在提示时授予相机权限。\n3. 拍摄照片。\n4. 选择检测模型。\n5. 获取即时的目标检测结果。\n\n#### 云端模型处理\n1. 在侧边栏输入您的 API 密钥。\n2. 上传图像。\n3. 选择 \"Qwen-Image-Edit\" 或 \"Gemini 2.5 Flash\" 模型。\n4. 利用先进的 AI 能力处理图像。\n5. 将结果与本地 YOLO 模型进行对比。\n\n## 未来增强方向\n\n未来版本的潜在改进点：\n\n1. **更多模型**：集成更多的云端 AI 服务。\n2. **实时视频处理**：增强视频流处理能力。\n3. **自定义模型训练**：允许用户训练自定义 YOLO 模型。\n4. **移动端优化**：为移动设备支持提供 PWA 特性。\n5. **批量处理**：同时处理多张图像。\n\n## 结论\n\n这款 YOLO 目标检测应用展示了如何构建一个复杂的、生产级别的计算机视觉系统。本地和云端模型的结合、双语支持以及全面的错误处理，使其不仅适用于开发环境，也适用于生产环境。\n\n该项目展示了以下方面的最佳实践：\n- 使用现代包管理工具进行 Python 开发。\n- Streamlit Web 应用程序架构。\n- 计算机视觉 API 集成。\n- 国际化与可访问性。\n- 针对不同硬件平台的性能优化。\n\n无论您是对计算机视觉、Web 开发还是 AI 应用感兴趣，本项目都为您提供了一个构建先进 AI 驱动 Web 应用的坚实基础。\n\n---\n\n",
    "supporting": [
      "index_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}