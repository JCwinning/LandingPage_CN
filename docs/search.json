[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "æ‰€æœ‰æ–‡ç« ",
    "section": "",
    "text": "æˆªè‡³ 2026-02-05ã€‚æ–‡ç« æ€»æ•°ï¼š12\n\n\n\n\n\n\n   \n    \n    \n      Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n    \n  \n    \n      \n      \n    \n\n\n\n\n\n\n \n\n\n\nDate\n\n\n\nTitle\n\n\n\nCategories\n\n\n\n\n\n\n\n\n\n\n\nJan 30, 2026\n\n\nAI è£åˆ¤ (AI Judge)\n\n\nAI\n\n\n\n\n\n\n\n\n\nJan 22, 2026\n\n\nVoice Studio: æ–‡å­—&lt;-&gt;è¯­éŸ³è½¬æ¢\n\n\nAI, Audio, ASR, TTS, Streamlit, MLX\n\n\n\n\n\n\n\n\n\nJan 8, 2026\n\n\nLLM æ‘˜è¦ç³»ç»Ÿï¼šå¤šå¹³å° AI æ‘˜è¦å·¥å…·\n\n\nAI, Python, LLM, Open Source\n\n\n\n\n\n\n\n\n\nJan 7, 2026\n\n\nAI èŠå¤©ï¼šå¤šè¯­è¨€å¤šæ¨¡å‹åº”ç”¨ (AI Chat)\n\n\nAI, Streamlit, Python, LLM\n\n\n\n\n\n\n\n\n\nNov 18, 2025\n\n\nä½¿ç”¨ AI SQL æ„å»ºçš„äº¤äº’å¼ GDP è¶‹åŠ¿çœ‹æ¿\n\n\nData Visualization, Streamlit, Economic Analysis, AI\n\n\n\n\n\n\n\n\n\nNov 8, 2025\n\n\nShop Map Manager (åº—é“ºåœ°å›¾ç®¡ç†ç³»ç»Ÿ)\n\n\nAI, API, map\n\n\n\n\n\n\n\n\n\nNov 6, 2025\n\n\nç»“åˆ AI é¢„æµ‹çš„ Streamlit å¤©æ°”é¢„æŠ¥åº”ç”¨\n\n\nPython, Streamlit, AI, tutorial\n\n\n\n\n\n\n\n\n\nNov 5, 2025\n\n\nç»“åˆ AI åˆ†æçš„ Shiny å’Œ Streamlit ä½“é‡è¿½è¸ªçœ‹æ¿\n\n\nAI, API, tutorial\n\n\n\n\n\n\n\n\n\nNov 5, 2025\n\n\nåŸºäº RAG çš„å¨å£«å¿Œå“é‰´ç¬”è®°\n\n\nAI, API, tutorial\n\n\n\n\n\n\n\n\n\nNov 5, 2025\n\n\nä½¿ç”¨ Streamlit æ„å»ºçš„ YOLO ç›®æ ‡æ£€æµ‹åº”ç”¨\n\n\nAI, API, tutorial\n\n\n\n\n\n\n\n\n\nNov 2, 2025\n\n\nR å’Œ Python ä¸­çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG)\n\n\nAI, API, tutorial\n\n\n\n\n\n\n\n\n\nNov 1, 2025\n\n\nOpenRouterï¼šå¤š AI æ¨¡å‹çš„ç»Ÿä¸€ API\n\n\nAI, API, tutorial\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/AI judge/index.html",
    "href": "posts/AI judge/index.html",
    "title": "AI è£åˆ¤ (AI Judge)",
    "section": "",
    "text": "AI judge AI workflow process using 3 method:LangGraph and LangChain (LCEL),n8n :\ngraph TD\n    Start([Start]) --&gt; ModelA[Model A]\n    Start --&gt; ModelB[Model B]\n    Start --&gt; ModelC[Model C]\n    ModelA --&gt; Judge{AI Judge}\n    ModelB --&gt; Judge\n    ModelC --&gt; Judge\n    Judge --&gt; End([End])"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AIç¯å¡”",
    "section": "",
    "text": "AI è£åˆ¤ (AI Judge)\n\n\n\nTony D\n\n\nJan 30, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nVoice Studio: æ–‡å­—&lt;-&gt;è¯­éŸ³è½¬æ¢\n\n\n\nTony D\n\n\nJan 22, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLM æ‘˜è¦ç³»ç»Ÿï¼šå¤šå¹³å° AI æ‘˜è¦å·¥å…·\n\n\n\nTony D\n\n\nJan 8, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI èŠå¤©ï¼šå¤šè¯­è¨€å¤šæ¨¡å‹åº”ç”¨ (AI Chat)\n\n\n\nTony D\n\n\nJan 7, 2026\n\n\n\n\n\n\n\n\n\n\n\n\n\nä½¿ç”¨ AI SQL æ„å»ºçš„äº¤äº’å¼ GDP è¶‹åŠ¿çœ‹æ¿\n\n\n\n\n\n\nNov 18, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nShop Map Manager (åº—é“ºåœ°å›¾ç®¡ç†ç³»ç»Ÿ)\n\n\n\nTony D\n\n\nNov 8, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nç»“åˆ AI é¢„æµ‹çš„ Streamlit å¤©æ°”é¢„æŠ¥åº”ç”¨\n\n\n\nTony D\n\n\nNov 6, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nç»“åˆ AI åˆ†æçš„ Shiny å’Œ Streamlit ä½“é‡è¿½è¸ªçœ‹æ¿\n\n\n\nTony D\n\n\nNov 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nåŸºäº RAG çš„å¨å£«å¿Œå“é‰´ç¬”è®°\n\n\n\nTony D\n\n\nNov 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nä½¿ç”¨ Streamlit æ„å»ºçš„ YOLO ç›®æ ‡æ£€æµ‹åº”ç”¨\n\n\n\nTony D\n\n\nNov 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nR å’Œ Python ä¸­çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG)\n\n\n\nTony D\n\n\nNov 2, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpenRouterï¼šå¤š AI æ¨¡å‹çš„ç»Ÿä¸€ API\n\n\n\nTony D\n\n\nNov 1, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/ARS/index.html",
    "href": "posts/ARS/index.html",
    "title": "Voice Studio: æ–‡å­—<->è¯­éŸ³è½¬æ¢",
    "section": "",
    "text": "ä¸€ä¸ªå¼ºå¤§ä¸”ç¾è§‚çš„ Streamlit åº”ç”¨ï¼Œé›†æˆäº† è‡ªåŠ¨è¯­éŸ³è¯†åˆ« (ASR) å’Œ æ–‡æœ¬è½¬è¯­éŸ³ (TTS) åŠŸèƒ½ã€‚æœ¬é¡¹ç›®æ—¨åœ¨æä¾›ä¸€ä¸ªä¾¿æ·çš„å¹³å°ï¼Œç”¨äºå¯¹æ¯” NVIDIAã€Google çš„å‰æ²¿äº‘ç«¯æ¨¡å‹ä¸æœ¬åœ° MLX ä¼˜åŒ–æ¨¡å‹çš„è¡¨ç°ã€‚"
  },
  {
    "objectID": "posts/ARS/index.html#åœ¨çº¿æ¼”ç¤º",
    "href": "posts/ARS/index.html#åœ¨çº¿æ¼”ç¤º",
    "title": "Voice Studio: æ–‡å­—<->è¯­éŸ³è½¬æ¢",
    "section": "åœ¨çº¿æ¼”ç¤º",
    "text": "åœ¨çº¿æ¼”ç¤º\nhttps://jcwinning-speech-text-model.share.connect.posit.cloud/"
  },
  {
    "objectID": "posts/ARS/index.html#æ ¸å¿ƒåŠŸèƒ½",
    "href": "posts/ARS/index.html#æ ¸å¿ƒåŠŸèƒ½",
    "title": "Voice Studio: æ–‡å­—<->è¯­éŸ³è½¬æ¢",
    "section": "âœ¨ æ ¸å¿ƒåŠŸèƒ½",
    "text": "âœ¨ æ ¸å¿ƒåŠŸèƒ½\n\nğŸ¤ è¯­éŸ³è½¬æ–‡å­— (STT)\n\nGoogle Gemini 2.5 Flash Lite: é€šè¿‡ OpenRouter æä¾›çš„é«˜é€Ÿã€ç²¾å‡†äº‘ç«¯è½¬å†™ã€‚\nNVIDIA Parakeet-CTC: è¡Œä¸šé¢†å…ˆçš„ ASR æ€§èƒ½ï¼ŒåŸºäº NVIDIA Riva Cloudã€‚\næœ¬åœ° MLX æ¨¡å‹: ä¸“ä¸º Apple Silicon ä¼˜åŒ–çš„æœ¬åœ°ç§å¯†è½¬å†™ã€‚\n\nGLM-ASR-Nano: è½»é‡ã€é«˜æ•ˆã€‚\nWhisper-Large-v3-Turbo: è¡Œä¸šé¡¶å°–ã€é«˜ç²¾åº¦çš„è½¬å†™æ¨¡å‹ã€‚\n\nåŒè¾“å…¥æ¨¡å¼: æ”¯æŒå®æ—¶éº¦å…‹é£å½•éŸ³æˆ–ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶ï¼ˆWAV, MP3, M4Aï¼‰ã€‚\nå³æ—¶æ˜¾ç¤º: ç»“æœåœ¨æ¯ä¸ªæ¨¡å‹å®Œæˆæ—¶ç«‹å³æ˜¾ç¤ºï¼Œæ— éœ€ç­‰å¾…æ‰€æœ‰æ¨¡å‹ã€‚\nè‡ªåŠ¨å½’ä¸€åŒ–: è‡ªåŠ¨å°†éŸ³é¢‘è½¬æ¢ä¸º 16kHz å•å£°é“ WAVï¼Œç¡®ä¿æœ€é«˜è¯†åˆ«å‡†ç¡®åº¦ã€‚\nç»“æœä¸‹è½½: æ”¯æŒå°†æ¯ä¸ªæ¨¡å‹çš„è½¬å†™ç»“æœä¿å­˜ä¸ºæœ¬åœ° .md æ–‡ä»¶ã€‚\n\n\n\nğŸ”Š æ–‡æœ¬è½¬è¯­éŸ³ (TTS)\n\nQwen TTS (DashScope): é˜¿é‡Œé€šä¹‰åƒé—®æä¾›çš„è‡ªç„¶è¯­éŸ³åˆæˆï¼Œå†…ç½® 7 ç§æ€§æ ¼å„å¼‚çš„å£°éŸ³ã€‚\nNVIDIA Riva (Magpie): ä¸“ä¸šçº§å¤šè¯­è¨€åˆæˆï¼Œé‡‡ç”¨æœ€æ–°çš„ Magpie-Multilingual æ¨¡å‹ã€‚\nåŠ¨æ€å£°éŸ³é€‰æ‹©: æä¾›ä¸°å¯Œçš„ä¸­æ–‡ï¼ˆæ™®é€šè¯ï¼‰å’Œè‹±æ–‡å‘éŸ³äººé€‰é¡¹ã€‚"
  },
  {
    "objectID": "posts/ARS/index.html#å¿«é€Ÿä¸Šæ‰‹",
    "href": "posts/ARS/index.html#å¿«é€Ÿä¸Šæ‰‹",
    "title": "Voice Studio: æ–‡å­—<->è¯­éŸ³è½¬æ¢",
    "section": "ğŸš€ å¿«é€Ÿä¸Šæ‰‹",
    "text": "ğŸš€ å¿«é€Ÿä¸Šæ‰‹\n\nç¯å¢ƒè¦æ±‚\n\nPython 3.10+\nApple Silicon (è‹¥éœ€ä½¿ç”¨æœ¬åœ° MLX åŠŸèƒ½)\nAPI å¯†é’¥:\n\nOpenRouter\nNVIDIA NIM\né˜¿é‡Œäº‘ DashScope\n\n\n\n\nå®‰è£…æ­¥éª¤\n\nå…‹éš†ä»“åº“:\ngit clone &lt;repository-url&gt;\ncd ARS\nå®‰è£…ä¾èµ–:\npip install -r requirements.txt\nåœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶å¹¶å¡«å…¥å¯†é’¥:\nOPENROUTER_API_KEY=ä½ çš„å¯†é’¥\nDASHSCOPE_API_KEY=ä½ çš„å¯†é’¥\nNVIDIA_API_KEY=ä½ çš„å¯†é’¥\n\n\n\nè¿è¡Œåº”ç”¨\nstreamlit run app.py"
  },
  {
    "objectID": "posts/ARS/index.html#äº‘ç«¯éƒ¨ç½²",
    "href": "posts/ARS/index.html#äº‘ç«¯éƒ¨ç½²",
    "title": "Voice Studio: æ–‡å­—<->è¯­éŸ³è½¬æ¢",
    "section": "â˜ï¸ äº‘ç«¯éƒ¨ç½²",
    "text": "â˜ï¸ äº‘ç«¯éƒ¨ç½²\næœ¬é¡¹ç›®å·²é’ˆå¯¹ Streamlit Cloud è¿›è¡Œé¢„é…ç½®ï¼š - è‡ªåŠ¨æ£€æµ‹è¿è¡Œç¯å¢ƒï¼Œåœ¨äº‘ç«¯éƒ¨ç½²æ—¶ç¦ç”¨æœ¬åœ°æ¨¡å‹ (MLX) ä»¥ç¡®ä¿ç³»ç»Ÿç¨³å®šã€‚ - API å¯†é’¥å¯ä»¥é€šè¿‡ Streamlit çš„ â€œSecretsâ€ é¢æ¿è¿›è¡Œå®‰å…¨ç®¡ç†ã€‚"
  },
  {
    "objectID": "posts/ARS/index.html#æŠ€æœ¯æ ˆ",
    "href": "posts/ARS/index.html#æŠ€æœ¯æ ˆ",
    "title": "Voice Studio: æ–‡å­—<->è¯­éŸ³è½¬æ¢",
    "section": "ğŸ› ï¸ æŠ€æœ¯æ ˆ",
    "text": "ğŸ› ï¸ æŠ€æœ¯æ ˆ\n\nç•Œé¢: Streamlit\næœ¬åœ°æ¨ç†: MLX (é’ˆå¯¹ Mac M èŠ¯ç‰‡ä¼˜åŒ–)\näº‘ç«¯æœåŠ¡: NVIDIA Riva, OpenRouter (Gemini), é˜¿é‡Œäº‘ DashScope (Qwen)\néŸ³é¢‘å¤„ç†: Wave, SoundFile, Streamlit Mic Recorder"
  },
  {
    "objectID": "posts/yolo-app/index.html",
    "href": "posts/yolo-app/index.html",
    "title": "ä½¿ç”¨ Streamlit æ„å»ºçš„ YOLO ç›®æ ‡æ£€æµ‹åº”ç”¨",
    "section": "",
    "text": "è¯¥åº”ç”¨æ˜¯ä¸€ä¸ªå…¨é¢çš„ Streamlit Web åº”ç”¨ç¨‹åºï¼Œåˆ©ç”¨ YOLO11ï¼ˆUltralytics æ¡†æ¶ï¼‰æä¾›ç›®æ ‡æ£€æµ‹åŠŸèƒ½ï¼Œæ”¯æŒå¤šç§è¾“å…¥æºå’Œå¤„ç†åç«¯ã€‚è¯¥é¡¹ç›®çš„ç‰¹åˆ«ä¹‹å¤„åœ¨äºå…¶å¤šæ¨¡å‹æ¶æ„å’Œç”Ÿäº§çº§åˆ«çš„ç‰¹æ€§ã€‚\nåœ¨çº¿æ¼”ç¤º: https://yolo-live.streamlit.app/\nGithub: https://github.com/JCwinning/YOLO_app\n\nç›®æ ‡æ£€æµ‹ç‰©ä½“è¯†åˆ«\n\n\n\n\n\nåº”ç”¨ç¨‹åºæˆªå›¾ - ä¸»ç•Œé¢\n\n\n\n\n\n\n\nåº”ç”¨ç¨‹åºæˆªå›¾ - æ£€æµ‹ç»“æœ\n\n\n\n\n\n\n\n\n\nåº”ç”¨æ”¯æŒå¤šç§è¾“å…¥æ–¹å¼ï¼š - æ–‡ä»¶ä¸Šä¼ ï¼šä»æœ¬åœ°å­˜å‚¨ä¸Šä¼ å›¾åƒå’Œè§†é¢‘ã€‚ - URL è¾“å…¥ï¼šç›´æ¥ä»ç½‘ç»œè¾“å…¥å›¾åƒ URLã€‚ - å®æ—¶ç›¸æœºï¼šä½¿ç”¨è®¾å¤‡ç›¸æœºè¿›è¡Œå®æ—¶ç…§ç‰‡æ•è·ã€‚\n\n\n\nå…¶æœ€çªå‡ºçš„ç‰¹æ€§ä¹‹ä¸€æ˜¯æ”¯æŒä¸åŒçš„ AI æ¨¡å‹ï¼š\n\n\n\näº”ç§ä¸åŒçš„æ¨¡å‹å˜ä½“ï¼ˆnano, small, medium, large, extra-largeï¼‰ã€‚\nè‡ªåŠ¨è®¾å¤‡æ£€æµ‹ï¼Œæ”¯æŒ Apple Silicon çš„ MPS åŠ é€Ÿã€‚\nåœ¨ä¸æ”¯æŒåŠ é€Ÿçš„æƒ…å†µä¸‹è‡ªåŠ¨å›é€€è‡³ CPUï¼Œç¡®ä¿æ›´å¹¿çš„å…¼å®¹æ€§ã€‚\n\n\n\n\n\né€šè¿‡ DashScope API è°ƒç”¨ Qwen-Image-Edit è¿›è¡Œé«˜çº§å›¾åƒæ ‡æ³¨ã€‚\né€šè¿‡ OpenRouter API è°ƒç”¨ Gemini 2.5 Flash Image è¿›è¡Œå‰æ²¿çš„å›¾åƒå¤„ç†ã€‚\n\n\n\n\n\n\nåŒè¯­ç•Œé¢ï¼šå®Œæ•´çš„è‹±æ–‡/ä¸­æ–‡æ”¯æŒï¼ŒåŒ…å« 113+ ä¸ªç¿»è¯‘å­—æ®µã€‚\næ™ºèƒ½ UI ç®¡ç†ï¼šå¤„ç†åè‡ªåŠ¨éšè—è¾“å…¥å›¾åƒã€‚\nä¸‹è½½åŠŸèƒ½ï¼šæ”¯æŒå°†æ ‡æ³¨åçš„ç»“æœä¿å­˜åˆ°æœ¬åœ°ã€‚\nè¿›åº¦è¿½è¸ªï¼šè§†é¢‘å¤„ç†è¿‡ç¨‹ä¸­çš„å®æ—¶è¿›åº¦æ›´æ–°ã€‚\nä¼šè¯ç®¡ç†ï¼šåœ¨ç”¨æˆ·äº¤äº’è¿‡ç¨‹ä¸­ä¿æŒæŒä¹…åŒ–çŠ¶æ€ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n ç³»ç»Ÿæ¶æ„å›¾ \n\n\n\n\n\n[project]\nname = \"yolo-app\"\nrequires-python = \"&gt;=3.12\"\ndependencies = [\n    \"dashscope&gt;=1.17.0\",      # é˜¿é‡Œäº‘ API\n    \"opencv-python&gt;=4.11.0.86\", # è®¡ç®—æœºè§†è§‰\n    \"streamlit&gt;=1.50.0\",       # Web æ¡†æ¶\n    \"torch&gt;=2.2\",              # æ·±åº¦å­¦ä¹ \n    \"ultralytics&gt;=8.3.0\",      # YOLO æ¡†æ¶\n]\n\n\n\nä¸»åº”ç”¨ç¨‹åº (app.py) ç”± 1,000 å¤šè¡Œç»“æ„è‰¯å¥½çš„ Python ä»£ç ç»„æˆï¼Œä¸»è¦åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªç»„ä»¶ï¼š\n\n\n\n\nCode\nfrom language import translations\n\ndef get_translation(key, **kwargs):\n    \"\"\"ä½¿ç”¨å½“å‰ä¼šè¯è¯­è¨€çš„ç¿»è¯‘å‡½æ•°\"\"\"\n    lang = st.session_state.get(\"language\", \"en\")\n    text = translations[lang].get(key, translations[\"en\"].get(key, key))\n    return text.format(**kwargs) if kwargs else text\n\n\n\n\n\n\n\nCode\ndef get_device():\n    \"\"\"è‡ªåŠ¨æ£€æµ‹æœ€ä½³å¯ç”¨è®¾å¤‡\"\"\"\n    if torch.backends.mps.is_available():\n        return \"mps\"  # Apple Silicon GPU åŠ é€Ÿ\n    return \"cpu\"      # å›é€€è‡³ CPU\n \n# æ¨¡å‹åŠ è½½ä¸è®¾å¤‡ä¼˜åŒ–\ndevice = get_device()\nmodel = YOLO(selected_model).to(device)\nst.info(f\"Using device: {device.upper()}\")\n\n\n\n\n\n\n\nCode\ndef encode_image_to_base64(image):\n    \"\"\"å°† PIL å›¾åƒç¼–ç ä¸º base64 å­—ç¬¦ä¸²å¹¶è¿›è¡Œå°ºå¯¸å‹ç¼©\"\"\"\n    max_size_bytes = 8 * 1024 * 1024  # 8MB é™åˆ¶\n\n    formats_and_qualities = [\n        (\"JPEG\", 95), (\"JPEG\", 85), (\"JPEG\", 75),\n        (\"WEBP\", 95), (\"WEBP\", 85), (\"WEBP\", 75),\n    ]\n\n    for fmt, quality in formats_and_qualities:\n        # å°è¯•ä¸åŒçš„å‹ç¼©ç­–ç•¥\n        # ... å‹ç¼©é€»è¾‘\n\n\n\n\n\n\n\n\nåº”ç”¨æ”¯æŒæ‰€æœ‰ YOLO11 æ¨¡å‹å˜ä½“ï¼Œå¹¶å…·å¤‡è‡ªåŠ¨æ€§èƒ½ä¼˜åŒ–ï¼š\n\n\nCode\n# æ¨¡å‹é€‰æ‹©ç•Œé¢\nmodel_options = [\"yolo11n.pt\", \"yolo11s.pt\", \"yolo11m.pt\", \"yolo11l.pt\", \"yolo11x.pt\"]\nmodel_descriptions = {\n    \"yolo11n.pt\": \"Nano - æœ€å¿«ï¼Œç²¾åº¦æœ€ä½\",\n    \"yolo11s.pt\": \"Small - å‡è¡¡æ€§å¥½\",\n    \"yolo11m.pt\": \"Medium - æ¨èä½¿ç”¨\",\n    \"yolo11l.pt\": \"Large - ç²¾åº¦è¾ƒé«˜\",\n    \"yolo11x.pt\": \"Extra Large - ç²¾åº¦æœ€é«˜\"\n}\n\nselected_model = st.sidebar.selectbox(\n    get_translation(\"model_selection\"),\n    model_options,\n    index=model_options.index(\"yolo11s.pt\"),\n    format_func=lambda x: f\"{model_descriptions[x]} ({x})\"\n)\n\n# å¸¦è¿›åº¦è¿½è¸ªçš„æ£€æµ‹è¿‡ç¨‹\ndef detect_objects(image, model, confidence_threshold=0.5):\n    \"\"\"æ‰§è¡Œå¸¦è¿›åº¦è¿½è¸ªçš„ç›®æ ‡æ£€æµ‹\"\"\"\n    with st.spinner(get_translation(\"processing\")):\n        results = model.predict(image, conf=confidence_threshold)\n\n        # å¤„ç†ç»“æœ\n        detections = []\n        for result in results:\n            boxes = result.boxes\n            for box in boxes:\n                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n                conf = box.conf[0].cpu().numpy()\n                cls = int(box.cls[0].cpu().numpy())\n                class_name = model.names[cls]\n\n                detections.append({\n                    'class': class_name,\n                    'confidence': conf,\n                    'bbox': [x1, y1, x2, y2]\n                })\n\n    return detections, results\n\n\n\n\n\nå¯¹äºäº‘ç«¯æ¨¡å‹ï¼Œåº”ç”¨è´Ÿè´£ API èº«ä»½éªŒè¯å’Œè¯·æ±‚æ ¼å¼åŒ–ï¼š\n\n\nCode\ndef process_with_qwen(image, api_key):\n    \"\"\"ä½¿ç”¨é˜¿é‡Œäº‘ DashScope æä¾›çš„ Qwen-Image-Edit å¤„ç†å›¾åƒ\"\"\"\n    try:\n        response = MultiModalConversation.call(\n            model='qwen-image-edit',\n            input=[\n                {\n                    'role': 'user',\n                    'content': [\n                        {'image': f\"data:image/jpeg;base64,{image_b64}\"},\n                        {'text': 'Please identify and label all objects in this image.'}\n                    ]\n                }\n            ]\n        )\n        return response\n    except Exception as e:\n        st.error(f\"API Error: {str(e)}\")\n        return None\n\n\n\n\n\n\n\n\n\nåº”ç”¨ç¨‹åºé‡‡ç”¨ä¸“ä¸šçš„ä¸‰ä¸ªåˆ†æ å¸ƒå±€ï¼š\n\nä¾§è¾¹æ ï¼šæ¨¡å‹é€‰æ‹©ã€ç½®ä¿¡åº¦é˜ˆå€¼ã€è¯­è¨€è®¾ç½®ã€‚\nä¸»åŒºåŸŸï¼šè¾“å…¥æ–¹å¼é€‰æ‹©ã€å›¾åƒ/è§†é¢‘æ˜¾ç¤ºã€ç»“æœå±•ç¤ºã€‚\nç»“æœé¢æ¿ï¼šæ£€æµ‹ç»Ÿè®¡ã€ä¸‹è½½é€‰é¡¹ã€‚\n\n\n\n\nç¿»è¯‘ç³»ç»Ÿç®¡ç†æ‰€æœ‰çš„ UI å…ƒç´ ï¼š\n\n\nCode\ntranslations = {\n    \"en\": {\n        \"title\": \"YOLO11 Object Detection\",\n        \"upload_file\": \"Upload File\",\n        \"camera_input\": \"Use Camera\",\n        # ... æ›´å¤šå­—æ®µ\n    },\n    \"zh\": {\n        \"title\": \"YOLO11 ç›®æ ‡æ£€æµ‹\",\n        \"upload_file\": \"ä¸Šä¼ æ–‡ä»¶\",\n        \"camera_input\": \"ä½¿ç”¨ç›¸æœº\",\n        # ... å¯¹åº”çš„ä¸­æ–‡ç¿»è¯‘\n    }\n}\n\n\n\n\n\n\n\n\n\n\n\næ¨¡å‹\nå‚æ•°é‡\nmAP\næ¨ç†æ—¶é—´ (CPU)\næ¨ç†æ—¶é—´ (MPS)\n\n\n\n\nYOLO11n\n2.6M\n37.2\n15ms\n3ms\n\n\nYOLO11s\n9.4M\n45.5\n28ms\n6ms\n\n\nYOLO11m\n25.4M\n51.2\n52ms\n12ms\n\n\nYOLO11l\n43.7M\n53.4\n84ms\n18ms\n\n\nYOLO11x\n68.2M\n54.7\n126ms\n26ms\n\n\n\n\n\n\nè¯¥åº”ç”¨ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶åœ¨ Apple Silicon è®¾å¤‡ä¸Šåˆ©ç”¨ Metal Performance Shaders (MPS)ï¼š\n\n\nCode\ndevice = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\nmodel = YOLO(selected_model).to(device)\n\n# æ€§èƒ½ç›‘æ§\nimport time\nstart_time = time.time()\nresults = model.predict(image)\ninference_time = (time.time() - start_time) * 1000\n\nst.metric(f\"æ¨ç†æ—¶é—´ ({device.upper()})\", f\"{inference_time:.1f}ms\")\n\n\n\n\n\nä¸ºäº†æ»¡è¶³ API çš„å¤§å°é™åˆ¶ï¼Œåº”ç”¨å®ç°äº†æ™ºèƒ½å›¾åƒå‹ç¼©ï¼š\n\n\nCode\ndef compress_image_for_api(image, max_size=8*1024*1024):\n    \"\"\"å‹ç¼©å›¾åƒä»¥æ»¡è¶³ API è¦æ±‚\"\"\"\n    for quality in [95, 85, 75, 65]:\n        for fmt in [\"JPEG\", \"WEBP\"]:\n            buffer = BytesIO()\n            image.save(buffer, format=fmt, quality=quality)\n            if buffer.tell() &lt;= max_size:\n                return buffer.getvalue()\n    return None\n\n\n\n\n\n\n\n\nåº”ç”¨ç¨‹åºç»´æŠ¤ç€å…¨é¢çš„ä¼šè¯çŠ¶æ€ï¼š\n\n\nCode\nsession_state_vars = [\n    \"current_image\", \"uploaded_image_bytes\",\n    \"current_video\", \"uploaded_video_bytes\",\n    \"camera_active\", \"camera_frame\",\n    \"qwen_processed\", \"gemini_processed\",\n    \"language\", \"input_method_index\"\n]\n\n\n\n\n\nå¥å£®çš„é”™è¯¯å¤„ç†ç¡®ä¿äº†ä¼˜é›…çš„é™çº§æœåŠ¡ï¼š\n\n\nCode\ntry:\n    result = model.predict(image, conf=confidence_threshold)\n    st.success(get_translation(\"detection_success\"))\nexcept Exception as e:\n    st.error(f\"æ£€æµ‹å¤±è´¥: {str(e)}\")\n    # å›é€€è‡³å¤‡é€‰å¤„ç†æ–¹æ³•\n\n\n\n\n\n\n\n\n\nPython 3.12 æˆ–æ›´é«˜ç‰ˆæœ¬\nç°ä»£åŒ…ç®¡ç†å™¨ï¼ˆæ¨èä½¿ç”¨ uvï¼‰\nå¯¹äºäº‘ç«¯æ¨¡å‹ï¼šéœ€è¦ DashScope å’Œ OpenRouter çš„ API å¯†é’¥\n\n\n\n\n# å…‹éš†ä»“åº“\ngit clone &lt;repository-url&gt;\ncd YOLO_app\n\n# ä½¿ç”¨ uv åŒæ­¥ä¾èµ–ï¼ˆæ¨èï¼‰\nuv sync\n\n# å¤‡é€‰ï¼šä½¿ç”¨ pip å®‰è£…\npip install -r requirements.txt\n\n# è¿è¡Œåº”ç”¨\nstreamlit run app.py\n\n\n\nåˆ›å»ºä¸€ä¸ªåŒ…å« API å¯†é’¥çš„ .env æ–‡ä»¶ï¼š\n# é˜¿é‡Œäº‘ DashScope API\nDASHSCOPE_API_KEY=æ‚¨çš„å¯†é’¥\n\n# OpenRouter API (ç”¨äº Gemini)\nOPENROUTER_API_KEY=æ‚¨çš„å¯†é’¥\n\n\n\n\n\n\nå¯åŠ¨åº”ç”¨ç¨‹åºã€‚\nä¸Šä¼ å›¾åƒæˆ–æä¾›å›¾åƒ URLã€‚\né€‰æ‹©æ‚¨åå¥½çš„ YOLO11 æ¨¡å‹ï¼ˆæ¨èä½¿ç”¨ yolo11s.ptï¼‰ã€‚\næ ¹æ®éœ€è¦è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼ã€‚\nç‚¹å‡»â€œå¼€å§‹æ£€æµ‹â€ã€‚\næŸ¥çœ‹ç»“æœå¹¶ä¸‹è½½æ ‡æ³¨åçš„å›¾åƒã€‚\n\n\n\n\n\né€‰æ‹©â€œä½¿ç”¨ç›¸æœºâ€è¾“å…¥æ–¹å¼ã€‚\nåœ¨æç¤ºæ—¶æˆäºˆç›¸æœºæƒé™ã€‚\næ‹æ‘„ç…§ç‰‡ã€‚\né€‰æ‹©æ£€æµ‹æ¨¡å‹ã€‚\nè·å–å³æ—¶çš„ç›®æ ‡æ£€æµ‹ç»“æœã€‚\n\n\n\n\n\nåœ¨ä¾§è¾¹æ è¾“å…¥æ‚¨çš„ API å¯†é’¥ã€‚\nä¸Šä¼ å›¾åƒã€‚\né€‰æ‹© â€œQwen-Image-Editâ€ æˆ– â€œGemini 2.5 Flashâ€ æ¨¡å‹ã€‚\nåˆ©ç”¨å…ˆè¿›çš„ AI èƒ½åŠ›å¤„ç†å›¾åƒã€‚\nå°†ç»“æœä¸æœ¬åœ° YOLO æ¨¡å‹è¿›è¡Œå¯¹æ¯”ã€‚\n\n\n\n\n\n\næœªæ¥ç‰ˆæœ¬çš„æ½œåœ¨æ”¹è¿›ç‚¹ï¼š\n\næ›´å¤šæ¨¡å‹ï¼šé›†æˆæ›´å¤šçš„äº‘ç«¯ AI æœåŠ¡ã€‚\nå®æ—¶è§†é¢‘å¤„ç†ï¼šå¢å¼ºè§†é¢‘æµå¤„ç†èƒ½åŠ›ã€‚\nè‡ªå®šä¹‰æ¨¡å‹è®­ç»ƒï¼šå…è®¸ç”¨æˆ·è®­ç»ƒè‡ªå®šä¹‰ YOLO æ¨¡å‹ã€‚\nç§»åŠ¨ç«¯ä¼˜åŒ–ï¼šä¸ºç§»åŠ¨è®¾å¤‡æ”¯æŒæä¾› PWA ç‰¹æ€§ã€‚\næ‰¹é‡å¤„ç†ï¼šåŒæ—¶å¤„ç†å¤šå¼ å›¾åƒã€‚\n\n\n\n\nè¿™æ¬¾ YOLO ç›®æ ‡æ£€æµ‹åº”ç”¨å±•ç¤ºäº†å¦‚ä½•æ„å»ºä¸€ä¸ªå¤æ‚çš„ã€ç”Ÿäº§çº§åˆ«çš„è®¡ç®—æœºè§†è§‰ç³»ç»Ÿã€‚æœ¬åœ°å’Œäº‘ç«¯æ¨¡å‹çš„ç»“åˆã€åŒè¯­æ”¯æŒä»¥åŠå…¨é¢çš„é”™è¯¯å¤„ç†ï¼Œä½¿å…¶ä¸ä»…é€‚ç”¨äºå¼€å‘ç¯å¢ƒï¼Œä¹Ÿé€‚ç”¨äºç”Ÿäº§ç¯å¢ƒã€‚\nè¯¥é¡¹ç›®å±•ç¤ºäº†ä»¥ä¸‹æ–¹é¢çš„æœ€ä½³å®è·µï¼š - ä½¿ç”¨ç°ä»£åŒ…ç®¡ç†å·¥å…·è¿›è¡Œ Python å¼€å‘ã€‚ - Streamlit Web åº”ç”¨ç¨‹åºæ¶æ„ã€‚ - è®¡ç®—æœºè§†è§‰ API é›†æˆã€‚ - å›½é™…åŒ–ä¸å¯è®¿é—®æ€§ã€‚ - é’ˆå¯¹ä¸åŒç¡¬ä»¶å¹³å°çš„æ€§èƒ½ä¼˜åŒ–ã€‚\næ— è®ºæ‚¨æ˜¯å¯¹è®¡ç®—æœºè§†è§‰ã€Web å¼€å‘è¿˜æ˜¯ AI åº”ç”¨æ„Ÿå…´è¶£ï¼Œæœ¬é¡¹ç›®éƒ½ä¸ºæ‚¨æä¾›äº†ä¸€ä¸ªæ„å»ºå…ˆè¿› AI é©±åŠ¨ Web åº”ç”¨çš„åšå®åŸºç¡€ã€‚"
  },
  {
    "objectID": "posts/yolo-app/index.html#æ ¸å¿ƒç‰¹æ€§",
    "href": "posts/yolo-app/index.html#æ ¸å¿ƒç‰¹æ€§",
    "title": "ä½¿ç”¨ Streamlit æ„å»ºçš„ YOLO ç›®æ ‡æ£€æµ‹åº”ç”¨",
    "section": "",
    "text": "åº”ç”¨æ”¯æŒå¤šç§è¾“å…¥æ–¹å¼ï¼š - æ–‡ä»¶ä¸Šä¼ ï¼šä»æœ¬åœ°å­˜å‚¨ä¸Šä¼ å›¾åƒå’Œè§†é¢‘ã€‚ - URL è¾“å…¥ï¼šç›´æ¥ä»ç½‘ç»œè¾“å…¥å›¾åƒ URLã€‚ - å®æ—¶ç›¸æœºï¼šä½¿ç”¨è®¾å¤‡ç›¸æœºè¿›è¡Œå®æ—¶ç…§ç‰‡æ•è·ã€‚\n\n\n\nå…¶æœ€çªå‡ºçš„ç‰¹æ€§ä¹‹ä¸€æ˜¯æ”¯æŒä¸åŒçš„ AI æ¨¡å‹ï¼š\n\n\n\näº”ç§ä¸åŒçš„æ¨¡å‹å˜ä½“ï¼ˆnano, small, medium, large, extra-largeï¼‰ã€‚\nè‡ªåŠ¨è®¾å¤‡æ£€æµ‹ï¼Œæ”¯æŒ Apple Silicon çš„ MPS åŠ é€Ÿã€‚\nåœ¨ä¸æ”¯æŒåŠ é€Ÿçš„æƒ…å†µä¸‹è‡ªåŠ¨å›é€€è‡³ CPUï¼Œç¡®ä¿æ›´å¹¿çš„å…¼å®¹æ€§ã€‚\n\n\n\n\n\né€šè¿‡ DashScope API è°ƒç”¨ Qwen-Image-Edit è¿›è¡Œé«˜çº§å›¾åƒæ ‡æ³¨ã€‚\né€šè¿‡ OpenRouter API è°ƒç”¨ Gemini 2.5 Flash Image è¿›è¡Œå‰æ²¿çš„å›¾åƒå¤„ç†ã€‚\n\n\n\n\n\n\nåŒè¯­ç•Œé¢ï¼šå®Œæ•´çš„è‹±æ–‡/ä¸­æ–‡æ”¯æŒï¼ŒåŒ…å« 113+ ä¸ªç¿»è¯‘å­—æ®µã€‚\næ™ºèƒ½ UI ç®¡ç†ï¼šå¤„ç†åè‡ªåŠ¨éšè—è¾“å…¥å›¾åƒã€‚\nä¸‹è½½åŠŸèƒ½ï¼šæ”¯æŒå°†æ ‡æ³¨åçš„ç»“æœä¿å­˜åˆ°æœ¬åœ°ã€‚\nè¿›åº¦è¿½è¸ªï¼šè§†é¢‘å¤„ç†è¿‡ç¨‹ä¸­çš„å®æ—¶è¿›åº¦æ›´æ–°ã€‚\nä¼šè¯ç®¡ç†ï¼šåœ¨ç”¨æˆ·äº¤äº’è¿‡ç¨‹ä¸­ä¿æŒæŒä¹…åŒ–çŠ¶æ€ã€‚"
  },
  {
    "objectID": "posts/yolo-app/index.html#æŠ€æœ¯æ¶æ„",
    "href": "posts/yolo-app/index.html#æŠ€æœ¯æ¶æ„",
    "title": "ä½¿ç”¨ Streamlit æ„å»ºçš„ YOLO ç›®æ ‡æ£€æµ‹åº”ç”¨",
    "section": "",
    "text": "ç³»ç»Ÿæ¶æ„å›¾ \n\n\n\n\n\n[project]\nname = \"yolo-app\"\nrequires-python = \"&gt;=3.12\"\ndependencies = [\n    \"dashscope&gt;=1.17.0\",      # é˜¿é‡Œäº‘ API\n    \"opencv-python&gt;=4.11.0.86\", # è®¡ç®—æœºè§†è§‰\n    \"streamlit&gt;=1.50.0\",       # Web æ¡†æ¶\n    \"torch&gt;=2.2\",              # æ·±åº¦å­¦ä¹ \n    \"ultralytics&gt;=8.3.0\",      # YOLO æ¡†æ¶\n]\n\n\n\nä¸»åº”ç”¨ç¨‹åº (app.py) ç”± 1,000 å¤šè¡Œç»“æ„è‰¯å¥½çš„ Python ä»£ç ç»„æˆï¼Œä¸»è¦åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªç»„ä»¶ï¼š\n\n\n\n\nCode\nfrom language import translations\n\ndef get_translation(key, **kwargs):\n    \"\"\"ä½¿ç”¨å½“å‰ä¼šè¯è¯­è¨€çš„ç¿»è¯‘å‡½æ•°\"\"\"\n    lang = st.session_state.get(\"language\", \"en\")\n    text = translations[lang].get(key, translations[\"en\"].get(key, key))\n    return text.format(**kwargs) if kwargs else text\n\n\n\n\n\n\n\nCode\ndef get_device():\n    \"\"\"è‡ªåŠ¨æ£€æµ‹æœ€ä½³å¯ç”¨è®¾å¤‡\"\"\"\n    if torch.backends.mps.is_available():\n        return \"mps\"  # Apple Silicon GPU åŠ é€Ÿ\n    return \"cpu\"      # å›é€€è‡³ CPU\n \n# æ¨¡å‹åŠ è½½ä¸è®¾å¤‡ä¼˜åŒ–\ndevice = get_device()\nmodel = YOLO(selected_model).to(device)\nst.info(f\"Using device: {device.upper()}\")\n\n\n\n\n\n\n\nCode\ndef encode_image_to_base64(image):\n    \"\"\"å°† PIL å›¾åƒç¼–ç ä¸º base64 å­—ç¬¦ä¸²å¹¶è¿›è¡Œå°ºå¯¸å‹ç¼©\"\"\"\n    max_size_bytes = 8 * 1024 * 1024  # 8MB é™åˆ¶\n\n    formats_and_qualities = [\n        (\"JPEG\", 95), (\"JPEG\", 85), (\"JPEG\", 75),\n        (\"WEBP\", 95), (\"WEBP\", 85), (\"WEBP\", 75),\n    ]\n\n    for fmt, quality in formats_and_qualities:\n        # å°è¯•ä¸åŒçš„å‹ç¼©ç­–ç•¥\n        # ... å‹ç¼©é€»è¾‘\n\n\n\n\n\n\n\n\nåº”ç”¨æ”¯æŒæ‰€æœ‰ YOLO11 æ¨¡å‹å˜ä½“ï¼Œå¹¶å…·å¤‡è‡ªåŠ¨æ€§èƒ½ä¼˜åŒ–ï¼š\n\n\nCode\n# æ¨¡å‹é€‰æ‹©ç•Œé¢\nmodel_options = [\"yolo11n.pt\", \"yolo11s.pt\", \"yolo11m.pt\", \"yolo11l.pt\", \"yolo11x.pt\"]\nmodel_descriptions = {\n    \"yolo11n.pt\": \"Nano - æœ€å¿«ï¼Œç²¾åº¦æœ€ä½\",\n    \"yolo11s.pt\": \"Small - å‡è¡¡æ€§å¥½\",\n    \"yolo11m.pt\": \"Medium - æ¨èä½¿ç”¨\",\n    \"yolo11l.pt\": \"Large - ç²¾åº¦è¾ƒé«˜\",\n    \"yolo11x.pt\": \"Extra Large - ç²¾åº¦æœ€é«˜\"\n}\n\nselected_model = st.sidebar.selectbox(\n    get_translation(\"model_selection\"),\n    model_options,\n    index=model_options.index(\"yolo11s.pt\"),\n    format_func=lambda x: f\"{model_descriptions[x]} ({x})\"\n)\n\n# å¸¦è¿›åº¦è¿½è¸ªçš„æ£€æµ‹è¿‡ç¨‹\ndef detect_objects(image, model, confidence_threshold=0.5):\n    \"\"\"æ‰§è¡Œå¸¦è¿›åº¦è¿½è¸ªçš„ç›®æ ‡æ£€æµ‹\"\"\"\n    with st.spinner(get_translation(\"processing\")):\n        results = model.predict(image, conf=confidence_threshold)\n\n        # å¤„ç†ç»“æœ\n        detections = []\n        for result in results:\n            boxes = result.boxes\n            for box in boxes:\n                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n                conf = box.conf[0].cpu().numpy()\n                cls = int(box.cls[0].cpu().numpy())\n                class_name = model.names[cls]\n\n                detections.append({\n                    'class': class_name,\n                    'confidence': conf,\n                    'bbox': [x1, y1, x2, y2]\n                })\n\n    return detections, results\n\n\n\n\n\nå¯¹äºäº‘ç«¯æ¨¡å‹ï¼Œåº”ç”¨è´Ÿè´£ API èº«ä»½éªŒè¯å’Œè¯·æ±‚æ ¼å¼åŒ–ï¼š\n\n\nCode\ndef process_with_qwen(image, api_key):\n    \"\"\"ä½¿ç”¨é˜¿é‡Œäº‘ DashScope æä¾›çš„ Qwen-Image-Edit å¤„ç†å›¾åƒ\"\"\"\n    try:\n        response = MultiModalConversation.call(\n            model='qwen-image-edit',\n            input=[\n                {\n                    'role': 'user',\n                    'content': [\n                        {'image': f\"data:image/jpeg;base64,{image_b64}\"},\n                        {'text': 'Please identify and label all objects in this image.'}\n                    ]\n                }\n            ]\n        )\n        return response\n    except Exception as e:\n        st.error(f\"API Error: {str(e)}\")\n        return None"
  },
  {
    "objectID": "posts/yolo-app/index.html#ç”¨æˆ·ç•Œé¢è®¾è®¡",
    "href": "posts/yolo-app/index.html#ç”¨æˆ·ç•Œé¢è®¾è®¡",
    "title": "ä½¿ç”¨ Streamlit æ„å»ºçš„ YOLO ç›®æ ‡æ£€æµ‹åº”ç”¨",
    "section": "",
    "text": "åº”ç”¨ç¨‹åºé‡‡ç”¨ä¸“ä¸šçš„ä¸‰ä¸ªåˆ†æ å¸ƒå±€ï¼š\n\nä¾§è¾¹æ ï¼šæ¨¡å‹é€‰æ‹©ã€ç½®ä¿¡åº¦é˜ˆå€¼ã€è¯­è¨€è®¾ç½®ã€‚\nä¸»åŒºåŸŸï¼šè¾“å…¥æ–¹å¼é€‰æ‹©ã€å›¾åƒ/è§†é¢‘æ˜¾ç¤ºã€ç»“æœå±•ç¤ºã€‚\nç»“æœé¢æ¿ï¼šæ£€æµ‹ç»Ÿè®¡ã€ä¸‹è½½é€‰é¡¹ã€‚\n\n\n\n\nç¿»è¯‘ç³»ç»Ÿç®¡ç†æ‰€æœ‰çš„ UI å…ƒç´ ï¼š\n\n\nCode\ntranslations = {\n    \"en\": {\n        \"title\": \"YOLO11 Object Detection\",\n        \"upload_file\": \"Upload File\",\n        \"camera_input\": \"Use Camera\",\n        # ... æ›´å¤šå­—æ®µ\n    },\n    \"zh\": {\n        \"title\": \"YOLO11 ç›®æ ‡æ£€æµ‹\",\n        \"upload_file\": \"ä¸Šä¼ æ–‡ä»¶\",\n        \"camera_input\": \"ä½¿ç”¨ç›¸æœº\",\n        # ... å¯¹åº”çš„ä¸­æ–‡ç¿»è¯‘\n    }\n}"
  },
  {
    "objectID": "posts/yolo-app/index.html#æ€§èƒ½ä¼˜åŒ–",
    "href": "posts/yolo-app/index.html#æ€§èƒ½ä¼˜åŒ–",
    "title": "ä½¿ç”¨ Streamlit æ„å»ºçš„ YOLO ç›®æ ‡æ£€æµ‹åº”ç”¨",
    "section": "",
    "text": "æ¨¡å‹\nå‚æ•°é‡\nmAP\næ¨ç†æ—¶é—´ (CPU)\næ¨ç†æ—¶é—´ (MPS)\n\n\n\n\nYOLO11n\n2.6M\n37.2\n15ms\n3ms\n\n\nYOLO11s\n9.4M\n45.5\n28ms\n6ms\n\n\nYOLO11m\n25.4M\n51.2\n52ms\n12ms\n\n\nYOLO11l\n43.7M\n53.4\n84ms\n18ms\n\n\nYOLO11x\n68.2M\n54.7\n126ms\n26ms\n\n\n\n\n\n\nè¯¥åº”ç”¨ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶åœ¨ Apple Silicon è®¾å¤‡ä¸Šåˆ©ç”¨ Metal Performance Shaders (MPS)ï¼š\n\n\nCode\ndevice = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\nmodel = YOLO(selected_model).to(device)\n\n# æ€§èƒ½ç›‘æ§\nimport time\nstart_time = time.time()\nresults = model.predict(image)\ninference_time = (time.time() - start_time) * 1000\n\nst.metric(f\"æ¨ç†æ—¶é—´ ({device.upper()})\", f\"{inference_time:.1f}ms\")\n\n\n\n\n\nä¸ºäº†æ»¡è¶³ API çš„å¤§å°é™åˆ¶ï¼Œåº”ç”¨å®ç°äº†æ™ºèƒ½å›¾åƒå‹ç¼©ï¼š\n\n\nCode\ndef compress_image_for_api(image, max_size=8*1024*1024):\n    \"\"\"å‹ç¼©å›¾åƒä»¥æ»¡è¶³ API è¦æ±‚\"\"\"\n    for quality in [95, 85, 75, 65]:\n        for fmt in [\"JPEG\", \"WEBP\"]:\n            buffer = BytesIO()\n            image.save(buffer, format=fmt, quality=quality)\n            if buffer.tell() &lt;= max_size:\n                return buffer.getvalue()\n    return None"
  },
  {
    "objectID": "posts/yolo-app/index.html#éƒ¨ç½²ä¸ç”Ÿäº§ç‰¹æ€§",
    "href": "posts/yolo-app/index.html#éƒ¨ç½²ä¸ç”Ÿäº§ç‰¹æ€§",
    "title": "ä½¿ç”¨ Streamlit æ„å»ºçš„ YOLO ç›®æ ‡æ£€æµ‹åº”ç”¨",
    "section": "",
    "text": "åº”ç”¨ç¨‹åºç»´æŠ¤ç€å…¨é¢çš„ä¼šè¯çŠ¶æ€ï¼š\n\n\nCode\nsession_state_vars = [\n    \"current_image\", \"uploaded_image_bytes\",\n    \"current_video\", \"uploaded_video_bytes\",\n    \"camera_active\", \"camera_frame\",\n    \"qwen_processed\", \"gemini_processed\",\n    \"language\", \"input_method_index\"\n]\n\n\n\n\n\nå¥å£®çš„é”™è¯¯å¤„ç†ç¡®ä¿äº†ä¼˜é›…çš„é™çº§æœåŠ¡ï¼š\n\n\nCode\ntry:\n    result = model.predict(image, conf=confidence_threshold)\n    st.success(get_translation(\"detection_success\"))\nexcept Exception as e:\n    st.error(f\"æ£€æµ‹å¤±è´¥: {str(e)}\")\n    # å›é€€è‡³å¤‡é€‰å¤„ç†æ–¹æ³•"
  },
  {
    "objectID": "posts/yolo-app/index.html#å¿«é€Ÿå¼€å§‹",
    "href": "posts/yolo-app/index.html#å¿«é€Ÿå¼€å§‹",
    "title": "ä½¿ç”¨ Streamlit æ„å»ºçš„ YOLO ç›®æ ‡æ£€æµ‹åº”ç”¨",
    "section": "",
    "text": "Python 3.12 æˆ–æ›´é«˜ç‰ˆæœ¬\nç°ä»£åŒ…ç®¡ç†å™¨ï¼ˆæ¨èä½¿ç”¨ uvï¼‰\nå¯¹äºäº‘ç«¯æ¨¡å‹ï¼šéœ€è¦ DashScope å’Œ OpenRouter çš„ API å¯†é’¥\n\n\n\n\n# å…‹éš†ä»“åº“\ngit clone &lt;repository-url&gt;\ncd YOLO_app\n\n# ä½¿ç”¨ uv åŒæ­¥ä¾èµ–ï¼ˆæ¨èï¼‰\nuv sync\n\n# å¤‡é€‰ï¼šä½¿ç”¨ pip å®‰è£…\npip install -r requirements.txt\n\n# è¿è¡Œåº”ç”¨\nstreamlit run app.py\n\n\n\nåˆ›å»ºä¸€ä¸ªåŒ…å« API å¯†é’¥çš„ .env æ–‡ä»¶ï¼š\n# é˜¿é‡Œäº‘ DashScope API\nDASHSCOPE_API_KEY=æ‚¨çš„å¯†é’¥\n\n# OpenRouter API (ç”¨äº Gemini)\nOPENROUTER_API_KEY=æ‚¨çš„å¯†é’¥\n\n\n\n\n\n\nå¯åŠ¨åº”ç”¨ç¨‹åºã€‚\nä¸Šä¼ å›¾åƒæˆ–æä¾›å›¾åƒ URLã€‚\né€‰æ‹©æ‚¨åå¥½çš„ YOLO11 æ¨¡å‹ï¼ˆæ¨èä½¿ç”¨ yolo11s.ptï¼‰ã€‚\næ ¹æ®éœ€è¦è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼ã€‚\nç‚¹å‡»â€œå¼€å§‹æ£€æµ‹â€ã€‚\næŸ¥çœ‹ç»“æœå¹¶ä¸‹è½½æ ‡æ³¨åçš„å›¾åƒã€‚\n\n\n\n\n\né€‰æ‹©â€œä½¿ç”¨ç›¸æœºâ€è¾“å…¥æ–¹å¼ã€‚\nåœ¨æç¤ºæ—¶æˆäºˆç›¸æœºæƒé™ã€‚\næ‹æ‘„ç…§ç‰‡ã€‚\né€‰æ‹©æ£€æµ‹æ¨¡å‹ã€‚\nè·å–å³æ—¶çš„ç›®æ ‡æ£€æµ‹ç»“æœã€‚\n\n\n\n\n\nåœ¨ä¾§è¾¹æ è¾“å…¥æ‚¨çš„ API å¯†é’¥ã€‚\nä¸Šä¼ å›¾åƒã€‚\né€‰æ‹© â€œQwen-Image-Editâ€ æˆ– â€œGemini 2.5 Flashâ€ æ¨¡å‹ã€‚\nåˆ©ç”¨å…ˆè¿›çš„ AI èƒ½åŠ›å¤„ç†å›¾åƒã€‚\nå°†ç»“æœä¸æœ¬åœ° YOLO æ¨¡å‹è¿›è¡Œå¯¹æ¯”ã€‚"
  },
  {
    "objectID": "posts/yolo-app/index.html#æœªæ¥å¢å¼ºæ–¹å‘",
    "href": "posts/yolo-app/index.html#æœªæ¥å¢å¼ºæ–¹å‘",
    "title": "ä½¿ç”¨ Streamlit æ„å»ºçš„ YOLO ç›®æ ‡æ£€æµ‹åº”ç”¨",
    "section": "",
    "text": "æœªæ¥ç‰ˆæœ¬çš„æ½œåœ¨æ”¹è¿›ç‚¹ï¼š\n\næ›´å¤šæ¨¡å‹ï¼šé›†æˆæ›´å¤šçš„äº‘ç«¯ AI æœåŠ¡ã€‚\nå®æ—¶è§†é¢‘å¤„ç†ï¼šå¢å¼ºè§†é¢‘æµå¤„ç†èƒ½åŠ›ã€‚\nè‡ªå®šä¹‰æ¨¡å‹è®­ç»ƒï¼šå…è®¸ç”¨æˆ·è®­ç»ƒè‡ªå®šä¹‰ YOLO æ¨¡å‹ã€‚\nç§»åŠ¨ç«¯ä¼˜åŒ–ï¼šä¸ºç§»åŠ¨è®¾å¤‡æ”¯æŒæä¾› PWA ç‰¹æ€§ã€‚\næ‰¹é‡å¤„ç†ï¼šåŒæ—¶å¤„ç†å¤šå¼ å›¾åƒã€‚"
  },
  {
    "objectID": "posts/yolo-app/index.html#ç»“è®º",
    "href": "posts/yolo-app/index.html#ç»“è®º",
    "title": "ä½¿ç”¨ Streamlit æ„å»ºçš„ YOLO ç›®æ ‡æ£€æµ‹åº”ç”¨",
    "section": "",
    "text": "è¿™æ¬¾ YOLO ç›®æ ‡æ£€æµ‹åº”ç”¨å±•ç¤ºäº†å¦‚ä½•æ„å»ºä¸€ä¸ªå¤æ‚çš„ã€ç”Ÿäº§çº§åˆ«çš„è®¡ç®—æœºè§†è§‰ç³»ç»Ÿã€‚æœ¬åœ°å’Œäº‘ç«¯æ¨¡å‹çš„ç»“åˆã€åŒè¯­æ”¯æŒä»¥åŠå…¨é¢çš„é”™è¯¯å¤„ç†ï¼Œä½¿å…¶ä¸ä»…é€‚ç”¨äºå¼€å‘ç¯å¢ƒï¼Œä¹Ÿé€‚ç”¨äºç”Ÿäº§ç¯å¢ƒã€‚\nè¯¥é¡¹ç›®å±•ç¤ºäº†ä»¥ä¸‹æ–¹é¢çš„æœ€ä½³å®è·µï¼š - ä½¿ç”¨ç°ä»£åŒ…ç®¡ç†å·¥å…·è¿›è¡Œ Python å¼€å‘ã€‚ - Streamlit Web åº”ç”¨ç¨‹åºæ¶æ„ã€‚ - è®¡ç®—æœºè§†è§‰ API é›†æˆã€‚ - å›½é™…åŒ–ä¸å¯è®¿é—®æ€§ã€‚ - é’ˆå¯¹ä¸åŒç¡¬ä»¶å¹³å°çš„æ€§èƒ½ä¼˜åŒ–ã€‚\næ— è®ºæ‚¨æ˜¯å¯¹è®¡ç®—æœºè§†è§‰ã€Web å¼€å‘è¿˜æ˜¯ AI åº”ç”¨æ„Ÿå…´è¶£ï¼Œæœ¬é¡¹ç›®éƒ½ä¸ºæ‚¨æä¾›äº†ä¸€ä¸ªæ„å»ºå…ˆè¿› AI é©±åŠ¨ Web åº”ç”¨çš„åšå®åŸºç¡€ã€‚"
  },
  {
    "objectID": "posts/weight-tracking/index.html",
    "href": "posts/weight-tracking/index.html",
    "title": "ç»“åˆ AI åˆ†æçš„ Shiny å’Œ Streamlit ä½“é‡è¿½è¸ªçœ‹æ¿",
    "section": "",
    "text": "ä½“é‡è¿½è¸ªåº”ç”¨æ˜¯ä¸€æ¬¾å…¨é¢çš„ R Shiny Web åº”ç”¨ç¨‹åºï¼Œå¯å¸®åŠ©ç”¨æˆ·ç›‘æµ‹ä½“é‡è¶‹åŠ¿ã€è®¡ç®— BMIï¼Œå¹¶è·å¾—åŸºäº AI çš„ä¸ªæ€§åŒ–å¥åº·å»ºè®®ã€‚æœ¬é¡¹ç›®çš„ä¸€ä¸ªç‰¹åˆ«ä¹‹å¤„åœ¨äºå®ƒé›†æˆäº†å¤šä¸ª AI æœåŠ¡å•†ï¼Œå¹¶å…·å¤‡å®æ—¶æ•°æ®åŒæ­¥åŠŸèƒ½ã€‚\nåœ¨çº¿æ¼”ç¤º: https://jcflyingco.shinyapps.io/weight_tracking/\nGithub: https://github.com/JCwinning/weight_tracking\n\nä½“é‡è¶‹åŠ¿å›¾AI åé¦ˆ\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nä½“é‡è¿½è¸ªï¼šäº¤äº’å¼çš„ä½“é‡è®°å½•å’Œéšæ—¶é—´å˜åŒ–çš„å¯è§†åŒ–ã€‚\nBMI è®¡ç®—å™¨ï¼šè‡ªåŠ¨è®¡ç®— BMI å¹¶ä¸å¥åº·èŒƒå›´è¿›è¡Œå¯¹æ¯”ã€‚\nå•ä½è½¬æ¢ï¼šåœ¨å…¬åˆ¶ï¼ˆkg/cmï¼‰å’Œè‹±åˆ¶ï¼ˆç£…/è‹±å¯¸ï¼‰ä¹‹é—´æ— ç¼åˆ‡æ¢ã€‚\nå®æ—¶æ›´æ–°ï¼šå½“ä¿®æ”¹ Excel æ–‡ä»¶æ—¶ï¼Œæ•°æ®ä¼šè‡ªåŠ¨åˆ·æ–°ã€‚\n\n\n\n\n\nå¤šæœåŠ¡å•† AI é›†æˆï¼šæ”¯æŒ Modelscopeã€OpenRouterã€Gemini å’Œ OpenAI å…¼å®¹çš„ APIã€‚\nå®Œå–„çš„å›½é™…åŒ–ï¼šå®Œæ•´çš„è‹±æ–‡/ä¸­æ–‡åŒè¯­æ”¯æŒï¼ŒåŒ…å« 50+ ä¸ªç¿»è¯‘å­—æ®µã€‚\nå®æ—¶æ–‡ä»¶ç›‘æ§ï¼šå½“æ•°æ®æ–‡ä»¶å‘ç”Ÿå˜åŒ–æ—¶ï¼ŒUI ä¼šè‡ªåŠ¨æ›´æ–°ã€‚\näº¤äº’å¼å¯è§†åŒ–ï¼šå…·å¤‡ç¼©æ”¾ã€å¹³ç§»å’Œæ‚¬åœåŠŸèƒ½çš„ Plotly å›¾è¡¨ã€‚\næ•°æ®ç®¡ç†ï¼šæ”¯æŒ Excel å¯¼å…¥/å¯¼å‡ºï¼Œå¹¶å…·å¤‡å“åº”å¼æ•°æ®æ›´æ–°ã€‚\n\n\n\n\n\n\n\n\n\n\n\n\n ä½“é‡è¿½è¸ªåº”ç”¨æ¶æ„ \n\n\n\n\n\n\nä¸»è¦æ¡†æ¶ï¼šR Shinyï¼ˆç»å…¸æ¶æ„ï¼‰\nUI ç»„ä»¶ï¼šåŸºäº Bootstrap çš„å“åº”å¼è®¾è®¡ï¼Œä½¿ç”¨ bslib\næ•°æ®å¤„ç†ï¼štidyverse, readxl, openxlsx\nå¯è§†åŒ–ï¼šä½¿ç”¨ plotly å®ç°äº¤äº’å¼å›¾è¡¨\nAI é›†æˆï¼šä½¿ç”¨ ellmer æ”¯æŒå¤šæœåŠ¡å•† AI\n\n\n\n\nweight_tracking/\nâ”œâ”€â”€ ui.R              # åŒ…å«æ§ä»¶çš„å¤šæ ‡ç­¾ç•Œé¢\nâ”œâ”€â”€ server.R          # æœåŠ¡å™¨é€»è¾‘å’Œæ•°æ®ç®¡ç†\nâ”œâ”€â”€ global.R          # URL ä¹¦ç­¾é…ç½®\nâ”œâ”€â”€ ai_config.R       # ç»Ÿä¸€çš„ AI æœåŠ¡å•†ç®¡ç†\nâ”œâ”€â”€ language.R        # å®Œæ•´çš„å›½é™…åŒ–ç³»ç»Ÿ\nâ”œâ”€â”€ weight.xlsx       # ä¸»è¦æ•°æ®å­˜å‚¨\nâ”œâ”€â”€ www/logo.png      # åº”ç”¨å“ç‰Œæ ‡è¯†\nâ””â”€â”€ images/           # åº”ç”¨æˆªå›¾\n\n\n\n\nè¯¥åº”ç”¨å®ç°äº†ä¸€å¥—ç²¾è‡´çš„æ•°æ®å¤„ç†æµç¨‹ï¼Œç¡®ä¿äº†å®æ—¶åŒæ­¥å’Œé«˜æ•ˆçš„æ•°æ®å¤„ç†ã€‚\n\n\n\n\n\n\n\n\n\n æ•°æ®å¤„ç†å·¥ä½œæµ \n\n\n\n\n\n\nåº”ç”¨ä½¿ç”¨ reactivePoll() æ¥ç›‘æ§ Excel æ•°æ®æ–‡ä»¶çš„æ›´æ”¹ï¼š\n\n\nCode\n# å®æ—¶æ•°æ®ç›‘æ§ï¼Œé—´éš”ä¸º 1000ms\nweight_data &lt;- reactivePoll(\n  intervalMillis = 1000,\n  session = session,\n  checkFunc = function() {\n    # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´\n    if (file.exists(\"weight.xlsx\")) {\n      file.info(\"weight.xlsx\")$mtime\n    } else {\n      0\n    }\n  },\n  valueFunc = function() {\n    # è¯»å–å¹¶å¤„ç† Excel æ–‡ä»¶\n    if (file.exists(\"weight.xlsx\")) {\n      data &lt;- read_excel(\"weight.xlsx\") %&gt;%\n        mutate(\n          Date = anytime(Date),\n          BMI = case_when(\n            Unit == \"kg\" ~ Weight / (Height/100)^2,\n            Unit == \"pound\" ~ (Weight * 0.453592) / ((Height * 2.54)/100)^2\n          )\n        )\n      return(data)\n    }\n    return(data.frame())\n  }\n)\n\n\n\n\n\nåº”ç”¨å®ç°äº†åŒ…å«å•ä½è½¬æ¢çš„å…¨é¢ BMI è®¡ç®—ï¼š\n\n\n\n\n\nBMI èŒƒå›´\nç±»åˆ«\nå¥åº·é£é™©\né¢œè‰²ä»£ç \n\n\n\n\n&lt; 18.5\nä½“é‡è¿‡è½»\nä¸­åº¦é£é™©\né»„è‰²\n\n\n18.5 - 24.9\nä½“é‡æ­£å¸¸\né£é™©æœ€å°\nç»¿è‰²\n\n\n25.0 - 29.9\nè¶…é‡\né£é™©å¢åŠ \næ©™è‰²\n\n\nâ‰¥ 30.0\nè‚¥èƒ–\né«˜é£é™©\nçº¢è‰²\n\n\n\n\n\n\n\n\nCode\n# å…¬åˆ¶å’Œè‹±åˆ¶å•ä½çš„ BMI è®¡ç®—\ncalculate_bmi &lt;- function(weight, height, unit) {\n  if (unit == \"kg\") {\n    # å…¬åˆ¶è®¡ç®—\n    bmi &lt;- weight / ((height/100)^2)\n  } else {\n    # è‹±åˆ¶è®¡ç®—å¹¶è½¬æ¢\n    weight_kg &lt;- weight * 0.453592  # ç£…è½¬æ¢ä¸ºåƒå…‹\n    height_m &lt;- height * 2.54 / 100  # è‹±å¯¸è½¬æ¢ä¸ºç±³\n    bmi &lt;- weight_kg / (height_m^2)\n  }\n\n  # BMI åˆ†ç±»\n  category &lt;- case_when(\n    bmi &lt; 18.5 ~ \"underweight\",\n    bmi &lt; 25 ~ \"normal\",\n    bmi &lt; 30 ~ \"overweight\",\n    TRUE ~ \"obese\"\n  )\n\n  return(list(bmi = round(bmi, 1), category = category))\n}\n\n\n\n\n\n\n\n\n\nåº”ç”¨æ”¯æŒå¤šä¸ª AI æœåŠ¡å•†ï¼Œå¹¶å¯åŠ¨æ€åˆ‡æ¢ï¼š\n\n\nCode\n# AI æœåŠ¡å•†é…ç½®\nai_providers &lt;- list(\n  modelscope = list(\n    provider_url = \"https://api-inference.modelscope.cn/v1\",\n    models = c(\"zhipuAI/GLM-4.6\", \"Qwen/Qwen3-Next-80B-A3B-Instruct\")\n  ),\n  openrouter = list(\n    provider_url = \"https://openrouter.ai/api/v1\",\n    models = c(\"openai/gpt-oss-120b:exacto\", \"minimax/minimax-m2:free\")\n  ),\n  Gemini = list(\n    provider_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\",\n    models = c(\"gemini-2.5-flash\", \"gemini-2.5-pro\")\n  )\n)\n\n# åŠ¨æ€æœåŠ¡å•†é€‰æ‹©\nobserveEvent(input$ai_provider, {\n  set_current_provider(input$ai_provider)\n  updateSelectInput(session, \"ai_model\",\n                    choices = get_provider_models(input$ai_provider))\n})\n\n\n\n\n\nAI æ ¹æ®ä½“é‡è¶‹åŠ¿ç”Ÿæˆä¸ªæ€§åŒ–å¥åº·å»ºè®®ï¼š\n\n\nCode\n# AI å»ºè®®ç”Ÿæˆ\nget_ai_suggestion &lt;- function(weight_data, api_key, model, provider) {\n  # å‡†å¤‡ AI åˆ†ææ•°æ®\n  recent_trend &lt;- analyze_weight_trend(weight_data)\n  current_bmi &lt;- get_current_bmi(weight_data)\n\n  # åˆ›å»ºç‰¹å®šè¯­è¨€çš„æç¤ºè¯\n  prompt &lt;- if (current_language == \"zh\") {\n    paste(\"åŸºäºä»¥ä¸‹ä½“é‡æ•°æ®åˆ†æï¼Œè¯·æä¾›ä¸ªæ€§åŒ–çš„å¥åº·å»ºè®®ï¼š\",\n          \"æœ€è¿‘ä½“é‡è¶‹åŠ¿ï¼š\", recent_trend,\n          \"å½“å‰BMIï¼š\", current_bmi,\n          \"è¯·ç”¨ä¸­æ–‡å›å¤ï¼ŒåŒ…å«å…·ä½“çš„é¥®é£Ÿå’Œè¿åŠ¨å»ºè®®ã€‚\")\n  } else {\n    paste(\"Based on the following weight data analysis, please provide personalized health advice:\",\n          \"Recent weight trend:\", recent_trend,\n          \"Current BMI:\", current_bmi,\n          \"Please respond in English with specific diet and exercise recommendations.\")\n  }\n\n  # è°ƒç”¨é€‰å®šæœåŠ¡å•†çš„ API\n  response &lt;- ellmer::chat_completion(\n    model = model,\n    messages = list(\n      list(role = \"user\", content = prompt)\n    ),\n    api_key = api_key,\n    base_url = get_provider_url(provider)\n  )\n\n  return(response$choices[[1]]$message$content)\n}\n\n\n\n\n\n\n\n\n\n\nCode\n# åŸºäºæ ‡ç­¾é¡µçš„ç•Œé¢ç»„ç»‡\nmainPanel(\n  tabsetPanel(\n    tabPanel(get_text(\"plot_tab\"),\n             # ä½“é‡å’Œ BMI å›¾è¡¨\n             fluidRow(\n               column(6, plotlyOutput(\"weight_plot\")),\n               column(6, plotlyOutput(\"bmi_plot\"))\n             )\n    ),\n    tabPanel(get_text(\"ui_tab\"),\n             # åŒ…å«è¯­æ³•é«˜äº®çš„ UI ä»£ç æŸ¥çœ‹å™¨\n             verbatimTextOutput(\"ui_code\")\n    ),\n    tabPanel(get_text(\"server_tab\"),\n             # Server ä»£ç æŸ¥çœ‹å™¨\n             verbatimTextOutput(\"server_code\")\n    ),\n    tabPanel(get_text(\"data_tab\"),\n             # äº¤äº’å¼æ•°æ®è¡¨æ ¼\n             DT::dataTableOutput(\"data_table\")\n    )\n  )\n)\n\n\n\n\n\nå®Œå–„çš„åŒè¯­æ”¯æŒï¼Œå…·å¤‡åŠ¨æ€è¯­è¨€åˆ‡æ¢åŠŸèƒ½ï¼š\n\n\nCode\n# è¯­è¨€ç¿»è¯‘ç³»ç»Ÿ\ntranslations &lt;- list(\n  en = list(\n    app_title = \"Weight tracking\",\n    your_weight = \"Your weight:\",\n    your_bmi = \"Your BMI:\",\n    get_ai_suggestion = \"Get AI Suggestion\"\n    # ... æ›´å¤šç¿»è¯‘\n  ),\n  zh = list(\n    app_title = \"ä½“é‡è¿½è¸ª\",\n    your_weight = \"æ‚¨çš„ä½“é‡:\",\n    your_bmi = \"æ‚¨çš„BMI:\",\n    get_ai_suggestion = \"è·å–AIå»ºè®®\"\n    # ... æ›´å¤šç¿»è¯‘\n  )\n)\n\n# è¯­è¨€åˆ‡æ¢å¤„ç†å™¨\nobserveEvent(input$lang_en, {\n  current_lang(\"en\")\n  set_language(\"en\")\n  updateUI()  # è§¦å‘ UI æ›´æ–°\n})\n\n\n\n\n\n\n\n\nåº”ç”¨å…·å¤‡å¸¦å¥åº·æŒ‡æ ‡çš„åŠ¨æ€å›¾è¡¨ï¼š\n\n\nCode\n# å¸¦å¥åº·èŒƒå›´çš„ BMI å›¾è¡¨\noutput$bmi_plot &lt;- renderPlotly({\n  data &lt;- weight_data()\n\n  plot_ly(data, x = ~Date, y = ~BMI, type = 'scatter', mode = 'lines+markers',\n          name = get_text(\"chart_bmi_legend\"),\n          line = list(color = 'blue', width = 3),\n          marker = list(size = 8)) %&gt;%\n    # æ·»åŠ å¥åº·èŒƒå›´å¸¦\n    add_trace(y = rep(18.5, nrow(data)), mode = 'lines',\n              line = list(color = 'green', dash = 'dash'), name = \"ç†æƒ³èŒƒå›´èµ·ç‚¹\") %&gt;%\n    add_trace(y = rep(24.9, nrow(data)), mode = 'lines',\n              line = list(color = 'red', dash = 'dash'), name = \"ç†æƒ³èŒƒå›´ç»ˆç‚¹\") %&gt;%\n    layout(\n      title = get_text(\"chart_bmi_title\"),\n      xaxis = list(title = \"æ—¥æœŸ\"),\n      yaxis = list(title = \"BMI\", range = c(15, 35)),\n      hovermode = 'x unified'\n    )\n})\n\n\n\n\n\n\n\n\nåº”ç”¨å·²éƒ¨ç½²å¹¶å¯é€šè¿‡ä»¥ä¸‹é“¾æ¥è®¿é—®ï¼š https://jcflyingco.shinyapps.io/weight-tracking/\n\n\n\n\n\nCode\n# åœ¨ global.R ä¸­å¯ç”¨ URL ä¹¦ç­¾\nshinyServer(\n  function(input, output, session) {\n    # ä¹¦ç­¾é…ç½®\n    enableBookmarking(\"url\")\n\n    # ä¿å­˜/æ¢å¤ UI çŠ¶æ€\n    setBookmarkExclude(c(\"lang_en\", \"lang_zh\"))  # æ’é™¤è¯­è¨€æŒ‰é’®\n  }\n)\n\n\n\n\n\n\n\n\nåº”ç”¨å®ç°äº†é«˜æ•ˆçš„å“åº”å¼ç¼–ç¨‹ï¼š\n\n\nCode\n# é«˜æ•ˆçš„å¸¦ç¼“å­˜æ•°æ®å¤„ç†\nprocessed_data &lt;- reactive({\n  data &lt;- weight_data()\n  if (nrow(data) == 0) return(NULL)\n\n  # ä»…è®¡ç®—ä¸€æ¬¡æ´¾ç”ŸæŒ‡æ ‡\n  data %&gt;%\n    mutate(\n      Weight_Change = c(NA, diff(Weight)),\n      BMI_Category = case_when(\n        BMI &lt; 18.5 ~ \"underweight\",\n        BMI &lt; 25 ~ \"normal\",\n        BMI &lt; 30 ~ \"overweight\",\n        TRUE ~ \"obese\"\n      ),\n      Date_Formatted = format(Date, \"%Y-%m-%d\")\n    )\n})\n\n# ç”¨äºå¤šä¸ªè¾“å‡ºçš„å…±äº«è®¡ç®—\ncurrent_stats &lt;- reactive({\n  data &lt;- processed_data()\n  if (is.null(data) || nrow(data) == 0) return(NULL)\n\n  list(\n    last_weight = tail(data$Weight, 1),\n    last_bmi = tail(data$BMI, 1),\n    trend = calculate_trend(data$Weight),\n    days_tracked = nrow(data)\n  )\n})\n\n\n\n\n\n\n\n\n\n\nCode\n# å®‰å…¨çš„ API å¯†é’¥å¤„ç†ï¼ˆä»…é™ä¼šè¯å­˜å‚¨ï¼‰\nobserveEvent(input$get_ai_suggestion, {\n  if (is.null(input$api_key) || input$api_key == \"\") {\n    showNotification(get_text(\"please_provide_api_key\"), type = \"error\")\n    return()\n  }\n\n  # ä½¿ç”¨ä¼šè¯ä¸­çš„ API å¯†é’¥ï¼ˆä¸æŒä¹…åŒ–ï¼‰\n  withBusyIndicator(\"æ­£åœ¨è·å– AI å»ºè®®...\", {\n    suggestion &lt;- get_ai_suggestion(\n      weight_data = weight_data(),\n      api_key = input$api_key,\n      model = input$ai_model,\n      provider = input$ai_provider\n    )\n\n    output$ai_response &lt;- renderUI({\n      div(class = \"markdown-content\",\n          HTML(markdown::renderMarkdown(suggestion))\n      )\n    })\n  })\n})\n\n\n\n\n\n\n\nCode\n# å…¨é¢çš„é”™è¯¯å¤„ç†\nget_ai_suggestion &lt;- function(...) {\n  tryCatch({\n    # API è°ƒç”¨é€»è¾‘\n    response &lt;- ellmer::chat_completion(...)\n    return(response$choices[[1]]$message$content)\n  }, error = function(e) {\n    # é”™è¯¯æ—¥å¿—è®°å½•å’Œç”¨æˆ·åé¦ˆ\n    log_error(paste(\"AI API é”™è¯¯:\", e$message))\n    return(get_text(\"ai_error_check_config\"))\n  })\n}\n\n\n\n\n\n\n\n\n\nåœ¨æµè§ˆå™¨ä¸­æ‰“å¼€åº”ç”¨ç¨‹åºã€‚\næŸ¥çœ‹å½“å‰ä½“é‡è¶‹åŠ¿å›¾å’Œ BMI å›¾è¡¨ã€‚\né€šè¿‡ Excel ä¸Šä¼ æ·»åŠ æ–°çš„ä½“é‡æ•°æ®ã€‚\nè·å– AI é©±åŠ¨çš„å¥åº·å»ºè®®ã€‚\nä¸‹è½½æ›´æ–°åçš„æ•°æ®ä¾›ç¦»çº¿ä½¿ç”¨ã€‚\n\n\n\n\n\nä½¿ç”¨å³ä¸Šè§’çš„æŒ‰é’®åœ¨ EN/ä¸­æ–‡ ä¹‹é—´åˆ‡æ¢ã€‚\næ‰€æœ‰ UI å…ƒç´ åŠ¨æ€æ›´æ–°ã€‚\nAI æç¤ºè¯é€‚é…æ‰€é€‰è¯­è¨€ã€‚\nå›¾è¡¨å’Œæ•°æ®ä¿æŒè¯­å¢ƒä¸€è‡´ã€‚\n\n\n\n\n\n\n\n\nå®æ—¶ Excel åŒæ­¥ï¼šæ•°æ®æ›´æ”¹æ—¶ UI è‡ªåŠ¨æ›´æ–°ã€‚\nå¤šæœåŠ¡å•† AI é›†æˆï¼šçµæ´»çš„ AI æœåŠ¡å•†åˆ‡æ¢ã€‚\nå®Œå–„çš„å›½é™…åŒ–ï¼šå®Œæ•´çš„åŒè¯­æ”¯æŒã€‚\nä¸“ä¸š UI è®¾è®¡ï¼šåŸºäº Bootstrap çš„å“åº”å¼å¸ƒå±€ã€‚\näº¤äº’å¼å¯è§†åŒ–ï¼šå¯ç¼©æ”¾ã€å¯æ‚¬åœçš„ Plotly å›¾è¡¨ã€‚\n\n\n\n\n\næ•°æ®åˆ·æ–°ï¼š1 ç§’è½®è¯¢é—´éš”ã€‚\nå›¾è¡¨æ¸²æŸ“ï¼šå…¸å‹æ•°æ®é›†æ¸²æŸ“æ—¶é—´ &lt; 100msã€‚\nAPI å“åº”ï¼šAI å»ºè®®å“åº”æ—¶é—´ä¸º 2-5 ç§’ã€‚\nå†…å­˜å ç”¨ï¼š1000+ æ¡è®°å½•ä¸‹å†…å­˜å ç”¨ &lt; 50MBã€‚\n\n\n\n\n\nä¸‹ä¸€ç‰ˆæœ¬çš„æ½œåœ¨æ”¹è¿›ç‚¹ï¼š\n\næ•°æ®åº“é›†æˆï¼šå°† Excel æ›¿æ¢ä¸º SQLite/PostgreSQLã€‚\nç”¨æˆ·è®¤è¯ï¼šæ”¯æŒå¤šç”¨æˆ·ï¼Œå®ç°ä¸ªäººæ•°æ®éš”ç¦»ã€‚\nç§»åŠ¨ç«¯ä¼˜åŒ–ï¼šä¸ºç§»åŠ¨è®¾å¤‡æä¾› PWA ç‰¹æ€§ã€‚\né«˜çº§åˆ†æï¼šä½¿ç”¨æ—¶é—´åºåˆ—æ„å»ºä½“é‡é¢„æµ‹æ¨¡å‹ã€‚\né›†æˆ APIï¼šè¿æ¥å¥èº«è¿½è¸ªå™¨å’Œå¥åº·åº”ç”¨ã€‚\n\n\n\n\nè¿™æ¬¾ä½“é‡è¿½è¸ªåº”ç”¨å±•ç¤ºäº†å°† R Shiny çš„å“åº”å¼ç¼–ç¨‹ä¸ç°ä»£ AI æŠ€æœ¯ç›¸ç»“åˆçš„å¼ºå¤§åŠ›é‡ã€‚é¡¹ç›®å±•ç¤ºäº†ï¼š\n\nç²¾ç»†çš„æ•°æ®ç®¡ç†ï¼šå®æ—¶æ–‡ä»¶ç›‘æ§å’Œå“åº”å¼æ›´æ–°ã€‚\nAI é›†æˆï¼šé›†æˆå¤šæœåŠ¡å•†å¹¶æä¾›ä¸ªæ€§åŒ–å¥åº·å»ºè®®ã€‚\nå›½é™…åŒ–ï¼šå®Œæ•´çš„åŒè¯­å®ç°ã€‚\nä¸“ä¸šçš„ UI/UXï¼šç°ä»£å“åº”å¼è®¾è®¡é…åˆäº¤äº’å¼å¯è§†åŒ–ã€‚\n\næ— è®ºæ‚¨æ˜¯å…³æ³¨å¥åº·ç›‘æµ‹ã€æ•°æ®å¯è§†åŒ–ï¼Œè¿˜æ˜¯ AI é›†æˆï¼Œæœ¬é¡¹ç›®éƒ½ä¸ºæ‚¨æä¾›äº†ä¸€ä¸ªä½¿ç”¨ R Shiny æ„å»ºç”Ÿäº§çº§ Web åº”ç”¨çš„ç»ä½³èŒƒä¾‹ã€‚"
  },
  {
    "objectID": "posts/weight-tracking/index.html#æ ¸å¿ƒåŠŸèƒ½",
    "href": "posts/weight-tracking/index.html#æ ¸å¿ƒåŠŸèƒ½",
    "title": "ç»“åˆ AI åˆ†æçš„ Shiny å’Œ Streamlit ä½“é‡è¿½è¸ªçœ‹æ¿",
    "section": "",
    "text": "ä½“é‡è¿½è¸ªï¼šäº¤äº’å¼çš„ä½“é‡è®°å½•å’Œéšæ—¶é—´å˜åŒ–çš„å¯è§†åŒ–ã€‚\nBMI è®¡ç®—å™¨ï¼šè‡ªåŠ¨è®¡ç®— BMI å¹¶ä¸å¥åº·èŒƒå›´è¿›è¡Œå¯¹æ¯”ã€‚\nå•ä½è½¬æ¢ï¼šåœ¨å…¬åˆ¶ï¼ˆkg/cmï¼‰å’Œè‹±åˆ¶ï¼ˆç£…/è‹±å¯¸ï¼‰ä¹‹é—´æ— ç¼åˆ‡æ¢ã€‚\nå®æ—¶æ›´æ–°ï¼šå½“ä¿®æ”¹ Excel æ–‡ä»¶æ—¶ï¼Œæ•°æ®ä¼šè‡ªåŠ¨åˆ·æ–°ã€‚\n\n\n\n\n\nå¤šæœåŠ¡å•† AI é›†æˆï¼šæ”¯æŒ Modelscopeã€OpenRouterã€Gemini å’Œ OpenAI å…¼å®¹çš„ APIã€‚\nå®Œå–„çš„å›½é™…åŒ–ï¼šå®Œæ•´çš„è‹±æ–‡/ä¸­æ–‡åŒè¯­æ”¯æŒï¼ŒåŒ…å« 50+ ä¸ªç¿»è¯‘å­—æ®µã€‚\nå®æ—¶æ–‡ä»¶ç›‘æ§ï¼šå½“æ•°æ®æ–‡ä»¶å‘ç”Ÿå˜åŒ–æ—¶ï¼ŒUI ä¼šè‡ªåŠ¨æ›´æ–°ã€‚\näº¤äº’å¼å¯è§†åŒ–ï¼šå…·å¤‡ç¼©æ”¾ã€å¹³ç§»å’Œæ‚¬åœåŠŸèƒ½çš„ Plotly å›¾è¡¨ã€‚\næ•°æ®ç®¡ç†ï¼šæ”¯æŒ Excel å¯¼å…¥/å¯¼å‡ºï¼Œå¹¶å…·å¤‡å“åº”å¼æ•°æ®æ›´æ–°ã€‚"
  },
  {
    "objectID": "posts/weight-tracking/index.html#æŠ€æœ¯æ¶æ„",
    "href": "posts/weight-tracking/index.html#æŠ€æœ¯æ¶æ„",
    "title": "ç»“åˆ AI åˆ†æçš„ Shiny å’Œ Streamlit ä½“é‡è¿½è¸ªçœ‹æ¿",
    "section": "",
    "text": "ä½“é‡è¿½è¸ªåº”ç”¨æ¶æ„ \n\n\n\n\n\n\nä¸»è¦æ¡†æ¶ï¼šR Shinyï¼ˆç»å…¸æ¶æ„ï¼‰\nUI ç»„ä»¶ï¼šåŸºäº Bootstrap çš„å“åº”å¼è®¾è®¡ï¼Œä½¿ç”¨ bslib\næ•°æ®å¤„ç†ï¼štidyverse, readxl, openxlsx\nå¯è§†åŒ–ï¼šä½¿ç”¨ plotly å®ç°äº¤äº’å¼å›¾è¡¨\nAI é›†æˆï¼šä½¿ç”¨ ellmer æ”¯æŒå¤šæœåŠ¡å•† AI\n\n\n\n\nweight_tracking/\nâ”œâ”€â”€ ui.R              # åŒ…å«æ§ä»¶çš„å¤šæ ‡ç­¾ç•Œé¢\nâ”œâ”€â”€ server.R          # æœåŠ¡å™¨é€»è¾‘å’Œæ•°æ®ç®¡ç†\nâ”œâ”€â”€ global.R          # URL ä¹¦ç­¾é…ç½®\nâ”œâ”€â”€ ai_config.R       # ç»Ÿä¸€çš„ AI æœåŠ¡å•†ç®¡ç†\nâ”œâ”€â”€ language.R        # å®Œæ•´çš„å›½é™…åŒ–ç³»ç»Ÿ\nâ”œâ”€â”€ weight.xlsx       # ä¸»è¦æ•°æ®å­˜å‚¨\nâ”œâ”€â”€ www/logo.png      # åº”ç”¨å“ç‰Œæ ‡è¯†\nâ””â”€â”€ images/           # åº”ç”¨æˆªå›¾"
  },
  {
    "objectID": "posts/weight-tracking/index.html#æ•°æ®ç®¡ç†ç³»ç»Ÿ",
    "href": "posts/weight-tracking/index.html#æ•°æ®ç®¡ç†ç³»ç»Ÿ",
    "title": "ç»“åˆ AI åˆ†æçš„ Shiny å’Œ Streamlit ä½“é‡è¿½è¸ªçœ‹æ¿",
    "section": "",
    "text": "è¯¥åº”ç”¨å®ç°äº†ä¸€å¥—ç²¾è‡´çš„æ•°æ®å¤„ç†æµç¨‹ï¼Œç¡®ä¿äº†å®æ—¶åŒæ­¥å’Œé«˜æ•ˆçš„æ•°æ®å¤„ç†ã€‚\n\n\n\n\n\n\n\n\n\n æ•°æ®å¤„ç†å·¥ä½œæµ \n\n\n\n\n\n\nåº”ç”¨ä½¿ç”¨ reactivePoll() æ¥ç›‘æ§ Excel æ•°æ®æ–‡ä»¶çš„æ›´æ”¹ï¼š\n\n\nCode\n# å®æ—¶æ•°æ®ç›‘æ§ï¼Œé—´éš”ä¸º 1000ms\nweight_data &lt;- reactivePoll(\n  intervalMillis = 1000,\n  session = session,\n  checkFunc = function() {\n    # æ£€æŸ¥æ–‡ä»¶ä¿®æ”¹æ—¶é—´\n    if (file.exists(\"weight.xlsx\")) {\n      file.info(\"weight.xlsx\")$mtime\n    } else {\n      0\n    }\n  },\n  valueFunc = function() {\n    # è¯»å–å¹¶å¤„ç† Excel æ–‡ä»¶\n    if (file.exists(\"weight.xlsx\")) {\n      data &lt;- read_excel(\"weight.xlsx\") %&gt;%\n        mutate(\n          Date = anytime(Date),\n          BMI = case_when(\n            Unit == \"kg\" ~ Weight / (Height/100)^2,\n            Unit == \"pound\" ~ (Weight * 0.453592) / ((Height * 2.54)/100)^2\n          )\n        )\n      return(data)\n    }\n    return(data.frame())\n  }\n)\n\n\n\n\n\nåº”ç”¨å®ç°äº†åŒ…å«å•ä½è½¬æ¢çš„å…¨é¢ BMI è®¡ç®—ï¼š\n\n\n\n\n\nBMI èŒƒå›´\nç±»åˆ«\nå¥åº·é£é™©\né¢œè‰²ä»£ç \n\n\n\n\n&lt; 18.5\nä½“é‡è¿‡è½»\nä¸­åº¦é£é™©\né»„è‰²\n\n\n18.5 - 24.9\nä½“é‡æ­£å¸¸\né£é™©æœ€å°\nç»¿è‰²\n\n\n25.0 - 29.9\nè¶…é‡\né£é™©å¢åŠ \næ©™è‰²\n\n\nâ‰¥ 30.0\nè‚¥èƒ–\né«˜é£é™©\nçº¢è‰²\n\n\n\n\n\n\n\n\nCode\n# å…¬åˆ¶å’Œè‹±åˆ¶å•ä½çš„ BMI è®¡ç®—\ncalculate_bmi &lt;- function(weight, height, unit) {\n  if (unit == \"kg\") {\n    # å…¬åˆ¶è®¡ç®—\n    bmi &lt;- weight / ((height/100)^2)\n  } else {\n    # è‹±åˆ¶è®¡ç®—å¹¶è½¬æ¢\n    weight_kg &lt;- weight * 0.453592  # ç£…è½¬æ¢ä¸ºåƒå…‹\n    height_m &lt;- height * 2.54 / 100  # è‹±å¯¸è½¬æ¢ä¸ºç±³\n    bmi &lt;- weight_kg / (height_m^2)\n  }\n\n  # BMI åˆ†ç±»\n  category &lt;- case_when(\n    bmi &lt; 18.5 ~ \"underweight\",\n    bmi &lt; 25 ~ \"normal\",\n    bmi &lt; 30 ~ \"overweight\",\n    TRUE ~ \"obese\"\n  )\n\n  return(list(bmi = round(bmi, 1), category = category))\n}"
  },
  {
    "objectID": "posts/weight-tracking/index.html#ai-é›†æˆæ¶æ„",
    "href": "posts/weight-tracking/index.html#ai-é›†æˆæ¶æ„",
    "title": "ç»“åˆ AI åˆ†æçš„ Shiny å’Œ Streamlit ä½“é‡è¿½è¸ªçœ‹æ¿",
    "section": "",
    "text": "åº”ç”¨æ”¯æŒå¤šä¸ª AI æœåŠ¡å•†ï¼Œå¹¶å¯åŠ¨æ€åˆ‡æ¢ï¼š\n\n\nCode\n# AI æœåŠ¡å•†é…ç½®\nai_providers &lt;- list(\n  modelscope = list(\n    provider_url = \"https://api-inference.modelscope.cn/v1\",\n    models = c(\"zhipuAI/GLM-4.6\", \"Qwen/Qwen3-Next-80B-A3B-Instruct\")\n  ),\n  openrouter = list(\n    provider_url = \"https://openrouter.ai/api/v1\",\n    models = c(\"openai/gpt-oss-120b:exacto\", \"minimax/minimax-m2:free\")\n  ),\n  Gemini = list(\n    provider_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\",\n    models = c(\"gemini-2.5-flash\", \"gemini-2.5-pro\")\n  )\n)\n\n# åŠ¨æ€æœåŠ¡å•†é€‰æ‹©\nobserveEvent(input$ai_provider, {\n  set_current_provider(input$ai_provider)\n  updateSelectInput(session, \"ai_model\",\n                    choices = get_provider_models(input$ai_provider))\n})\n\n\n\n\n\nAI æ ¹æ®ä½“é‡è¶‹åŠ¿ç”Ÿæˆä¸ªæ€§åŒ–å¥åº·å»ºè®®ï¼š\n\n\nCode\n# AI å»ºè®®ç”Ÿæˆ\nget_ai_suggestion &lt;- function(weight_data, api_key, model, provider) {\n  # å‡†å¤‡ AI åˆ†ææ•°æ®\n  recent_trend &lt;- analyze_weight_trend(weight_data)\n  current_bmi &lt;- get_current_bmi(weight_data)\n\n  # åˆ›å»ºç‰¹å®šè¯­è¨€çš„æç¤ºè¯\n  prompt &lt;- if (current_language == \"zh\") {\n    paste(\"åŸºäºä»¥ä¸‹ä½“é‡æ•°æ®åˆ†æï¼Œè¯·æä¾›ä¸ªæ€§åŒ–çš„å¥åº·å»ºè®®ï¼š\",\n          \"æœ€è¿‘ä½“é‡è¶‹åŠ¿ï¼š\", recent_trend,\n          \"å½“å‰BMIï¼š\", current_bmi,\n          \"è¯·ç”¨ä¸­æ–‡å›å¤ï¼ŒåŒ…å«å…·ä½“çš„é¥®é£Ÿå’Œè¿åŠ¨å»ºè®®ã€‚\")\n  } else {\n    paste(\"Based on the following weight data analysis, please provide personalized health advice:\",\n          \"Recent weight trend:\", recent_trend,\n          \"Current BMI:\", current_bmi,\n          \"Please respond in English with specific diet and exercise recommendations.\")\n  }\n\n  # è°ƒç”¨é€‰å®šæœåŠ¡å•†çš„ API\n  response &lt;- ellmer::chat_completion(\n    model = model,\n    messages = list(\n      list(role = \"user\", content = prompt)\n    ),\n    api_key = api_key,\n    base_url = get_provider_url(provider)\n  )\n\n  return(response$choices[[1]]$message$content)\n}"
  },
  {
    "objectID": "posts/weight-tracking/index.html#ç”¨æˆ·ç•Œé¢è®¾è®¡",
    "href": "posts/weight-tracking/index.html#ç”¨æˆ·ç•Œé¢è®¾è®¡",
    "title": "ç»“åˆ AI åˆ†æçš„ Shiny å’Œ Streamlit ä½“é‡è¿½è¸ªçœ‹æ¿",
    "section": "",
    "text": "Code\n# åŸºäºæ ‡ç­¾é¡µçš„ç•Œé¢ç»„ç»‡\nmainPanel(\n  tabsetPanel(\n    tabPanel(get_text(\"plot_tab\"),\n             # ä½“é‡å’Œ BMI å›¾è¡¨\n             fluidRow(\n               column(6, plotlyOutput(\"weight_plot\")),\n               column(6, plotlyOutput(\"bmi_plot\"))\n             )\n    ),\n    tabPanel(get_text(\"ui_tab\"),\n             # åŒ…å«è¯­æ³•é«˜äº®çš„ UI ä»£ç æŸ¥çœ‹å™¨\n             verbatimTextOutput(\"ui_code\")\n    ),\n    tabPanel(get_text(\"server_tab\"),\n             # Server ä»£ç æŸ¥çœ‹å™¨\n             verbatimTextOutput(\"server_code\")\n    ),\n    tabPanel(get_text(\"data_tab\"),\n             # äº¤äº’å¼æ•°æ®è¡¨æ ¼\n             DT::dataTableOutput(\"data_table\")\n    )\n  )\n)\n\n\n\n\n\nå®Œå–„çš„åŒè¯­æ”¯æŒï¼Œå…·å¤‡åŠ¨æ€è¯­è¨€åˆ‡æ¢åŠŸèƒ½ï¼š\n\n\nCode\n# è¯­è¨€ç¿»è¯‘ç³»ç»Ÿ\ntranslations &lt;- list(\n  en = list(\n    app_title = \"Weight tracking\",\n    your_weight = \"Your weight:\",\n    your_bmi = \"Your BMI:\",\n    get_ai_suggestion = \"Get AI Suggestion\"\n    # ... æ›´å¤šç¿»è¯‘\n  ),\n  zh = list(\n    app_title = \"ä½“é‡è¿½è¸ª\",\n    your_weight = \"æ‚¨çš„ä½“é‡:\",\n    your_bmi = \"æ‚¨çš„BMI:\",\n    get_ai_suggestion = \"è·å–AIå»ºè®®\"\n    # ... æ›´å¤šç¿»è¯‘\n  )\n)\n\n# è¯­è¨€åˆ‡æ¢å¤„ç†å™¨\nobserveEvent(input$lang_en, {\n  current_lang(\"en\")\n  set_language(\"en\")\n  updateUI()  # è§¦å‘ UI æ›´æ–°\n})"
  },
  {
    "objectID": "posts/weight-tracking/index.html#æ•°æ®å¯è§†åŒ–",
    "href": "posts/weight-tracking/index.html#æ•°æ®å¯è§†åŒ–",
    "title": "ç»“åˆ AI åˆ†æçš„ Shiny å’Œ Streamlit ä½“é‡è¿½è¸ªçœ‹æ¿",
    "section": "",
    "text": "åº”ç”¨å…·å¤‡å¸¦å¥åº·æŒ‡æ ‡çš„åŠ¨æ€å›¾è¡¨ï¼š\n\n\nCode\n# å¸¦å¥åº·èŒƒå›´çš„ BMI å›¾è¡¨\noutput$bmi_plot &lt;- renderPlotly({\n  data &lt;- weight_data()\n\n  plot_ly(data, x = ~Date, y = ~BMI, type = 'scatter', mode = 'lines+markers',\n          name = get_text(\"chart_bmi_legend\"),\n          line = list(color = 'blue', width = 3),\n          marker = list(size = 8)) %&gt;%\n    # æ·»åŠ å¥åº·èŒƒå›´å¸¦\n    add_trace(y = rep(18.5, nrow(data)), mode = 'lines',\n              line = list(color = 'green', dash = 'dash'), name = \"ç†æƒ³èŒƒå›´èµ·ç‚¹\") %&gt;%\n    add_trace(y = rep(24.9, nrow(data)), mode = 'lines',\n              line = list(color = 'red', dash = 'dash'), name = \"ç†æƒ³èŒƒå›´ç»ˆç‚¹\") %&gt;%\n    layout(\n      title = get_text(\"chart_bmi_title\"),\n      xaxis = list(title = \"æ—¥æœŸ\"),\n      yaxis = list(title = \"BMI\", range = c(15, 35)),\n      hovermode = 'x unified'\n    )\n})"
  },
  {
    "objectID": "posts/weight-tracking/index.html#éƒ¨ç½²ä¸é…ç½®",
    "href": "posts/weight-tracking/index.html#éƒ¨ç½²ä¸é…ç½®",
    "title": "ç»“åˆ AI åˆ†æçš„ Shiny å’Œ Streamlit ä½“é‡è¿½è¸ªçœ‹æ¿",
    "section": "",
    "text": "åº”ç”¨å·²éƒ¨ç½²å¹¶å¯é€šè¿‡ä»¥ä¸‹é“¾æ¥è®¿é—®ï¼š https://jcflyingco.shinyapps.io/weight-tracking/\n\n\n\n\n\nCode\n# åœ¨ global.R ä¸­å¯ç”¨ URL ä¹¦ç­¾\nshinyServer(\n  function(input, output, session) {\n    # ä¹¦ç­¾é…ç½®\n    enableBookmarking(\"url\")\n\n    # ä¿å­˜/æ¢å¤ UI çŠ¶æ€\n    setBookmarkExclude(c(\"lang_en\", \"lang_zh\"))  # æ’é™¤è¯­è¨€æŒ‰é’®\n  }\n)"
  },
  {
    "objectID": "posts/weight-tracking/index.html#æ€§èƒ½ä¼˜åŒ–",
    "href": "posts/weight-tracking/index.html#æ€§èƒ½ä¼˜åŒ–",
    "title": "ç»“åˆ AI åˆ†æçš„ Shiny å’Œ Streamlit ä½“é‡è¿½è¸ªçœ‹æ¿",
    "section": "",
    "text": "åº”ç”¨å®ç°äº†é«˜æ•ˆçš„å“åº”å¼ç¼–ç¨‹ï¼š\n\n\nCode\n# é«˜æ•ˆçš„å¸¦ç¼“å­˜æ•°æ®å¤„ç†\nprocessed_data &lt;- reactive({\n  data &lt;- weight_data()\n  if (nrow(data) == 0) return(NULL)\n\n  # ä»…è®¡ç®—ä¸€æ¬¡æ´¾ç”ŸæŒ‡æ ‡\n  data %&gt;%\n    mutate(\n      Weight_Change = c(NA, diff(Weight)),\n      BMI_Category = case_when(\n        BMI &lt; 18.5 ~ \"underweight\",\n        BMI &lt; 25 ~ \"normal\",\n        BMI &lt; 30 ~ \"overweight\",\n        TRUE ~ \"obese\"\n      ),\n      Date_Formatted = format(Date, \"%Y-%m-%d\")\n    )\n})\n\n# ç”¨äºå¤šä¸ªè¾“å‡ºçš„å…±äº«è®¡ç®—\ncurrent_stats &lt;- reactive({\n  data &lt;- processed_data()\n  if (is.null(data) || nrow(data) == 0) return(NULL)\n\n  list(\n    last_weight = tail(data$Weight, 1),\n    last_bmi = tail(data$BMI, 1),\n    trend = calculate_trend(data$Weight),\n    days_tracked = nrow(data)\n  )\n})"
  },
  {
    "objectID": "posts/weight-tracking/index.html#å®‰å…¨ä¸æœ€ä½³å®è·µ",
    "href": "posts/weight-tracking/index.html#å®‰å…¨ä¸æœ€ä½³å®è·µ",
    "title": "ç»“åˆ AI åˆ†æçš„ Shiny å’Œ Streamlit ä½“é‡è¿½è¸ªçœ‹æ¿",
    "section": "",
    "text": "Code\n# å®‰å…¨çš„ API å¯†é’¥å¤„ç†ï¼ˆä»…é™ä¼šè¯å­˜å‚¨ï¼‰\nobserveEvent(input$get_ai_suggestion, {\n  if (is.null(input$api_key) || input$api_key == \"\") {\n    showNotification(get_text(\"please_provide_api_key\"), type = \"error\")\n    return()\n  }\n\n  # ä½¿ç”¨ä¼šè¯ä¸­çš„ API å¯†é’¥ï¼ˆä¸æŒä¹…åŒ–ï¼‰\n  withBusyIndicator(\"æ­£åœ¨è·å– AI å»ºè®®...\", {\n    suggestion &lt;- get_ai_suggestion(\n      weight_data = weight_data(),\n      api_key = input$api_key,\n      model = input$ai_model,\n      provider = input$ai_provider\n    )\n\n    output$ai_response &lt;- renderUI({\n      div(class = \"markdown-content\",\n          HTML(markdown::renderMarkdown(suggestion))\n      )\n    })\n  })\n})\n\n\n\n\n\n\n\nCode\n# å…¨é¢çš„é”™è¯¯å¤„ç†\nget_ai_suggestion &lt;- function(...) {\n  tryCatch({\n    # API è°ƒç”¨é€»è¾‘\n    response &lt;- ellmer::chat_completion(...)\n    return(response$choices[[1]]$message$content)\n  }, error = function(e) {\n    # é”™è¯¯æ—¥å¿—è®°å½•å’Œç”¨æˆ·åé¦ˆ\n    log_error(paste(\"AI API é”™è¯¯:\", e$message))\n    return(get_text(\"ai_error_check_config\"))\n  })\n}"
  },
  {
    "objectID": "posts/weight-tracking/index.html#ä½¿ç”¨ç¤ºä¾‹ä¸ç”¨æˆ·å·¥ä½œæµ",
    "href": "posts/weight-tracking/index.html#ä½¿ç”¨ç¤ºä¾‹ä¸ç”¨æˆ·å·¥ä½œæµ",
    "title": "ç»“åˆ AI åˆ†æçš„ Shiny å’Œ Streamlit ä½“é‡è¿½è¸ªçœ‹æ¿",
    "section": "",
    "text": "åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€åº”ç”¨ç¨‹åºã€‚\næŸ¥çœ‹å½“å‰ä½“é‡è¶‹åŠ¿å›¾å’Œ BMI å›¾è¡¨ã€‚\né€šè¿‡ Excel ä¸Šä¼ æ·»åŠ æ–°çš„ä½“é‡æ•°æ®ã€‚\nè·å– AI é©±åŠ¨çš„å¥åº·å»ºè®®ã€‚\nä¸‹è½½æ›´æ–°åçš„æ•°æ®ä¾›ç¦»çº¿ä½¿ç”¨ã€‚\n\n\n\n\n\nä½¿ç”¨å³ä¸Šè§’çš„æŒ‰é’®åœ¨ EN/ä¸­æ–‡ ä¹‹é—´åˆ‡æ¢ã€‚\næ‰€æœ‰ UI å…ƒç´ åŠ¨æ€æ›´æ–°ã€‚\nAI æç¤ºè¯é€‚é…æ‰€é€‰è¯­è¨€ã€‚\nå›¾è¡¨å’Œæ•°æ®ä¿æŒè¯­å¢ƒä¸€è‡´ã€‚"
  },
  {
    "objectID": "posts/weight-tracking/index.html#æŠ€æœ¯æˆå°±",
    "href": "posts/weight-tracking/index.html#æŠ€æœ¯æˆå°±",
    "title": "ç»“åˆ AI åˆ†æçš„ Shiny å’Œ Streamlit ä½“é‡è¿½è¸ªçœ‹æ¿",
    "section": "",
    "text": "å®æ—¶ Excel åŒæ­¥ï¼šæ•°æ®æ›´æ”¹æ—¶ UI è‡ªåŠ¨æ›´æ–°ã€‚\nå¤šæœåŠ¡å•† AI é›†æˆï¼šçµæ´»çš„ AI æœåŠ¡å•†åˆ‡æ¢ã€‚\nå®Œå–„çš„å›½é™…åŒ–ï¼šå®Œæ•´çš„åŒè¯­æ”¯æŒã€‚\nä¸“ä¸š UI è®¾è®¡ï¼šåŸºäº Bootstrap çš„å“åº”å¼å¸ƒå±€ã€‚\näº¤äº’å¼å¯è§†åŒ–ï¼šå¯ç¼©æ”¾ã€å¯æ‚¬åœçš„ Plotly å›¾è¡¨ã€‚\n\n\n\n\n\næ•°æ®åˆ·æ–°ï¼š1 ç§’è½®è¯¢é—´éš”ã€‚\nå›¾è¡¨æ¸²æŸ“ï¼šå…¸å‹æ•°æ®é›†æ¸²æŸ“æ—¶é—´ &lt; 100msã€‚\nAPI å“åº”ï¼šAI å»ºè®®å“åº”æ—¶é—´ä¸º 2-5 ç§’ã€‚\nå†…å­˜å ç”¨ï¼š1000+ æ¡è®°å½•ä¸‹å†…å­˜å ç”¨ &lt; 50MBã€‚"
  },
  {
    "objectID": "posts/weight-tracking/index.html#æœªæ¥å¢å¼ºæ–¹å‘",
    "href": "posts/weight-tracking/index.html#æœªæ¥å¢å¼ºæ–¹å‘",
    "title": "ç»“åˆ AI åˆ†æçš„ Shiny å’Œ Streamlit ä½“é‡è¿½è¸ªçœ‹æ¿",
    "section": "",
    "text": "ä¸‹ä¸€ç‰ˆæœ¬çš„æ½œåœ¨æ”¹è¿›ç‚¹ï¼š\n\næ•°æ®åº“é›†æˆï¼šå°† Excel æ›¿æ¢ä¸º SQLite/PostgreSQLã€‚\nç”¨æˆ·è®¤è¯ï¼šæ”¯æŒå¤šç”¨æˆ·ï¼Œå®ç°ä¸ªäººæ•°æ®éš”ç¦»ã€‚\nç§»åŠ¨ç«¯ä¼˜åŒ–ï¼šä¸ºç§»åŠ¨è®¾å¤‡æä¾› PWA ç‰¹æ€§ã€‚\né«˜çº§åˆ†æï¼šä½¿ç”¨æ—¶é—´åºåˆ—æ„å»ºä½“é‡é¢„æµ‹æ¨¡å‹ã€‚\né›†æˆ APIï¼šè¿æ¥å¥èº«è¿½è¸ªå™¨å’Œå¥åº·åº”ç”¨ã€‚"
  },
  {
    "objectID": "posts/weight-tracking/index.html#ç»“è®º",
    "href": "posts/weight-tracking/index.html#ç»“è®º",
    "title": "ç»“åˆ AI åˆ†æçš„ Shiny å’Œ Streamlit ä½“é‡è¿½è¸ªçœ‹æ¿",
    "section": "",
    "text": "è¿™æ¬¾ä½“é‡è¿½è¸ªåº”ç”¨å±•ç¤ºäº†å°† R Shiny çš„å“åº”å¼ç¼–ç¨‹ä¸ç°ä»£ AI æŠ€æœ¯ç›¸ç»“åˆçš„å¼ºå¤§åŠ›é‡ã€‚é¡¹ç›®å±•ç¤ºäº†ï¼š\n\nç²¾ç»†çš„æ•°æ®ç®¡ç†ï¼šå®æ—¶æ–‡ä»¶ç›‘æ§å’Œå“åº”å¼æ›´æ–°ã€‚\nAI é›†æˆï¼šé›†æˆå¤šæœåŠ¡å•†å¹¶æä¾›ä¸ªæ€§åŒ–å¥åº·å»ºè®®ã€‚\nå›½é™…åŒ–ï¼šå®Œæ•´çš„åŒè¯­å®ç°ã€‚\nä¸“ä¸šçš„ UI/UXï¼šç°ä»£å“åº”å¼è®¾è®¡é…åˆäº¤äº’å¼å¯è§†åŒ–ã€‚\n\næ— è®ºæ‚¨æ˜¯å…³æ³¨å¥åº·ç›‘æµ‹ã€æ•°æ®å¯è§†åŒ–ï¼Œè¿˜æ˜¯ AI é›†æˆï¼Œæœ¬é¡¹ç›®éƒ½ä¸ºæ‚¨æä¾›äº†ä¸€ä¸ªä½¿ç”¨ R Shiny æ„å»ºç”Ÿäº§çº§ Web åº”ç”¨çš„ç»ä½³èŒƒä¾‹ã€‚"
  },
  {
    "objectID": "posts/shop-map-manager/index.html",
    "href": "posts/shop-map-manager/index.html",
    "title": "Shop Map Manager (åº—é“ºåœ°å›¾ç®¡ç†ç³»ç»Ÿ)",
    "section": "",
    "text": "ä¸€ä¸ªå¼ºå¤§ä¸”ä¼˜é›…çš„ä¸ªäººåº—é“ºç®¡ç†ç³»ç»Ÿã€‚æ— è®ºæ‚¨æ˜¯åœ¨è¿½è¸ªå¿ƒçˆ±çš„å’–å•¡é¦†ã€é£æ™¯åèƒœï¼Œè¿˜æ˜¯åœ¨è§„åˆ’æœªæ¥çš„è¡Œç¨‹ï¼Œè¯¥åº”ç”¨ç¨‹åºéƒ½èƒ½ä¸ºæ‚¨æä¾›ä¸€ä¸ªå¼ºå¤§çš„å¯è§†åŒ–å’Œæ•°æ®ç®¡ç†å¹³å°ã€‚\nåœ¨çº¿æ¼”ç¤º (Streamlit): https://china-map.streamlit.app (Vercel): https://china-mapping.vercel.app/"
  },
  {
    "objectID": "posts/shop-map-manager/index.html#æ ¸å¿ƒæ¶æ„æ¼”å˜åŒæ¨¡å¼å­˜å‚¨",
    "href": "posts/shop-map-manager/index.html#æ ¸å¿ƒæ¶æ„æ¼”å˜åŒæ¨¡å¼å­˜å‚¨",
    "title": "Shop Map Manager (åº—é“ºåœ°å›¾ç®¡ç†ç³»ç»Ÿ)",
    "section": "æ ¸å¿ƒæ¶æ„æ¼”å˜ï¼šåŒæ¨¡å¼å­˜å‚¨",
    "text": "æ ¸å¿ƒæ¶æ„æ¼”å˜ï¼šåŒæ¨¡å¼å­˜å‚¨\næœ¬é¡¹ç›®æœ€é‡è¦çš„æ›´æ–°æ˜¯å¼•å…¥äº† åŒæ•°æ®å­˜å‚¨æ¨¡å¼ï¼ŒåŒæ—¶å…¼é¡¾äº†éšç§å’Œä¾¿æºæ€§ï¼š\n\næœ¬åœ°æ¨¡å¼ï¼šæ•°æ®å®‰å…¨åœ°å­˜å‚¨åœ¨æœ¬åœ° shops.csv æ–‡ä»¶ä¸­ã€‚é€‚åˆæ— éœ€ä»»ä½•é…ç½®çš„å¿«é€Ÿä½¿ç”¨ã€‚\näº‘ç«¯æ¨¡å¼ï¼šåˆ©ç”¨ Supabase è¿›è¡Œè·¨è®¾å¤‡çš„å®æ—¶åŒæ­¥ã€‚è®©æ‚¨çš„æ—…ç¨‹è®°å½•éšè¡Œã€‚"
  },
  {
    "objectID": "posts/shop-map-manager/index.html#åŠŸèƒ½ç‰¹æ€§",
    "href": "posts/shop-map-manager/index.html#åŠŸèƒ½ç‰¹æ€§",
    "title": "Shop Map Manager (åº—é“ºåœ°å›¾ç®¡ç†ç³»ç»Ÿ)",
    "section": "åŠŸèƒ½ç‰¹æ€§",
    "text": "åŠŸèƒ½ç‰¹æ€§\n\nğŸ” æ— é™æ¢ç´¢ï¼šæ— ç¼é›†æˆ é«˜å¾·åœ°å›¾ (Amap) APIã€‚ä¸€é”®æœç´¢å¹¶æ·»åŠ ä»»ä½•åœ°ç‚¹åˆ°æ‚¨çš„æ”¶è—ã€‚\nğŸ¨ åŠ¨æ€å¯è§†åŒ–ï¼šåŸºäº Folium çš„äº¤äº’å¼åœ°å›¾ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹è‰²ï¼š\n\né’ˆå¯¹ä¸åŒç±»åˆ«çš„è‡ªå®šä¹‰å›¾æ ‡ï¼ˆå’–å•¡ã€é¤é¥®ã€é£æ™¯ç­‰ï¼‰ã€‚\nç›´è§‚çš„é¢œè‰²ç¼–ç ï¼šçº¢è‰² è¡¨ç¤º â€œå·²å»è¿‡â€ï¼Œç»¿è‰² è¡¨ç¤º â€œæƒ³å»â€ã€‚\n\nğŸ“¸ è§†è§‰è®°å¿†ï¼šï¼ˆäº‘ç«¯æ¨¡å¼ï¼‰ä¸ºæ¯ä¸ªåœ°ç‚¹æ‹æ‘„å¹¶ä¸Šä¼ å¤šå¼ ç…§ç‰‡ï¼Œå®‰å…¨æ‰˜ç®¡åœ¨ Supabase Storageã€‚\nâ­ æ·±åº¦æ´å¯Ÿï¼šä¸ä»…è®°å½•åœ°ç‚¹ã€‚è¿˜å¯ä»¥å­˜å‚¨æ˜Ÿçº§è¯„åˆ† (1-5)ã€ä¸ªäººç¬”è®°å’Œè®¿é—®æ—¶é—´æˆ³ã€‚\nâš¡ å®æ—¶è¿‡æ»¤ï¼šæ ¹æ®è¡Œç¨‹ç±»å‹æˆ–è®¿é—®çŠ¶æ€å³æ—¶è¿‡æ»¤è§†å›¾ï¼Œä¸“æ³¨äºæ‚¨å…³å¿ƒçš„å†…å®¹ã€‚"
  },
  {
    "objectID": "posts/shop-map-manager/index.html#æŠ€æœ¯æ ˆ",
    "href": "posts/shop-map-manager/index.html#æŠ€æœ¯æ ˆ",
    "title": "Shop Map Manager (åº—é“ºåœ°å›¾ç®¡ç†ç³»ç»Ÿ)",
    "section": "æŠ€æœ¯æ ˆ",
    "text": "æŠ€æœ¯æ ˆ\n\n\n\nç»„ä»¶\næŠ€æœ¯\n\n\n\n\nå‰ç«¯\nStreamlit\n\n\nåœ°å›¾\nFolium\n\n\næ•°æ®åº“/è®¤è¯\nSupabase\n\n\nAPI\né«˜å¾·åœ°å›¾ API\n\n\næ•°æ®é€»è¾‘\nPython & Pandas"
  },
  {
    "objectID": "posts/shop-map-manager/index.html#å¿«é€Ÿä¸Šæ‰‹",
    "href": "posts/shop-map-manager/index.html#å¿«é€Ÿä¸Šæ‰‹",
    "title": "Shop Map Manager (åº—é“ºåœ°å›¾ç®¡ç†ç³»ç»Ÿ)",
    "section": "å¿«é€Ÿä¸Šæ‰‹",
    "text": "å¿«é€Ÿä¸Šæ‰‹\n\n1. å®‰è£…\ngit clone https://github.com/JCwinning/map_app.git\ncd map_app\npip install -r requirements.txt\n\n\n2. ç¯å¢ƒé…ç½®\nåœ¨æ ¹ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ª .env æ–‡ä»¶ï¼š\n# å¿…å¡«\nGAODE_API_KEY=æ‚¨çš„å¯†é’¥\n\n# å¯é€‰ï¼šç”¨äºäº‘ç«¯æ¨¡å¼\nSUPABASE_URL=æ‚¨çš„ supabase url\nSUPABASE_KEY=æ‚¨çš„ supabase anon å¯†é’¥\n\n\n3. å¯åŠ¨\nstreamlit run app.py"
  },
  {
    "objectID": "posts/shop-map-manager/index.html#æ•°æ®ç®¡ç†",
    "href": "posts/shop-map-manager/index.html#æ•°æ®ç®¡ç†",
    "title": "Shop Map Manager (åº—é“ºåœ°å›¾ç®¡ç†ç³»ç»Ÿ)",
    "section": "æ•°æ®ç®¡ç†",
    "text": "æ•°æ®ç®¡ç†\næ— è®ºæ˜¯å­˜å‚¨åœ¨æ‰å¹³çš„ CSV è¿˜æ˜¯å…³ç³»å‹çš„ Supabase è¡¨ä¸­ï¼Œè¯¥åº”ç”¨éƒ½èƒ½ä¼˜é›…åœ°å¤„ç†å¤æ‚çš„æ•°æ®ç»“æ„ï¼š\n\n\n\nåˆ—å\nè¯´æ˜\n\n\n\n\nshop_name\nåœ°ç‚¹åç§°\n\n\nvisit_status\nå½“å‰çŠ¶æ€ (å·²å»è¿‡ / æƒ³å»)\n\n\nrating\næ‚¨çš„ä¸ªäººæ˜Ÿçº§è¯„åˆ† (1-5)\n\n\nshop_type\nç±»åˆ« (ä¾‹å¦‚: å’–å•¡, é›¶å”®, é£æ™¯)\n\n\nimages\n(äº‘ç«¯æ¨¡å¼) æ‰˜ç®¡å›¾åƒçš„ URL æ•°ç»„"
  },
  {
    "objectID": "posts/shop-map-manager/index.html#ç»“è®º",
    "href": "posts/shop-map-manager/index.html#ç»“è®º",
    "title": "Shop Map Manager (åº—é“ºåœ°å›¾ç®¡ç†ç³»ç»Ÿ)",
    "section": "ç»“è®º",
    "text": "ç»“è®º\nShop Map Manager å·²ä»ä¸€ä¸ªç®€å•çš„ CSV å¯è§†åŒ–å·¥å…·æ¼”å˜ä¸ºä¸€ä¸ªå…¨é¢çš„ä¸ªäººæ—…è¡Œå’Œæ¢ç´¢ä¼´ä¾£ã€‚é€šè¿‡è¿æ¥æœ¬åœ°çš„ä¾¿æ·æ€§ä¸äº‘ç«¯çš„å¼ºå¤§åŠŸèƒ½ï¼Œå®ƒä¸ºç°ä»£æ¢ç´¢è€…æä¾›äº†æè‡´çš„çµæ´»æ€§ã€‚"
  },
  {
    "objectID": "posts/llm-summary/index.html",
    "href": "posts/llm-summary/index.html",
    "title": "LLM æ‘˜è¦ç³»ç»Ÿï¼šå¤šå¹³å° AI æ‘˜è¦å·¥å…·",
    "section": "",
    "text": "ç®€ä»‹\nåœ¨ä¿¡æ¯çˆ†ç‚¸çš„æ—¶ä»£ï¼Œç´§è·Ÿ YouTubeã€Bilibiliã€Spotify å’Œå°çº¢ä¹¦ç­‰å¤šä¸ªå¹³å°çš„å†…å®¹å¯èƒ½ä¼šè®©äººæ„Ÿåˆ°åŠ›ä¸ä»å¿ƒã€‚LLM Summary System æ˜¯ä¸€ä¸ªå¼ºå¤§çš„ç»Ÿä¸€å·¥å…·ï¼Œæ—¨åœ¨é€šè¿‡è‡ªåŠ¨ä¸‹è½½ã€è½¬å†™å¹¶ä½¿ç”¨æœ€å…ˆè¿›çš„å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) æ€»ç»“å†…å®¹æ¥è§£å†³è¿™ä¸€é—®é¢˜ã€‚\nè¯¥é¡¹ç›®æä¾›äº†ä¸€ç§æ— ç¼ä½“éªŒï¼Œèƒ½å¤Ÿå°†é•¿ç¯‡éŸ³è§†é¢‘å†…å®¹è½¬æ¢ä¸ºç®€æ´ã€å…·æœ‰å¯å‘æ€§çš„æ‘˜è¦ã€‚\n\n\n\nä¸»è¦ç‰¹æ€§\nè¯¥ç³»ç»Ÿå…·å¤‡å¤šç§åŠŸèƒ½ï¼Œæ˜¯å†…å®¹æ¶ˆè´¹çš„å¼ºå¤§é€‰æ‹©ï¼š\n\nå¤šå¹³å°æ”¯æŒï¼šä¸º YouTubeã€Bilibiliã€Spotifyã€å°çº¢ä¹¦å’Œå°å®‡å®™ FM æä¾›ç»Ÿä¸€æ¥å£ã€‚\næ™ºèƒ½å¤„ç†ï¼šé’ˆå¯¹å¤§æ–‡ä»¶å’Œè½¬å½•æ–‡æœ¬è‡ªåŠ¨åˆ†å—ï¼Œä»¥å¤„ç†é•¿ç¯‡å†…å®¹ï¼ˆæœ€é«˜æ”¯æŒ 200 ä¸‡ Tokenï¼‰ã€‚\né«˜è´¨é‡è½¬å†™ï¼šä½¿ç”¨ MLX Whisperï¼ˆé’ˆå¯¹ Apple Silicon ä¼˜åŒ–ï¼‰ï¼Œå¹¶å…·å¤‡ OpenAI Whisper å¤‡é€‰æ–¹æ¡ˆã€‚\né«˜çº§æ‘˜è¦ï¼šæ”¯æŒ 15 ç§ä»¥ä¸Š LLM æ¨¡å‹ï¼ˆåŒ…æ‹¬é€šä¹‰åƒé—® Qwenã€GLMã€DeepSeekã€GPT-4ã€Gemini å’Œ Grokï¼‰ã€‚\næ–‡æœ¬è½¬è¯­éŸ³ (TTS)ï¼šä½¿ç”¨ Google Cloud TTSã€Qwen æˆ– Gemini å°†æ‘˜è¦é‡æ–°è½¬æ¢ä¸ºéŸ³é¢‘ã€‚\næœç´¢é›†æˆï¼šåˆ©ç”¨ AI æå–çš„å…³é”®è°ƒï¼Œè‡ªåŠ¨æŸ¥æ‰¾ç›¸å…³çš„é˜…è¯»ææ–™ã€‚\nå®æ—¶è¿›åº¦è·Ÿè¸ªï¼šç”¨æˆ·å‹å¥½çš„ Streamlit Web ç•Œé¢ï¼Œæä¾›å®æ—¶æ›´æ–°ã€‚\n\n\n\næ¶æ„æ¦‚è§ˆ\nç³»ç»Ÿéµå¾ªä¸€ä¸ªæµçº¿å‹çš„å·¥ä½œæµï¼š\ngraph LR\n    A[URL è¾“å…¥] --&gt; B[å¹³å°æ£€æµ‹]\n    B --&gt; C[å†…å®¹ä¸‹è½½]\n    C --&gt; D[éŸ³é¢‘æå–]\n    D --&gt; E[è½¬å†™ - Whisper]\n    E --&gt; F[AI æ‘˜è¦ç”Ÿæˆ]\n    F --&gt; G[TTS åˆæˆ]\n    G --&gt; H[æ–‡ä»¶è¾“å‡º + Web å±•ç¤º]\n\næ ¸å¿ƒç»„ä»¶\n\napp.pyï¼šä¸»è¦çš„ Streamlit Web ç•Œé¢ï¼Œå¤„ç†å¹¶å‘ URL æäº¤å’ŒåŠ¨æ€æ’é˜Ÿã€‚\ndownload.pyï¼šç»Ÿä¸€çš„ä¸‹è½½å™¨ï¼Œä¸ºæ‰€æœ‰æ”¯æŒçš„å¹³å°æä¾›äº†å…¨é¢çš„é‡è¯•é€»è¾‘ã€‚\nprocess.pyï¼šé€šè¿‡æ™ºèƒ½åˆ†å—å¤„ç†éŸ³é¢‘è½¬å†™å’Œ AI æ‘˜è¦ã€‚\nconfig.pyï¼šç®¡ç† LLM æ¨¡å‹é…ç½®å’Œç¯å¢ƒå˜é‡ã€‚\ntts.pyï¼šå¤šä¾›åº”å•†æ–‡æœ¬è½¬è¯­éŸ³æ”¯æŒï¼Œå…·å¤‡åŸºäºå“ˆå¸Œçš„ç¼“å­˜æœºåˆ¶ã€‚\n\n\n\n\né«˜çº§æ™ºèƒ½\nè¯¥ç³»ç»Ÿåœ¨å¤„ç†å¤æ‚ä»»åŠ¡æ—¶çš„è¡¨ç°ä½¿å…¶è„±é¢–è€Œå‡ºï¼š\n\næ™ºèƒ½åˆ†å—\nä¸ºäº†é˜²æ­¢å†…å­˜æº¢å‡ºå¹¶å¤„ç†è¶…é•¿å†…å®¹ï¼š - éŸ³é¢‘ï¼šè‡ªåŠ¨åˆ†å‰²è¶…è¿‡ 60 åˆ†é’Ÿçš„æ–‡ä»¶è¿›è¡Œè½¬å†™ã€‚ - æ–‡æœ¬ï¼šè¶…è¿‡ 24 ä¸‡å­—ç¬¦çš„è½¬å½•æ–‡æœ¬å°†è¢«åˆ†å‰²æˆæ¯ä»½ 10 ä¸‡å­—ç¬¦çš„å—ã€‚\n\n\næœç´¢é›†æˆ\nåœ¨ç”Ÿæˆæ‘˜è¦åï¼Œç³»ç»Ÿä¼šæå–å…³é”®è¯ï¼Œå¹¶é€šè¿‡ DuckDuckGoï¼ˆæˆ–ç™¾åº¦ä½œä¸ºå¤‡é€‰ï¼‰æœç´¢è¡¥å……ææ–™ã€‚è¿™ç¡®ä¿äº†æ‚¨å¯¹è¯¥ä¸»é¢˜æœ‰æ›´å…¨é¢çš„ç†è§£ã€‚\n\n\n\nå¿«é€Ÿä¸Šæ‰‹\nè¿è¡Œè¯¥ç³»ç»Ÿçš„æœ€ç®€å•æ–¹æ³•æ˜¯é€šè¿‡ Web ç•Œé¢ï¼š\n\nå…‹éš†ä»“åº“ï¼š\ngit clone https://github.com/JCwinning/llm_summary.git\ncd llm_summary\né…ç½®ç¯å¢ƒï¼šåˆ›å»ºä¸€ä¸ª .env æ–‡ä»¶å¹¶å¡«å…¥æ‚¨çš„ API å¯†é’¥ï¼ˆOpenAIã€DashScope ç­‰ï¼‰ã€‚\nå®‰è£…ä¾èµ–ï¼š\npip install -r requirements.txt\nè¿è¡Œåº”ç”¨ï¼š\nstreamlit run app.py\n\n\n\nç»“è®º\nLLM Summary System ä¸ä»…ä»…æ˜¯ä¸€ä¸ªä¸‹è½½å™¨ï¼›å®ƒè¿˜æ˜¯æ‚¨çš„ç§äºº AI ç ”ç©¶åŠ©æ‰‹ã€‚æ— è®ºæ‚¨æ˜¯å­¦ç”Ÿã€ç ”ç©¶äººå‘˜ï¼Œè¿˜æ˜¯åªæ˜¯æƒ³ä¿æŒè·å–å’¨è¯¢ï¼Œè¯¥å·¥å…·éƒ½èƒ½é€šè¿‡å°†æ•°å°æ—¶çš„å†…å®¹æµ“ç¼©ä¸ºåˆ†é’Ÿçº§çš„é˜…è¯»ï¼Œæ˜¾è‘—æé«˜æ‚¨çš„ç”Ÿäº§åŠ›ã€‚\nåœ¨ GitHub ä¸ŠæŸ¥çœ‹å®Œæ•´æºä»£ç å¹¶å‚ä¸è´¡çŒ®ã€‚"
  },
  {
    "objectID": "posts/RAG/index.html",
    "href": "posts/RAG/index.html",
    "title": "R å’Œ Python ä¸­çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG)",
    "section": "",
    "text": "ç®€ä»‹\næ£€ç´¢å¢å¼ºç”Ÿæˆ (Retrieval-Augmented Generation, RAG) æ˜¯ä¸€ç§å¼ºå¤§çš„æŠ€æœ¯ï¼Œå®ƒå°†å¤§å‹è¯­è¨€æ¨¡å‹ (LLM) çš„ç”Ÿæˆèƒ½åŠ›ä¸ä¿¡æ¯æ£€ç´¢çš„ç²¾å‡†æ€§ç›¸ç»“åˆã€‚é€šè¿‡å°† LLM çš„å“åº”é”šå®šåœ¨å¤–éƒ¨ã€å¯éªŒè¯çš„æ•°æ®ä¸­ï¼ŒRAG å‡å°‘äº†å¹»è§‰ï¼Œå¹¶ä½¿æ¨¡å‹èƒ½å¤Ÿå›ç­”å…³äºç‰¹å®šã€ç§æœ‰æˆ–æœ€æ–°ä¿¡æ¯çš„é—®é¢˜ã€‚\nåœ¨æœ¬æ•™ç¨‹ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ R å’Œ Python æ„å»ºä¸€ä¸ª RAG ç³»ç»Ÿã€‚\nåœ¨ R ä¸­ï¼Œæˆ‘ä»¬å°†åˆ©ç”¨ ragnar åŒ…å¤„ç† RAG å·¥ä½œæµï¼Œå¹¶ä½¿ç”¨ ellmer æä¾›èŠå¤©ç•Œé¢ã€‚\nåœ¨ Python ä¸­ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ LangChain æ„å»º RAG æµæ°´çº¿ï¼Œä½¿ç”¨ ChromaDB ä½œä¸ºå‘é‡æ•°æ®åº“ï¼Œå¹¶ä½¿ç”¨ OpenAI è¿›è¡Œæ¨¡å‹äº¤äº’ã€‚\næˆ‘ä»¬çš„ç›®æ ‡æ˜¯åˆ›å»ºä¸€ä¸ªç³»ç»Ÿï¼Œé€šè¿‡çˆ¬å– OpenRouter API çš„æ–‡æ¡£ï¼Œæ¥å›ç­”ä¸å…¶ç›¸å…³çš„é—®é¢˜ã€‚\n\n\næ•°æ®é‡‡é›†\n\nRPython\n\n\né¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸ºçŸ¥è¯†åº“æ”¶é›†æ•°æ®ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ rvest åŒ…ä» OpenRouter æ–‡æ¡£ä¸­çˆ¬å– URLã€‚è¿™å°†ä¸ºæˆ‘ä»¬æä¾›å¾…æ¥å…¥çš„é¡µé¢åˆ—è¡¨ã€‚\n\n\nCode\nlibrary(ragnar)\nlibrary(ellmer)\nlibrary(dotenv)\nload_dot_env(file = \".env\")\n\n\n\n\nCode\nlibrary(rvest)\n\n# å¾…çˆ¬å–çš„ URL\nurl &lt;- \"https://openrouter.ai/docs/quickstart\"\n\n# è¯»å–é¡µé¢çš„ HTML å†…å®¹\npage &lt;- read_html(url)\n\n# æå–æ‰€æœ‰å¸¦æœ‰ href çš„ &lt;a&gt; æ ‡ç­¾\nlinks &lt;- page %&gt;%\n    html_nodes(\"a\") %&gt;%\n    html_attr(\"href\")\n\n# ç§»é™¤ç©ºå€¼å’Œé‡å¤é¡¹\nlinks &lt;- unique(na.omit(links))\n\n# å¯é€‰ï¼šä»…ä¿ç•™å®Œæ•´ URL\nlinks_full &lt;- paste0(\"https://openrouter.ai\", links[grepl(\"^/docs/\", links)])\n\n# æ‰“å°æ‰€æœ‰é“¾æ¥\nprint(links_full)\n\n\n [1] \"https://openrouter.ai/docs/api-reference/overview\"                               \n [2] \"https://openrouter.ai/docs/quickstart\"                                           \n [3] \"https://openrouter.ai/docs/api/reference/overview\"                               \n [4] \"https://openrouter.ai/docs/sdks/agentic-usage\"                                   \n [5] \"https://openrouter.ai/docs/guides/overview/principles\"                           \n [6] \"https://openrouter.ai/docs/guides/overview/models\"                               \n [7] \"https://openrouter.ai/docs/faq\"                                                  \n [8] \"https://openrouter.ai/docs/guides/overview/report-feedback\"                      \n [9] \"https://openrouter.ai/docs/guides/routing/model-fallbacks\"                       \n[10] \"https://openrouter.ai/docs/guides/routing/provider-selection\"                    \n[11] \"https://openrouter.ai/docs/guides/features/presets\"                              \n[12] \"https://openrouter.ai/docs/guides/features/tool-calling\"                         \n[13] \"https://openrouter.ai/docs/guides/features/structured-outputs\"                   \n[14] \"https://openrouter.ai/docs/guides/features/message-transforms\"                   \n[15] \"https://openrouter.ai/docs/guides/features/zero-completion-insurance\"            \n[16] \"https://openrouter.ai/docs/guides/features/zdr\"                                  \n[17] \"https://openrouter.ai/docs/app-attribution\"                                      \n[18] \"https://openrouter.ai/docs/guides/features/guardrails\"                           \n[19] \"https://openrouter.ai/docs/faq#how-are-rate-limits-calculated\"                   \n[20] \"https://openrouter.ai/docs/api/reference/streaming\"                              \n[21] \"https://openrouter.ai/docs/guides/community/frameworks-and-integrations-overview\"\n\n\n\n\né¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦ä¸ºçŸ¥è¯†åº“æ”¶é›†æ•°æ®ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ requests å’Œ BeautifulSoup ä» OpenRouter æ–‡æ¡£ä¸­çˆ¬å– URLã€‚è¿™å°†ä¸ºæˆ‘ä»¬æä¾›å¾…æ¥å…¥çš„é¡µé¢åˆ—è¡¨ã€‚\n\n\nCode\nimport sys\nprint(sys.executable)\n\n\n/Library/Frameworks/Python.framework/Versions/3.13/bin/python3\n\n\n\n\nCode\nimport requests\nfrom bs4 import BeautifulSoup\nfrom dotenv import load_dotenv\nimport os\nfrom markitdown import MarkItDown\nfrom io import BytesIO\nimport re\n\n# åŠ è½½ç¯å¢ƒå˜é‡\nload_dotenv()\n\n\nTrue\n\n\nCode\n# è¾…åŠ©å‡½æ•°\ndef fetch_html(url: str) -&gt; bytes:\n    \"\"\"ä» URL è·å– HTML å†…å®¹å¹¶ä»¥å­—èŠ‚å½¢å¼è¿”å›ã€‚\"\"\"\n    resp = requests.get(url)\n    resp.raise_for_status()\n    return resp.content\n\ndef html_to_markdown(html_bytes: bytes) -&gt; str:\n    \"\"\"ä½¿ç”¨ MarkItDown å°† HTML å­—èŠ‚è½¬æ¢ä¸º Markdownã€‚\"\"\"\n    md = MarkItDown()\n    stream = BytesIO(html_bytes)\n    result = md.convert_stream(stream, mime_type=\"text/html\")\n    return result.markdown\n\ndef save_markdown(md_content: str, output_path: str):\n    \"\"\"å°† Markdown å†…å®¹ä¿å­˜åˆ°æ–‡ä»¶ã€‚\"\"\"\n    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n        f.write(md_content)\n\ndef sanitize_filename(filename: str) -&gt; str:\n    \"\"\"æ¸…ç† URL ä»¥åˆ›å»ºåˆæ³•çš„æ–‡ä»¶åã€‚\"\"\"\n    filename = re.sub(r'^https?://[^/]+', '', filename)\n    filename = re.sub(r'[^\\w\\-_.]', '_', filename)\n    filename = filename.strip('_')\n    if not filename.endswith('.md'):\n        filename += '.md'\n    return filename\n\n# å¾…çˆ¬å–çš„ URL\nurl = \"https://openrouter.ai/docs/quickstart\"\n\n# è¯»å–é¡µé¢çš„ HTML å†…å®¹\nresponse = requests.get(url)\nsoup = BeautifulSoup(response.content, 'html.parser')\n\n# æå–æ‰€æœ‰å¸¦æœ‰ href çš„ &lt;a&gt; æ ‡ç­¾\nlinks = [a['href'] for a in soup.find_all('a', href=True)]\n\n# ç§»é™¤é‡å¤é¡¹\nlinks = list(set(links))\n\n# ä»…ä¿ç•™æ–‡æ¡£çš„å®Œæ•´ URL\nlinks_full = [f\"https://openrouter.ai{link}\" for link in links if link.startswith(\"/docs/\")]\n\n# æ˜¾å¼æ·»åŠ  FAQ\nlinks_full.append(\"https://openrouter.ai/docs/faq\")\nlinks_full = list(set(links_full))\n\n# æ‰“å°æ‰€æœ‰é“¾æ¥\nprint(f\"æ‰¾åˆ° {len(links_full)} ä¸ªæ–‡æ¡£ URL\")\n\n\næ‰¾åˆ° 21 ä¸ªæ–‡æ¡£ URL\n\n\nCode\nprint(links_full)\n\n\n['https://openrouter.ai/docs/faq', 'https://openrouter.ai/docs/sdks/agentic-usage', 'https://openrouter.ai/docs/guides/features/message-transforms', 'https://openrouter.ai/docs/api/reference/overview', 'https://openrouter.ai/docs/guides/overview/principles', 'https://openrouter.ai/docs/guides/overview/report-feedback', 'https://openrouter.ai/docs/api-reference/overview', 'https://openrouter.ai/docs/quickstart', 'https://openrouter.ai/docs/guides/community/frameworks-and-integrations-overview', 'https://openrouter.ai/docs/guides/routing/provider-selection', 'https://openrouter.ai/docs/guides/features/structured-outputs', 'https://openrouter.ai/docs/faq#how-are-rate-limits-calculated', 'https://openrouter.ai/docs/guides/features/presets', 'https://openrouter.ai/docs/guides/routing/model-fallbacks', 'https://openrouter.ai/docs/guides/features/guardrails', 'https://openrouter.ai/docs/api/reference/streaming', 'https://openrouter.ai/docs/guides/features/zdr', 'https://openrouter.ai/docs/app-attribution', 'https://openrouter.ai/docs/guides/features/tool-calling', 'https://openrouter.ai/docs/guides/overview/models', 'https://openrouter.ai/docs/guides/features/zero-completion-insurance']\n\n\n\n\n\n\n\nå°†ç½‘é¡µå†…å®¹ä¿å­˜åˆ°æœ¬åœ°\n\nRPython DuckDBPython Chroma\n\n\nä¸ºäº†è¿›è¡Œè¯­ä¹‰æœç´¢ï¼Œæˆ‘ä»¬éœ€è¦å°†æ–‡æœ¬æ•°æ®å­˜å‚¨ä¸ºå‘é‡ï¼ˆåµŒå…¥ï¼‰ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ DuckDB ä½œä¸ºæœ¬åœ°å‘é‡æ•°æ®åº“ã€‚æˆ‘ä»¬è¿˜éœ€è¦ä¸€ä¸ªåµŒå…¥æ¨¡å‹å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é…ç½® ragnar é€šè¿‡ OpenAI å…¼å®¹çš„ API (SiliconFlow) ä½¿ç”¨ç‰¹å®šçš„åµŒå…¥æ¨¡å‹ã€‚\n\n\nCode\n# pages &lt;- ragnar_find_links(base_url)\npages &lt;- links_full\nstore_location &lt;- \"openrouter.duckdb\"\n\nstore &lt;- ragnar_store_create(\n    store_location,\n    overwrite = TRUE,\n    embed = \\(x) ragnar::embed_openai(x,\n        model = \"BAAI/bge-m3\",\n        base_url = \"https://api.siliconflow.cn/v1\",\n        api_key = Sys.getenv(\"siliconflow\")\n    )\n)\n\n\nåœ¨å­˜å‚¨åˆå§‹åŒ–åï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥æ¥å…¥æ•°æ®ã€‚æˆ‘ä»¬éå†ä¹‹å‰çˆ¬å–çš„é¡µé¢åˆ—è¡¨ã€‚å¯¹äºæ¯ä¸ªé¡µé¢ï¼Œæˆ‘ä»¬ï¼š 1. ä»¥ Markdown æ ¼å¼è¯»å–å†…å®¹ã€‚ 2. å°†å†…å®¹æ‹†åˆ†ä¸ºè¾ƒå°çš„å—ï¼ˆçº¦ 600 å­—ç¬¦ï¼‰ã€‚ 3. å°†è¿™äº›å—æ’å…¥åˆ°æˆ‘ä»¬çš„å‘é‡æ•°æ®åº“ä¸­ã€‚\næ­¤è¿‡ç¨‹æ„å»ºäº†æˆ‘ä»¬å°†è¦æœç´¢çš„ç´¢å¼•ã€‚\n\n\nCode\n# page=\"https://openrouter.ai/docs/faq\"\n# chunks &lt;- page |&gt;read_as_markdown() |&gt;markdown_chunk(target_size = 2000)\n# ragnar_chunks_view(chunks)\n\n\n\n\nCode\nfor (page in pages) {\n    message(\"æ­£åœ¨æ¥å…¥: \", page)\n    print(page)\n    chunks &lt;- page |&gt;\n        read_as_markdown() |&gt;\n        markdown_chunk(target_size = 2000)\n    # print(chunks)\n    # print('chunks done')\n    ragnar_store_insert(store, chunks)\n    print(\"æ’å…¥å®Œæˆ\")\n}\n\n\n\n\nCode\nragnar_store_build_index(store)\n\n# é‡Šæ”¾è¿æ¥ä»¥ä¾›åç»­ Python ä»£ç ä½¿ç”¨\nrm(store)\ngc()\n\n\n\n\n\n\nCode\nimport os\nfrom llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, Settings\nfrom llama_index.vector_stores.duckdb import DuckDBVectorStore\nfrom llama_index.embeddings.openai import OpenAIEmbedding\n\n# --- 1. é…ç½® ---\n\n# ç¡®ä¿ API å¯†é’¥å¯ç”¨\nopenrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\") # æˆ–ç›´æ¥ç²˜è´´å­—ç¬¦ä¸²\n\n# åˆå§‹åŒ–æŒ‡å‘ OpenRouter çš„åµŒå…¥æ¨¡å‹\n# æˆ‘ä»¬ä½¿ç”¨ OpenAI ç±»ï¼Œå› ä¸º OpenRouter ä½¿ç”¨äº† OpenAI å…¼å®¹çš„ API ç»“æ„\nembed_model = OpenAIEmbedding(\n    api_key=openrouter_api_key,\n    base_url=\"https://openrouter.ai/api/v1\",\n    model=\"qwen/qwen3-embedding-8b\"  \n)\n\n# æ›´æ–°å…¨å±€è®¾ç½®ï¼Œä»¥ä¾¿ LlamaIndex çŸ¥é“ä½¿ç”¨æ­¤æ¨¡å‹\nSettings.embed_model = embed_model\nSettings.chunk_size = 2000\nSettings.chunk_overlap = 200\n# --- 2. æ¥å…¥ä¸ç´¢å¼• ---\n\n# åŠ è½½æ•°æ®\ndocuments = SimpleDirectoryReader(\"markdown_docs\").load_data()\n\n# åˆå§‹åŒ– DuckDB å‘é‡æ•°æ®åº“\nvector_store = DuckDBVectorStore(\"openrouter.duckdb\", persist_dir=\"./persist/\")\nstorage_context = StorageContext.from_defaults(vector_store=vector_store)\n\n# åˆ›å»ºç´¢å¼•\n# è¿™å°†è‡ªåŠ¨ä½¿ç”¨ Settings ä¸­å®šä¹‰çš„ Qwen åµŒå…¥\nindex = VectorStoreIndex.from_documents(\n    documents, \n    storage_context=storage_context\n)\n\n\n\n\nä¸ºäº†è¿›è¡Œè¯­ä¹‰æœç´¢ï¼Œæˆ‘ä»¬éœ€è¦å°†æ–‡æœ¬æ•°æ®è½¬æ¢ä¸ºå‘é‡ï¼ˆåµŒå…¥ï¼‰è¿›è¡Œå­˜å‚¨ã€‚æˆ‘ä»¬å°†ä½¿ç”¨ ChromaDB ä½œä¸ºæœ¬åœ°å‘é‡æ•°æ®åº“ã€‚æˆ‘ä»¬è¿˜éœ€è¦ä¸€ä¸ªåµŒå…¥æ¨¡å‹æŠŠæ–‡æœ¬è½¬ä¸ºå‘é‡ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬é…ç½®äº†ä¸€ä¸ªè‡ªå®šä¹‰çš„ OpenRouterEmbeddings ç±»ï¼Œé€šè¿‡ OpenRouter API ä½¿ç”¨ qwen/qwen3-embedding-8b æ¨¡å‹ã€‚\n\n\nCode\nfrom openai import OpenAI\nfrom langchain_core.embeddings import Embeddings\nfrom langchain_chroma import Chroma\nfrom typing import List\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n# é’ˆå¯¹ OpenRouter API çš„è‡ªå®šä¹‰åµŒå…¥ç±»\nclass OpenRouterEmbeddings(Embeddings):\n    \"\"\"é’ˆå¯¹ OpenRouter API çš„è‡ªå®šä¹‰åµŒå…¥ç±»ã€‚\"\"\"\n    \n    def __init__(self, api_key: str, model: str = \"text-embedding-3-small\"):\n        self.client = OpenAI(\n            base_url=\"https://openrouter.ai/api/v1\",\n            api_key=api_key,\n        )\n        self.model = model\n    \n    def embed_documents(self, texts: List[str]) -&gt; List[List[float]]:\n        \"\"\"å¯¹æ–‡æ¡£åˆ—è¡¨è¿›è¡ŒåµŒå…¥ã€‚\"\"\"\n        response = self.client.embeddings.create(\n            extra_headers={\n                \"HTTP-Referer\": \"https://ai-blog.com\",\n                \"X-Title\": \"AI Blog RAG\",\n            },\n            model=self.model,\n            input=texts,\n            encoding_format=\"float\"\n        )\n        return [item.embedding for item in response.data]\n    \n    def embed_query(self, text: str) -&gt; List[float]:\n        \"\"\"å¯¹å•ä¸ªæŸ¥è¯¢è¿›è¡ŒåµŒå…¥ã€‚\"\"\"\n        response = self.client.embeddings.create(\n            extra_headers={\n                \"HTTP-Referer\": \"https://ai-blog.com\",\n                \"X-Title\": \"AI Blog RAG\",\n            },\n            model=self.model,\n            input=text,\n            encoding_format=\"float\"\n        )\n        return response.data[0].embedding\n\n# è·å– OpenRouter API å¯†é’¥\nopenrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\nif not openrouter_api_key:\n    raise ValueError(\"æœªåœ¨ç¯å¢ƒå˜é‡ä¸­æ‰¾åˆ° OPENROUTER_API_KEY\")\n\n# ä½¿ç”¨ OpenRouter åˆ›å»ºåµŒå…¥å®ä¾‹\nembeddings = OpenRouterEmbeddings(\n    api_key=openrouter_api_key,\n    model=\"qwen/qwen3-embedding-8b\"\n)\n\n# å®šä¹‰å‘é‡æ•°æ®åº“ä½ç½®\npersist_directory = \"chroma_db_data\"\n\n\nåœ¨å­˜å‚¨åˆå§‹åŒ–åï¼Œæˆ‘ä»¬ç°åœ¨å¯ä»¥æ¥å…¥æ•°æ®ã€‚æˆ‘ä»¬éå†ä¹‹å‰ä¿å­˜çš„ Markdown æ–‡ä»¶ã€‚å¯¹äºæ¯ä¸ªæ–‡ä»¶ï¼Œæˆ‘ä»¬ï¼š 1. åŠ è½½å†…å®¹ã€‚ 2. ä½¿ç”¨ RecursiveCharacterTextSplitter å°†å†…å®¹æ‹†åˆ†ä¸ºè¾ƒå°çš„å—ï¼ˆçº¦ 2000 å­—ç¬¦ï¼‰ã€‚ 3. ä»è¿™äº›å—ä¸­åˆ›å»ºä¸€ä¸ªæ–°çš„ Chroma å‘é‡æ•°æ®åº“ã€‚\næ­¤è¿‡ç¨‹æ„å»ºäº†æˆ‘ä»¬å°†è¦æœç´¢çš„ç´¢å¼•ã€‚\n\n\nCode\nfrom langchain_core.documents import Document\nfrom langchain_text_splitters import RecursiveCharacterTextSplitter\nimport shutil\n\n# åŠ è½½ Markdown æ–‡ä»¶çš„è¾…åŠ©å‡½æ•°\ndef load_markdown_files(directory: str) -&gt; list[Document]:\n    \"\"\"ä»ç›®å½•åŠ è½½æ‰€æœ‰ Markdown æ–‡ä»¶å¹¶åˆ›å»º Document å¯¹è±¡ã€‚\"\"\"\n    documents = []\n    if not os.path.exists(directory):\n        return documents\n        \n    for filename in os.listdir(directory):\n        if filename.endswith('.md'):\n            filepath = os.path.join(directory, filename)\n            with open(filepath, 'r', encoding='utf-8') as f:\n                content = f.read()\n                doc = Document(\n                    page_content=content,\n                    metadata={\n                        \"source\": filename,\n                        \"filepath\": filepath\n                    }\n                )\n                documents.append(doc)\n    return documents\n\n# åˆ›å»º Markdown æ–‡ä»¶çš„è¾“å‡ºç›®å½•\noutput_dir = \"markdown_docs\"\nos.makedirs(output_dir, exist_ok=True)\n\n# å°†æ¯ä¸ª URL è½¬æ¢ä¸º Markdown å¹¶ä¿å­˜\nfor i, link_url in enumerate(links_full, 1):\n    try:\n        print(f\"æ­£åœ¨å¤„ç† {i}/{len(links_full)}: {link_url}\")\n        html_content = fetch_html(link_url)\n        markdown_content = html_to_markdown(html_content)\n        filename = sanitize_filename(link_url)\n        output_path = os.path.join(output_dir, filename)\n        save_markdown(markdown_content, output_path)\n        print(f\"  âœ“ å·²ä¿å­˜è‡³ {output_path}\")\n    except Exception as e:\n        print(f\"  âœ— å¤„ç† {link_url} æ—¶å‡ºé”™: {str(e)}\")\n\n# åŠ è½½ Markdown æ–‡æ¡£\ndocuments = load_markdown_files(output_dir)\nprint(f\"\\nåŠ è½½äº† {len(documents)} ä¸ª Markdown æ–‡æ¡£\")\n\n# å°†æ–‡æ¡£æ‹†åˆ†ä¸ºå—\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=2000,\n    chunk_overlap=200,\n    length_function=len,\n    is_separator_regex=False,\n)\n\nsplits = text_splitter.split_documents(documents)\nprint(f\"æ‹†åˆ†ä¸º {len(splits)} ä¸ªå—\")\n\n\n\n\nCode\n# å¦‚æœæ•°æ®åº“å·²å­˜åœ¨ï¼Œåˆ™å°†å…¶ç§»é™¤\nif os.path.exists(persist_directory):\n    print(f\"æ­£åœ¨ç§»é™¤ä½äº {persist_directory} çš„ç°æœ‰æ•°æ®åº“...\")\n    shutil.rmtree(persist_directory)\n\n# åˆ›å»ºæ–°çš„å‘é‡æ•°æ®åº“\nvectorstore = Chroma.from_documents(\n    documents=splits,\n    embedding=embeddings,\n    persist_directory=persist_directory\n)\n\nprint(f\"\\nâœ“ æˆåŠŸåˆ›å»ºäº†åŒ…å« {len(splits)} ä¸ªå—çš„ ChromaDBï¼\")\nprint(f\"âœ“ æ•°æ®åº“å·²ä¿å­˜è‡³: {persist_directory}\")\n\n\n\n\n\n\n\næ£€ç´¢\n\nRPython DuckDBPython Chroma\n\n\nç°åœ¨æˆ‘ä»¬çš„çŸ¥è¯†åº“å·²ç»å¡«å……å®Œæ¯•ï¼Œæˆ‘ä»¬å¯ä»¥æµ‹è¯•æ£€ç´¢ç³»ç»Ÿã€‚æˆ‘ä»¬å¯ä»¥æå‡ºä¸€ä¸ªç‰¹å®šçš„é—®é¢˜ï¼Œä¾‹å¦‚â€œä»€ä¹ˆæ˜¯æ¨¡å‹å˜ä½“ï¼Ÿ(What are model variants?)â€ï¼Œå¹¶æŸ¥è¯¢å­˜å‚¨åº“ä»¥æŸ¥çœ‹å“ªäº›æ–‡æœ¬å—æœ€ç›¸å…³ã€‚è¿™ç¡®è®¤äº†æˆ‘ä»¬çš„åµŒå…¥å’Œæœç´¢æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚\n\né—®é¢˜ï¼šä»€ä¹ˆæ˜¯æ¨¡å‹å˜ä½“ï¼Ÿ(What are model variants?)\nRAG ç»“æœï¼š\n\n\nCode\nstore_location &lt;- \"openrouter.duckdb\"\ntext &lt;- \"What are model variants?\"\n\nrelevant_chunks &lt;- tryCatch({\n    store &lt;- ragnar_store_connect(store_location)\n    ragnar_retrieve(store, text, top_k = 3)\n}, error = function(e) {\n    message(\"âš ï¸ æ— æ³•è¿æ¥åˆ° DuckDB (å¯èƒ½è¢«é”å®š): \", e$message)\n    return(NULL)\n})\n\nif (!is.null(relevant_chunks)) {\n    cat(\"æ£€ç´¢åˆ°\", nrow(relevant_chunks), \"ä¸ªæ–‡æœ¬å—ï¼š\\n\\n\")\n    for (i in seq_len(nrow(relevant_chunks))) {\n        cat(sprintf(\"--- å— %d ---\\n%s\\n\\n\", i, relevant_chunks$text[i]))\n    }\n} else {\n    cat(\"çŸ¥è¯†åº“å½“å‰ä¸å¯ç”¨ï¼ˆç”±äºæ•°æ®åº“é”å®šï¼‰ã€‚\")\n}\n\n\næ£€ç´¢åˆ° 6 ä¸ªæ–‡æœ¬å—ï¼š\n\n--- å— 1 ---\n[Zero Completion Insurance](/docs/features/zero-completion-insurance)\n  + [Provisioning API Keys](/docs/features/provisioning-api-keys)\n  + [App Attribution](/docs/app-attribution)\n* API Reference\n\n  + [Overview](/docs/api-reference/overview)\n  + [Streaming](/docs/api-reference/streaming)\n  + [Embeddings](/docs/api-reference/embeddings)\n  + [Limits](/docs/api-reference/limits)\n  + [Authentication](/docs/api-reference/authentication)\n  + [Parameters](/docs/api-reference/parameters)\n  + [Errors](/docs/api-reference/errors)\n  + Responses API\n  + beta.responses\n  + Analytics\n  + Credits\n  + Embeddings\n  + Generations\n  + Models\n  + Endpoints\n  + Parameters\n  + Providers\n  + API Keys\n  + O Auth\n  + Chat\n  + Completions\n* SDK Reference (BETA)\n\n  + [Python SDK](/docs/sdks/python)\n  + [TypeScript SDK](/docs/sdks/typescript)\n* Use Cases\n\n  + [BYOK](/docs/use-cases/byok)\n  + [Crypto API](/docs/use-cases/crypto-api)\n  + [OAuth PKCE](/docs/use-cases/oauth-pkce)\n  + [MCP Servers](/docs/use-cases/mcp-servers)\n  + [Organization Management](/docs/use-cases/organization-management)\n  + [For Providers](/docs/use-cases/for-providers)\n  + [Reasoning Tokens](/docs/use-cases/reasoning-tokens)\n  + [Usage Accounting](/docs/use-cases/usage-accounting)\n  + [User Tracking](/docs/use-cases/user-tracking)\n* Community\n\n  + [Frameworks and Integrations Overview](/docs/community/frameworks-and-integrations-overview)\n  + [Effect AI SDK](/docs/community/effect-ai-sdk)\n  + [Arize](/docs/community/arize)\n  + [LangChain](/docs/community/lang-chain)\n  + [LiveKit](/docs/community/live-kit)\n  + [Langfuse](/docs/community/langfuse)\n  + [Mastra](/docs/community/mastra)\n  + [OpenAI SDK](/docs/community/open-ai-sdk)\n  + [PydanticAI](/docs/community/pydantic-ai)\n  + [Vercel AI SDK](/docs/community/vercel-ai-sdk)\n  + [Xcode](/docs/community/xcode)\n  + [Zapier](/docs/community/zapier)\n  + [Discord](https://discord.gg/openrouter)\n\nLight\n\nOn this page\n\n* [Requests](#requests)\n* [Completions Request Format](#completions-request-format)\n* [Headers](#headers)\n* [Assistant Prefill](#assistant-prefill)\n* [Responses](#responses)\n* [CompletionsResponse Format](#completionsresponse-format)\n* [Finish Reason](#finish-reason)\n* [Querying Cost and Stats](#querying-cost-and-stats)\n\n[API Reference](/docs/api-reference/overview)\n\n\n\n--- å— 2 ---\n###### How frequently are new models added?\n\nWe work on adding models as quickly as we can. We often have partnerships with\nthe labs releasing models and can release models as soon as they are\navailable. If there is a model missing that youâ€™d like OpenRouter to support, feel free to message us on\n[Discord](https://discord.gg/openrouter).\n\n###### What are model variants?\n\nVariants are suffixes that can be added to the model slug to change its behavior.\n\nStatic variants can only be used with specific models and these are listed in our [models api](https://openrouter.ai/api/v1/models).\n\n1. `:free` - The model is always provided for free and has low rate limits.\n2. `:beta` - The model is not moderated by OpenRouter.\n3. `:extended` - The model has longer than usual context length.\n4. `:exacto` - The model only uses OpenRouter-curated high-quality endpoints.\n5. `:thinking` - The model supports reasoning by default.\n\nDynamic variants can be used on all models and they change the behavior of how the request is routed or used.\n\n1. `:online` - All requests will run a query to extract web results that are attached to the prompt.\n2. `:nitro` - Providers will be sorted by throughput rather than the default sort, optimizing for faster response times.\n3. `:floor` - Providers will be sorted by price rather than the default sort, prioritizing the most cost-effective options.\n\n###### I am an inference provider, how can I get listed on OpenRouter?\n\nYou can read our requirements at the [Providers\npage](/docs/use-cases/for-providers). If you would like to contact us, the best\nplace to reach us is over email.\n\n###### What is the expected latency/response time for different models?\n\nFor each model on OpenRouter we show the latency (time to first token) and the token\nthroughput for all providers. You can use this to estimate how long requests\nwill take. If you would like to optimize for throughput you can use the\n`:nitro` variant to route to the fastest provider.\n\n\n\n--- å— 3 ---\n###### How frequently are new models added?\n\nWe work on adding models as quickly as we can. We often have partnerships with\nthe labs releasing models and can release models as soon as they are\navailable. If there is a model missing that youâ€™d like OpenRouter to support, feel free to message us on\n[Discord](https://discord.gg/openrouter).\n\n###### What are model variants?\n\nVariants are suffixes that can be added to the model slug to change its behavior.\n\nStatic variants can only be used with specific models and these are listed in our [models api](https://openrouter.ai/api/v1/models).\n\n1. `:free` - The model is always provided for free and has low rate limits.\n2. `:beta` - The model is not moderated by OpenRouter.\n3. `:extended` - The model has longer than usual context length.\n4. `:exacto` - The model only uses OpenRouter-curated high-quality endpoints.\n5. `:thinking` - The model supports reasoning by default.\n\nDynamic variants can be used on all models and they change the behavior of how the request is routed or used.\n\n1. `:online` - All requests will run a query to extract web results that are attached to the prompt.\n2. `:nitro` - Providers will be sorted by throughput rather than the default sort, optimizing for faster response times.\n3. `:floor` - Providers will be sorted by price rather than the default sort, prioritizing the most cost-effective options.\n\n###### I am an inference provider, how can I get listed on OpenRouter?\n\nYou can read our requirements at the [Providers\npage](/docs/use-cases/for-providers). If you would like to contact us, the best\nplace to reach us is over email.\n\n###### What is the expected latency/response time for different models?\n\nFor each model on OpenRouter we show the latency (time to first token) and the token\nthroughput for all providers. You can use this to estimate how long requests\nwill take. If you would like to optimize for throughput you can use the\n`:nitro` variant to route to the fastest provider.\n\n\n\n--- å— 4 ---\n## The `models` parameter\n\nThe `models` parameter lets you automatically try other models if the primary modelâ€™s providers are down, rate-limited, or refuse to reply due to content moderation.\n\nTypeScript SDKTypeScript (fetch)Python\n\n```code-block-root not-prose rounded-b-[inherit] rounded-t-none\n|  |  |\n| --- | --- |\n| 1 | import { OpenRouter } from '@openrouter/sdk'; |\n| 2 |  |\n| 3 | const openRouter = new OpenRouter({ |\n| 4 | apiKey: '&lt;OPENROUTER_API_KEY&gt;', |\n| 5 | }); |\n| 6 |  |\n| 7 | const completion = await openRouter.chat.send({ |\n| 8 | models: ['anthropic/claude-3.5-sonnet', 'gryphe/mythomax-l2-13b'], |\n| 9 | messages: [ |\n| 10 | { |\n| 11 | role: 'user', |\n| 12 | content: 'What is the meaning of life?', |\n| 13 | }, |\n| 14 | ], |\n| 15 | }); |\n| 16 |  |\n| 17 | console.log(completion.choices[0].message.content); |\n```\n\nIf the model you selected returns an error, OpenRouter will try to use the fallback model instead. If the fallback model is down or returns an error, OpenRouter will return that error.\n\nBy default, any error can trigger the use of a fallback model, including context length validation errors, moderation flags for filtered models, rate-limiting, and downtime.\n\nRequests are priced using the model that was ultimately used, which will be returned in the `model` attribute of the response body.\n\n## Using with OpenAI SDK\n\nTo use the `models` array with the OpenAI SDK, include it in the `extra_body` parameter. In the example below, gpt-4o will be tried first, and the `models` array will be tried in order as fallbacks.\n\nPythonTypeScript\n\n\n\n--- å— 5 ---\n[Web Search](/docs/features/web-search)\n  + [Zero Completion Insurance](/docs/features/zero-completion-insurance)\n  + [Provisioning API Keys](/docs/features/provisioning-api-keys)\n  + [App Attribution](/docs/app-attribution)\n* API Reference\n\n  + [Overview](/docs/api-reference/overview)\n  + [Streaming](/docs/api-reference/streaming)\n  + [Embeddings](/docs/api-reference/embeddings)\n  + [Limits](/docs/api-reference/limits)\n  + [Authentication](/docs/api-reference/authentication)\n  + [Parameters](/docs/api-reference/parameters)\n  + [Errors](/docs/api-reference/errors)\n  + Responses API\n  + beta.responses\n  + Analytics\n  + Credits\n  + Embeddings\n  + Generations\n  + Models\n  + Endpoints\n  + Parameters\n  + Providers\n  + API Keys\n  + O Auth\n  + Chat\n  + Completions\n* SDK Reference (BETA)\n\n  + [Python SDK](/docs/sdks/python)\n  + [TypeScript SDK](/docs/sdks/typescript)\n* Use Cases\n\n  + [BYOK](/docs/use-cases/byok)\n  + [Crypto API](/docs/use-cases/crypto-api)\n  + [OAuth PKCE](/docs/use-cases/oauth-pkce)\n  + [MCP Servers](/docs/use-cases/mcp-servers)\n  + [Organization Management](/docs/use-cases/organization-management)\n  + [For Providers](/docs/use-cases/for-providers)\n  + [Reasoning Tokens](/docs/use-cases/reasoning-tokens)\n  + [Usage Accounting](/docs/use-cases/usage-accounting)\n  + [User Tracking](/docs/use-cases/user-tracking)\n* Community\n\n  + [Frameworks and Integrations Overview](/docs/community/frameworks-and-integrations-overview)\n  + [Effect AI SDK](/docs/community/effect-ai-sdk)\n  + [Arize](/docs/community/arize)\n  + [LangChain](/docs/community/lang-chain)\n  + [LiveKit](/docs/community/live-kit)\n  + [Langfuse](/docs/community/langfuse)\n  + [Mastra](/docs/community/mastra)\n  + [OpenAI SDK](/docs/community/open-ai-sdk)\n  + [PydanticAI](/docs/community/pydantic-ai)\n  + [Vercel AI SDK](/docs/community/vercel-ai-sdk)\n  + [Xcode](/docs/community/xcode)\n  + [Zapier](/docs/community/zapier)\n  + [Discord](https://discord.gg/openrouter)\n\nLight\n\nOn this page\n\n* [Within OpenRouter](#within-openrouter)\n* [Provider Policies](#provider-policies)\n* [Training on Prompts](#training-on-prompts)\n* [Data Retention & Logging](#data-retention--logging)\n* [Enterprise EU in-region routing](#enterprise-eu-in-region-routing)\n\n[Features](/docs/features/privacy-and-logging)\n\n\n\n--- å— 6 ---\n[Web Search](/docs/features/web-search)\n  + [Zero Completion Insurance](/docs/features/zero-completion-insurance)\n  + [Provisioning API Keys](/docs/features/provisioning-api-keys)\n  + [App Attribution](/docs/app-attribution)\n* API Reference\n\n  + [Overview](/docs/api-reference/overview)\n  + [Streaming](/docs/api-reference/streaming)\n  + [Embeddings](/docs/api-reference/embeddings)\n  + [Limits](/docs/api-reference/limits)\n  + [Authentication](/docs/api-reference/authentication)\n  + [Parameters](/docs/api-reference/parameters)\n  + [Errors](/docs/api-reference/errors)\n  + Responses API\n  + beta.responses\n  + Analytics\n  + Credits\n  + Embeddings\n  + Generations\n  + Models\n  + Endpoints\n  + Parameters\n  + Providers\n  + API Keys\n  + O Auth\n  + Chat\n  + Completions\n* SDK Reference (BETA)\n\n  + [Python SDK](/docs/sdks/python)\n  + [TypeScript SDK](/docs/sdks/typescript)\n* Use Cases\n\n  + [BYOK](/docs/use-cases/byok)\n  + [Crypto API](/docs/use-cases/crypto-api)\n  + [OAuth PKCE](/docs/use-cases/oauth-pkce)\n  + [MCP Servers](/docs/use-cases/mcp-servers)\n  + [Organization Management](/docs/use-cases/organization-management)\n  + [For Providers](/docs/use-cases/for-providers)\n  + [Reasoning Tokens](/docs/use-cases/reasoning-tokens)\n  + [Usage Accounting](/docs/use-cases/usage-accounting)\n  + [User Tracking](/docs/use-cases/user-tracking)\n* Community\n\n  + [Frameworks and Integrations Overview](/docs/community/frameworks-and-integrations-overview)\n  + [Effect AI SDK](/docs/community/effect-ai-sdk)\n  + [Arize](/docs/community/arize)\n  + [LangChain](/docs/community/lang-chain)\n  + [LiveKit](/docs/community/live-kit)\n  + [Langfuse](/docs/community/langfuse)\n  + [Mastra](/docs/community/mastra)\n  + [OpenAI SDK](/docs/community/open-ai-sdk)\n  + [PydanticAI](/docs/community/pydantic-ai)\n  + [Vercel AI SDK](/docs/community/vercel-ai-sdk)\n  + [Xcode](/docs/community/xcode)\n  + [Zapier](/docs/community/zapier)\n  + [Discord](https://discord.gg/openrouter)\n\nLight\n\nOn this page\n\n* [How OpenRouter Manages Data Policies](#how-openrouter-manages-data-policies)\n* [Per-Request ZDR Enforcement](#per-request-zdr-enforcement)\n* [Usage](#usage)\n* [Caching](#caching)\n* [OpenRouterâ€™s Retention Policy](#openrouters-retention-policy)\n* [Zero Retention Endpoints](#zero-retention-endpoints)\n\n[Features](/docs/features/privacy-and-logging)\n\n\nCode\n# é‡Šæ”¾è¿æ¥ä»¥é¿å…æ–‡ä»¶é”å®š\nif (exists(\"store\")) {\n    rm(store)\n    gc()\n}\n\n\n          used  (Mb) gc trigger  (Mb) limit (Mb) max used  (Mb)\nNcells 2385439 127.4    4675528 249.8         NA  3250438 173.6\nVcells 4239754  32.4   10146329  77.5      16384  5558189  42.5\n\n\n\n\nCode\n# ragnar_store_inspect(store)\n#ragnar_chunks_view(chunks)\n\n\n\n\n\nåœ¨ Python ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ LlamaIndex ä¸æˆ‘ä»¬çš„ DuckDB å‘é‡æ•°æ®åº“è¿›è¡Œäº¤äº’ã€‚åœ¨æ­¤æ­¥éª¤ä¸­ï¼Œæˆ‘ä»¬å°†é…ç½®åµŒå…¥æ¨¡å‹å¹¶ä¸ºæŸ¥è¯¢æ£€ç´¢å‰å‡ ä¸ªç›¸å…³å—ï¼Œå¹¶å°†å®ƒä»¬ä¿å­˜åˆ°æ–‡ä»¶ä¸­ä»¥ä¾›æ£€æŸ¥ã€‚æˆ‘ä»¬æš‚ä¸ä½¿ç”¨ LLM è¿›è¡Œç”Ÿæˆï¼Œä»…ä¸“æ³¨äºéªŒè¯æ£€ç´¢è´¨é‡ã€‚\n\né—®é¢˜ï¼šä»€ä¹ˆæ˜¯æ¨¡å‹å˜ä½“ï¼Ÿ(What are model variants?)\nRAG ç»“æœï¼š\n\n\nCode\nimport os\nimport sys\nprint(f\"Python å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„: {sys.executable}\")\n\n\nPython å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„: /Library/Frameworks/Python.framework/Versions/3.13/bin/python3\n\n\nCode\nprint(f\"Python è·¯å¾„ (sys.path): {sys.path}\")\n\n\nPython è·¯å¾„ (sys.path): ['', '/Library/Frameworks/Python.framework/Versions/3.13/bin', '/Library/Frameworks/Python.framework/Versions/3.13/lib/python313.zip', '/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13', '/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/lib-dynload', '/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages', '/Library/Frameworks/R.framework/Versions/4.5-arm64/Resources/library/reticulate/python']\n\n\nCode\nfrom typing import Any, List\nfrom openai import OpenAI\nfrom llama_index.core import VectorStoreIndex, Settings\nfrom llama_index.core.embeddings import BaseEmbedding\nfrom llama_index.vector_stores.duckdb import DuckDBVectorStore\nfrom dotenv import load_dotenv\n\n# åŠ è½½ç¯å¢ƒå˜é‡\nload_dotenv()\n\n\nTrue\n\n\nCode\n# ç¡®ä¿ API å¯†é’¥å¯ç”¨\nopenrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n\n# é’ˆå¯¹ LlamaIndex çš„è‡ªå®šä¹‰ OpenRouter åµŒå…¥ç±»\nclass OpenRouterEmbedding(BaseEmbedding):\n    \"\"\"ä¸ LlamaIndex å…¼å®¹çš„ OpenRouter API è‡ªå®šä¹‰åµŒå…¥ç±»ã€‚\"\"\"\n    \n    def __init__(\n        self,\n        api_key: str,\n        model: str = \"qwen/qwen3-embedding-8b\",\n        **kwargs: Any\n    ):\n        super().__init__(**kwargs)\n        self._client = OpenAI(\n            base_url=\"https://openrouter.ai/api/v1\",\n            api_key=api_key,\n        )\n        self._model = model\n    \n    def _get_query_embedding(self, query: str) -&gt; List[float]:\n        \"\"\"è·å–æŸ¥è¯¢å­—ç¬¦ä¸²çš„åµŒå…¥å‘é‡ã€‚\"\"\"\n        response = self._client.embeddings.create(\n            extra_headers={\n                \"HTTP-Referer\": \"https://ai-blog.com\",\n                \"X-Title\": \"AI Blog RAG\",\n            },\n            model=self._model,\n            input=query,\n            encoding_format=\"float\"\n        )\n        return response.data[0].embedding\n    \n    def _get_text_embedding(self, text: str) -&gt; List[float]:\n        \"\"\"è·å–æ–‡æœ¬å­—ç¬¦ä¸²çš„åµŒå…¥å‘é‡ã€‚\"\"\"\n        return self._get_query_embedding(text)\n    \n    async def _aget_query_embedding(self, query: str) -&gt; List[float]:\n        \"\"\"å¼‚æ­¥ç‰ˆæœ¬çš„ get_query_embeddingã€‚\"\"\"\n        return self._get_query_embedding(query)\n    \n    async def _aget_text_embedding(self, text: str) -&gt; List[float]:\n        \"\"\"å¼‚æ­¥ç‰ˆæœ¬çš„ get_text_embeddingã€‚\"\"\"\n        return self._get_text_embedding(text)\n\n# 1. ä½¿ç”¨è‡ªå®šä¹‰ OpenRouter ç±»é…ç½®åµŒå…¥æ¨¡å‹\nembed_model = OpenRouterEmbedding(\n    api_key=openrouter_api_key,\n    model=\"qwen/qwen3-embedding-8b\"\n)\n\n# 2. åº”ç”¨è®¾ç½®\nSettings.embed_model = embed_model\n\n# åŠ è½½ä¸æ£€ç´¢\n# åŠ è½½ç°æœ‰çš„ DuckDB å‘é‡æ•°æ®åº“\nprint(\"æ­£åœ¨ä» openrouter.duckdb åŠ è½½å‘é‡æ•°æ®åº“...\")\n\n\næ­£åœ¨ä» openrouter.duckdb åŠ è½½å‘é‡æ•°æ®åº“...\n\n\nCode\ntry:\n    vector_store = DuckDBVectorStore(database_name=\"openrouter.duckdb\", persist_dir=\"./persist/\", read_only=True)\n    index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\nexcept Exception as e:\n    print(f\"âš ï¸ æ— æ³•åŠ è½½å‘é‡æ•°æ®åº“ (å¯èƒ½è¢«é”å®š): {e}\")\n    # åˆ›å»ºä¸€ä¸ªç©ºç´¢å¼•ä½œä¸ºå¤‡é€‰ï¼Œæˆ–è€…è·³è¿‡\n    index = None\n\n# å®šä¹‰æŸ¥è¯¢\nquery = \"What are model variants?\"\nprint(f\"\\n{'='*60}\")\n\n\n\n============================================================\n\n\nCode\nprint(f\"æŸ¥è¯¢é—®é¢˜: '{query}'\")\n\n\næŸ¥è¯¢é—®é¢˜: 'What are model variants?'\n\n\nCode\nprint(f\"{'='*60}\\n\")\n\n\n============================================================\n\n\nCode\n# æ£€ç´¢å‰ 3 ä¸ªç›¸å…³å—\nif index:\n    retriever = index.as_retriever(similarity_top_k=5)\n    nodes = retriever.retrieve(query)\nelse:\n    nodes = []\n\n# æ‰“å°è¯¦ç»†æ£€ç´¢ä¿¡æ¯\nprint(f\"ä» DuckDB ä¸­æ£€ç´¢åˆ° {len(nodes)} ä¸ªæ–‡æœ¬å—ï¼š\\n\")\n\n\nä» DuckDB ä¸­æ£€ç´¢åˆ° 5 ä¸ªæ–‡æœ¬å—ï¼š\n\n\nCode\nfor i, node in enumerate(nodes, 1):\n    print(f\"{'â”€'*60}\")\n    print(f\"å— {i}\")\n    print(f\"{'â”€'*60}\")\n\n    # æ‰“å°ç›¸ä¼¼åº¦åˆ†æ•°\n    if hasattr(node, 'score'):\n        print(f\"ç›¸ä¼¼åº¦åˆ†æ•°: {node.score:.4f}\")\n\n    # æ‰“å°å…ƒæ•°æ®\n    if hasattr(node, 'metadata') and node.metadata:\n        print(f\"å…ƒæ•°æ®:\")\n        for key, value in node.metadata.items():\n            print(f\"  - {key}: {value}\")\n\n    # æ‰“å°æ–‡æœ¬å†…å®¹ï¼ˆæˆªæ–­æ˜¾ç¤ºï¼‰\n    text_preview = node.text[:500] + \"...\" if len(node.text) &gt; 500 else node.text\n    print(f\"\\nå†…å®¹é¢„è§ˆ:\\n{text_preview}\\n\")\n\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nå— 1\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nç›¸ä¼¼åº¦åˆ†æ•°: 0.6170\nå…ƒæ•°æ®:\n  - file_path: /Users/jinchaoduan/Documents/post_project/AI_Blog/posts/RAG/markdown_docs/docs_features_exacto-variant.md\n  - file_name: docs_features_exacto-variant.md\n  - file_type: text/markdown\n  - file_size: 7972\n  - creation_date: 2025-11-21\n  - last_modified_date: 2025-11-21\n\nå†…å®¹é¢„è§ˆ:\nSearch\n\n`/`\n\nAsk AI\n\n[API](/docs/api-reference/overview)[Models](https://openrouter.ai/models)[Chat](https://openrouter.ai/chat)[Ranking](https://openrouter.ai/rankings)\n\n* Overview\n\n  + [Quickstart](/docs/quickstart)\n  + [FAQ](/docs/faq)\n  + [Principles](/docs/overview/principles)\n  + [Models](/docs/overview/models)\n  + [Enterprise](https://openrouter.ai/enterprise)\n* Features\n\n  + [Privacy and Logging](/docs/features/privacy-and-logging)\n  + [Zero Data Retention (ZDR)](/docs/features/zdr)\n  + ...\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nå— 2\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nç›¸ä¼¼åº¦åˆ†æ•°: 0.6101\nå…ƒæ•°æ®:\n  - file_path: /Users/jinchaoduan/Documents/post_project/AI_Blog/posts/RAG/markdown_docs/docs_overview_models.md\n  - file_name: docs_overview_models.md\n  - file_type: text/markdown\n  - file_size: 9021\n  - creation_date: 2025-11-21\n  - last_modified_date: 2025-11-21\n\nå†…å®¹é¢„è§ˆ:\nSearch\n\n`/`\n\nAsk AI\n\n[API](/docs/api-reference/overview)[Models](https://openrouter.ai/models)[Chat](https://openrouter.ai/chat)[Ranking](https://openrouter.ai/rankings)\n\n* Overview\n\n  + [Quickstart](/docs/quickstart)\n  + [FAQ](/docs/faq)\n  + [Principles](/docs/overview/principles)\n  + [Models](/docs/overview/models)\n  + [Enterprise](https://openrouter.ai/enterprise)\n* Features\n\n  + [Privacy and Logging](/docs/features/privacy-and-logging)\n  + [Zero Data Retention (ZDR)](/docs/features/zdr)\n  + ...\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nå— 3\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nç›¸ä¼¼åº¦åˆ†æ•°: 0.5821\nå…ƒæ•°æ®:\n  - file_path: /Users/jinchaoduan/Documents/post_project/AI_Blog/posts/RAG/markdown_docs/docs_guides_overview_models.md\n  - file_name: docs_guides_overview_models.md\n  - file_type: text/markdown\n  - file_size: 7557\n  - creation_date: 2026-01-06\n  - last_modified_date: 2026-01-06\n\nå†…å®¹é¢„è§ˆ:\nSearch\n\n`/`\n\nAsk AI\n\n[Models](https://openrouter.ai/models)[Chat](https://openrouter.ai/chat)[Ranking](https://openrouter.ai/rankings)[Docs](/docs/api-reference/overview)\n\n[Docs](/docs/quickstart)[API Reference](/docs/api/reference/overview)[SDK Reference](/docs/sdks/call-model/overview)\n\n[Docs](/docs/quickstart)[API Reference](/docs/api/reference/overview)[SDK Reference](/docs/sdks/call-model/overview)\n\n* Overview\n\n  + [Quickstart](/docs/quickstart)\n  + [Principles](/docs/guides/overview/princi...\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nå— 4\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nç›¸ä¼¼åº¦åˆ†æ•°: 0.5763\nå…ƒæ•°æ®:\n  - file_path: /Users/jinchaoduan/Documents/post_project/AI_Blog/posts/RAG/markdown_docs/docs_faq_how-are-rate-limits-calculated.md\n  - file_name: docs_faq_how-are-rate-limits-calculated.md\n  - file_type: text/markdown\n  - file_size: 17710\n  - creation_date: 2026-01-06\n  - last_modified_date: 2026-01-06\n\nå†…å®¹é¢„è§ˆ:\nSearch\n\n`/`\n\nAsk AI\n\n[Models](https://openrouter.ai/models)[Chat](https://openrouter.ai/chat)[Ranking](https://openrouter.ai/rankings)[Docs](/docs/api-reference/overview)\n\n[Docs](/docs/quickstart)[API Reference](/docs/api/reference/overview)[SDK Reference](/docs/sdks/call-model/overview)\n\n[Docs](/docs/quickstart)[API Reference](/docs/api/reference/overview)[SDK Reference](/docs/sdks/call-model/overview)\n\n* Overview\n\n  + [Quickstart](/docs/quickstart)\n  + [Principles](/docs/guides/overview/princi...\n\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nå— 5\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\nç›¸ä¼¼åº¦åˆ†æ•°: 0.5703\nå…ƒæ•°æ®:\n  - file_path: /Users/jinchaoduan/Documents/post_project/AI_Blog/posts/RAG/markdown_docs/docs_features_model-routing.md\n  - file_name: docs_features_model-routing.md\n  - file_type: text/markdown\n  - file_size: 7024\n  - creation_date: 2025-11-21\n  - last_modified_date: 2025-11-21\n\nå†…å®¹é¢„è§ˆ:\n|\n| 17 | } |\n| 18 | ] |\n| 19 | ) |\n| 20 |  |\n| 21 | print(completion.choices[0].message.content) |\n```\n\nWas this page helpful?\n\nYesNo\n\n[Previous](/docs/features/zdr)[#### Provider Routing\n\nRoute requests to the best provider\n\nNext](/docs/features/provider-routing)[Built with](https://buildwithfern.com/?utm_campaign=buildWith&utm_medium=docs&utm_source=openrouter.ai)\n\n[![Logo](https://files.buildwithfern.com/openrouter.docs.buildwithfern.com/docs/2025-11-21T16:36:36.134Z/content/assets/logo.svg)!...\n\n\nCode\n\n# Save retrieved chunks to a markdown file for easy inspection\n# with open(\"retriever.md\", \"w\", encoding=\"utf-8\") as f:\n#     f.write(f\"# Query: {query}\\n\\n\")\n#     f.write(f\"# Retrieved {len(nodes)} chunks from openrouter.duckdb\\n\\n\")\n#     for i, node in enumerate(nodes, 1):\n#         f.write(f\"{'â”€'*60}\\n\")\n#         f.write(f\"## Chunk {i}\\n\\n\")\n#         if hasattr(node, 'score'):\n#             f.write(f\"**Similarity Score:** {node.score:.4f}\\n\\n\")\n#         if hasattr(node, 'metadata') and node.metadata:\n#             f.write(f\"**Metadata:**\\n\")\n#             for key, value in node.metadata.items():\n#                 f.write(f\"- {key}: {value}\\n\")\n#             f.write(f\"\\n\")\n#         f.write(f\"{node.text}\\n\\n\")\n\n\n\n\n\nç°åœ¨æˆ‘ä»¬çš„çŸ¥è¯†åº“å·²ç»å¡«å……å®Œæ¯•ï¼Œæˆ‘ä»¬å¯ä»¥æµ‹è¯•æ£€ç´¢ç³»ç»Ÿã€‚æˆ‘ä»¬å¯ä»¥æå‡ºä¸€ä¸ªç‰¹å®šçš„é—®é¢˜ï¼Œä¾‹å¦‚â€œä»€ä¹ˆæ˜¯æ¨¡å‹å˜ä½“ï¼Ÿ (What are model variants?)â€ï¼Œå¹¶æŸ¥è¯¢ Chroma å­˜å‚¨åº“ä»¥æŸ¥çœ‹å“ªäº›æ–‡æœ¬å—æœ€ç›¸å…³ã€‚è¿™ç¡®è®¤äº†æˆ‘ä»¬çš„åµŒå…¥å’Œæœç´¢æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚\n\né—®é¢˜ï¼šä»€ä¹ˆæ˜¯æ¨¡å‹å˜ä½“ï¼Ÿ (What are model variants?)\nRAG ç»“æœï¼š\n\n\nCode\nfrom openai import OpenAI\nfrom langchain_core.embeddings import Embeddings\nfrom langchain_chroma import Chroma\nfrom typing import List\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\nTrue\n\n\nCode\n# é’ˆå¯¹ OpenRouter API çš„è‡ªå®šä¹‰åµŒå…¥ç±»\nclass OpenRouterEmbeddings(Embeddings):\n    \"\"\"é’ˆå¯¹ OpenRouter API çš„è‡ªå®šä¹‰åµŒå…¥ç±»ã€‚\"\"\"\n    \n    def __init__(self, api_key: str, model: str = \"qwen/qwen3-embedding-8b\"):\n        self.client = OpenAI(\n            base_url=\"https://openrouter.ai/api/v1\",\n            api_key=api_key,\n        )\n        self.model = model\n    \n    def embed_documents(self, texts: List[str]) -&gt; List[List[float]]:\n        \"\"\"å¯¹æ–‡æ¡£åˆ—è¡¨è¿›è¡ŒåµŒå…¥ã€‚\"\"\"\n        response = self.client.embeddings.create(\n            extra_headers={\n                \"HTTP-Referer\": \"https://ai-blog.com\",\n                \"X-Title\": \"AI Blog RAG\",\n            },\n            model=self.model,\n            input=texts,\n            encoding_format=\"float\"\n        )\n        return [item.embedding for item in response.data]\n    \n    def embed_query(self, text: str) -&gt; List[float]:\n        \"\"\"å¯¹å•ä¸ªæŸ¥è¯¢è¿›è¡ŒåµŒå…¥ã€‚\"\"\"\n        response = self.client.embeddings.create(\n            extra_headers={\n                \"HTTP-Referer\": \"https://ai-blog.com\",\n                \"X-Title\": \"AI Blog RAG\",\n            },\n            model=self.model,\n            input=text,\n            encoding_format=\"float\"\n        )\n        return response.data[0].embedding\n\n# è·å– OpenRouter API å¯†é’¥\nopenrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\nif not openrouter_api_key:\n    raise ValueError(\"æœªåœ¨ç¯å¢ƒå˜é‡ä¸­æ‰¾åˆ° OPENROUTER_API_KEY\")\n\n# ä½¿ç”¨ OpenRouter åˆ›å»ºåµŒå…¥å®ä¾‹\nembeddings = OpenRouterEmbeddings(\n    api_key=openrouter_api_key,\n    model=\"qwen/qwen3-embedding-8b\"\n)\n\n# å®šä¹‰å‘é‡æ•°æ®åº“ä½ç½®\npersist_directory = \"chroma_db_data\"\n\n# åŠ è½½ç°æœ‰çš„å‘é‡æ•°æ®åº“\nvectorstore = Chroma(\n    persist_directory=persist_directory,\n    embedding_function=embeddings\n)\n\n# æµ‹è¯•æŸ¥è¯¢\nquery = \"What are model variants?\"\n\n# æ‰§è¡Œç›¸ä¼¼åº¦æœç´¢\nresults = vectorstore.similarity_search(query, k=5)\n\nprint(f\"\\næŸ¥è¯¢é—®é¢˜: '{query}'\")\n\n\n\næŸ¥è¯¢é—®é¢˜: 'What are model variants?'\n\n\nCode\nprint(f\"æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³å—ï¼š\\n\")\n\n\næ‰¾åˆ° 5 ä¸ªç›¸å…³å—ï¼š\n\n\nCode\nfor i, doc in enumerate(results, 1):\n    print(f\"ç»“æœ {i}:\")\n    print(f\"æ¥æº: {doc.metadata.get('source', 'æœªçŸ¥')}\")\n    print(f\"å†…å®¹é¢„è§ˆ: {doc.page_content[:800]}...\")\n\n\nç»“æœ 1:\næ¥æº: docs_faq_how-are-rate-limits-calculated.md\nå†…å®¹é¢„è§ˆ: ###### What are model variants?\n\nVariants are suffixes that can be added to the model slug to change its behavior.\n\nStatic variants can only be used with specific models and these are listed in our [models api](https://openrouter.ai/api/v1/models).\n\n1. `:free` - The model is always provided for free and has low rate limits.\n2. `:beta` - The model is not moderated by OpenRouter.\n3. `:extended` - The model has longer than usual context length.\n4. `:exacto` - The model only uses OpenRouter-curated high-quality endpoints.\n5. `:thinking` - The model supports reasoning by default.\n\nDynamic variants can be used on all models and they change the behavior of how the request is routed or used.\n\n1. `:online` - All requests will run a query to extract web results that are attached to the prompt.\n2. `:...\nç»“æœ 2:\næ¥æº: docs_faq.md\nå†…å®¹é¢„è§ˆ: ###### What are model variants?\n\nVariants are suffixes that can be added to the model slug to change its behavior.\n\nStatic variants can only be used with specific models and these are listed in our [models api](https://openrouter.ai/api/v1/models).\n\n1. `:free` - The model is always provided for free and has low rate limits.\n2. `:beta` - The model is not moderated by OpenRouter.\n3. `:extended` - The model has longer than usual context length.\n4. `:exacto` - The model only uses OpenRouter-curated high-quality endpoints.\n5. `:thinking` - The model supports reasoning by default.\n\nDynamic variants can be used on all models and they change the behavior of how the request is routed or used.\n\n1. `:online` - All requests will run a query to extract web results that are attached to the prompt.\n2. `:...\nç»“æœ 3:\næ¥æº: docs_use-cases_crypto-api.md\nå†…å®¹é¢„è§ˆ: [API](/docs/api-reference/overview)[Models](https://openrouter.ai/models)[Chat](https://openrouter.ai/chat)[Ranking](https://openrouter.ai/rankings)...\nç»“æœ 4:\næ¥æº: docs_sdks_typescript.md\nå†…å®¹é¢„è§ˆ: [API](/docs/api-reference/overview)[Models](https://openrouter.ai/models)[Chat](https://openrouter.ai/chat)[Ranking](https://openrouter.ai/rankings)...\nç»“æœ 5:\næ¥æº: docs_features_provider-routing.md\nå†…å®¹é¢„è§ˆ: Route requests through OpenRouter-curated providers\n\nNext](/docs/features/exacto-variant)[Built with](https://buildwithfern.com/?utm_campaign=buildWith&utm_medium=docs&utm_source=openrouter.ai)\n\n[![Logo](https://files.buildwithfern.com/openrouter.docs.buildwithfern.com/docs/2025-11-21T16:36:36.134Z/content/assets/logo.svg)![Logo](https://files.buildwithfern.com/openrouter.docs.buildwithfern.com/docs/2025-11-21T16:36:36.134Z/content/assets/logo-white.svg)](https://openrouter.ai/)\n\n[API](/docs/api-reference/overview)[Models](https://openrouter.ai/models)[Chat](https://openrouter.ai/chat)[Ranking](https://openrouter.ai/rankings)...\n\n\n\n\n\n\n\n\nç»“åˆ RAG è¿›è¡ŒèŠå¤© (Chat with RAG)\n\nRPython chatlasPython LangChain\n\n\næœ€åä¸€ä¸ªç¯èŠ‚æ˜¯å°†è¿™ç§æ£€ç´¢èƒ½åŠ›è¿æ¥åˆ°èŠå¤©ç•Œé¢ã€‚æˆ‘ä»¬ä½¿ç”¨ ellmer åˆ›å»ºä¸€ä¸ªèŠå¤©å®¢æˆ·ç«¯ã€‚å…³é”®åœ¨äºï¼Œæˆ‘ä»¬ä½¿ç”¨ ragnar_register_tool_retrieve æ³¨å†Œä¸€ä¸ªâ€œæ£€ç´¢å·¥å…·â€ã€‚è¿™ä½¿ LLM èƒ½å¤Ÿåœ¨éœ€è¦ä¿¡æ¯å›ç­”ç”¨æˆ·é—®é¢˜æ—¶ï¼Œè‡ªä¸»æŸ¥è¯¢æˆ‘ä»¬çš„å‘é‡æ•°æ®åº“ã€‚\næˆ‘ä»¬è¿˜æä¾›äº†ä¸€ä¸ªç³»ç»Ÿæç¤ºè¯ï¼ŒæŒ‡ç¤ºæ¨¡å‹å§‹ç»ˆæ£€æŸ¥çŸ¥è¯†åº“å¹¶å¼•ç”¨å…¶æ¥æºã€‚\n\n\nCode\nlibrary(ellmer)\nlibrary(dotenv)\nlibrary(ragnar)\nload_dot_env(file = \".env\")\n\nchat &lt;- chat_openrouter(\n    api_key = Sys.getenv(\"OPENROUTER_API_KEY\"),\n    model = \"openai/gpt-oss-120b\",\n    system_prompt = glue::trim(\"\n  ä½ æ˜¯ä¸€ä¸ªè´Ÿè´£é—®ç­”ä»»åŠ¡çš„åŠ©æ‰‹ã€‚è¯·ä¿æŒå›å¤ç®€ç»ƒã€‚\n\n  åœ¨å›å¤ä¹‹å‰ï¼Œè¯·ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³ç´ æã€‚å¼•ç”¨æˆ–è½¬è¿°æ®µè½ï¼Œæ¸…æ™°åœ°æ ‡æ³¨å“ªäº›æ˜¯ä½ è‡ªå·±çš„è¯ï¼Œå“ªäº›æ˜¯æ¥æºã€‚\n  ä¸ºä½ å¼•ç”¨çš„æ¯ä¸ªæ¥æºæä¾›ä¸€ä¸ªæœ‰æ•ˆçš„é“¾æ¥ï¼Œä»¥åŠä»»ä½•å…¶ä»–ç›¸å…³çš„é“¾æ¥ã€‚\n  é™¤éä½ å·²ç»æ£€ç´¢å¹¶å¼•ç”¨äº†æ¥æºï¼Œå¦åˆ™ä¸è¦å›ç­”ã€‚å¦‚æœä½ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯´â€œæˆ‘åœ¨çŸ¥è¯†åº“ä¸­æ‰¾ä¸åˆ°ä»»ä½•ç›¸å…³ä¿¡æ¯â€ã€‚\n    \")\n)\n\n# å°è¯•è¿æ¥å­˜å‚¨å¹¶æ³¨å†Œå·¥å…·\nstore_connected &lt;- FALSE\ntryCatch({\n    store &lt;- ragnar_store_connect(\"openrouter.duckdb\")\n    chat &lt;- chat |&gt; ragnar_register_tool_retrieve(store, top_k = 3)\n    store_connected &lt;- TRUE\n}, error = function(e) {\n    message(\"âš ï¸ æ— æ³•è¿æ¥åˆ° DuckDB è¿›è¡Œå·¥å…·æ³¨å†Œ: \", e$message)\n})\n\n\n\né—®é¢˜ï¼šä»€ä¹ˆæ˜¯æ¨¡å‹å˜ä½“ï¼Ÿ(What are model variants?)\n\nCode\nif (store_connected) {\n    chat$chat(\"What are model variants?\")\n    # èŠå¤©ç»“æŸåç«‹å³é‡Šæ”¾é”\n    rm(store)\n    gc()\n} else {\n    cat(\"ç”±äºæ•°æ®åº“é”å®šï¼ŒR èŠå¤©åŠŸèƒ½æš‚æ—¶ä¸å¯ç”¨ã€‚\")\n}\n\næ¨¡å‹å˜ä½“ï¼ˆmodel variantsï¼‰æ˜¯å¯ä»¥åœ¨æ¨¡å‹æ ‡è¯†ï¼ˆslugï¼‰åæ·»åŠ çš„åç¼€ï¼Œç”¨æ¥æ”¹å˜æ¨¡å‹çš„è¡Œä¸ºæ–¹å¼ã€‚\n\né™æ€å˜ä½“åªèƒ½ç”¨äºç‰¹å®šæ¨¡å‹ï¼Œåˆ—åœ¨â€¯Models APIâ€¯ä¸­ã€‚ä¾‹å¦‚ï¼š\n\n:free â€“ å§‹ç»ˆå…è´¹æä¾›ï¼Œä¸”é€Ÿç‡é™åˆ¶è¾ƒä½ã€‚\n\n:beta â€“ ä¸å— OpenRouter å†…å®¹å®¡æŸ¥ã€‚\n\n:extended â€“ æä¾›æ¯”å¸¸è§„æ›´é•¿çš„ä¸Šä¸‹æ–‡é•¿åº¦ã€‚\n\n:exacto â€“ ä»…ä½¿ç”¨ OpenRouter ç²¾é€‰çš„é«˜è´¨é‡ç«¯ç‚¹ã€‚\n\n:thinking â€“ é»˜è®¤æ”¯æŒæ¨ç†ï¼ˆreasoningï¼‰ã€‚\n\nåŠ¨æ€å˜ä½“å¯ä»¥åœ¨æ‰€æœ‰æ¨¡å‹ä¸Šä½¿ç”¨ï¼Œæ”¹å˜è¯·æ±‚çš„è·¯ç”±æˆ–ä½¿ç”¨æ–¹å¼ã€‚ä¾‹å¦‚ï¼š\n\n:online â€“ åœ¨æç¤ºä¸­é™„åŠ ç½‘ç»œæœç´¢ç»“æœã€‚\n\n:nitro â€“ æŒ‰ååé‡æ’åºæä¾›è€…ï¼Œä¼˜å…ˆæ›´å¿«å“åº”ã€‚\n\n:floor â€“ æŒ‰ä»·æ ¼æ’åºæä¾›è€…ï¼Œä¼˜å…ˆæ›´å…·æˆæœ¬æ•ˆç›Šçš„é€‰é¡¹ã€‚\n\n\n\nâ€œVariants are suffixes that can be added to the model slug to change its behavior.â€ã€æ¥æº: OpenRouter FAQ â€“ æ¨¡å‹å’Œæä¾›è€…ã€‘(https://openrouter.ai/docs/faq) used (Mb) gc trigger (Mb) limit (Mb) max used (Mb) Ncells 3083914 164.7 4675528 249.8 NA 4675528 249.8 Vcells 5315244 40.6 10146329 77.5 16384 9527284 72.7\n\n\n\n\næˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨ chatlas åº“æ¥åˆ›å»ºä¸€ä¸ªèŠå¤©ç•Œé¢ã€‚åœ¨è¿™é‡Œï¼Œæˆ‘ä»¬å®šä¹‰äº†ä¸€ä¸ªè‡ªå®šä¹‰å·¥å…· retrieve_trusted_contentï¼Œç”¨äºæŸ¥è¯¢æˆ‘ä»¬çš„ DuckDB ç´¢å¼•ã€‚ç„¶åæˆ‘ä»¬å°†è¿™ä¸ªå·¥å…·æ³¨å†Œåˆ°èŠå¤©æ¨¡å‹ä¸­ï¼Œä½¿å…¶èƒ½å¤Ÿåœ¨å›ç­”ç”¨æˆ·é—®é¢˜æ—¶å¼•å…¥ç›¸å…³ä¿¡æ¯ã€‚\n\né—®é¢˜ï¼šä»€ä¹ˆæ˜¯æ¨¡å‹å˜ä½“ï¼Ÿ(What are model variants?)\n\n\nCode\nimport os\nfrom typing import Any, List\nfrom openai import OpenAI\nimport chatlas as ctl\nfrom llama_index.core import VectorStoreIndex, Settings\nfrom llama_index.core.embeddings import BaseEmbedding\nfrom llama_index.vector_stores.duckdb import DuckDBVectorStore\nfrom dotenv import load_dotenv\nload_dotenv()\n\n\nTrue\n\n\nCode\n# ç¡®ä¿ API å¯†é’¥å¯ç”¨\nopenrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\n\n# é’ˆå¯¹ LlamaIndex çš„è‡ªå®šä¹‰ OpenRouter åµŒå…¥ç±»\nclass OpenRouterEmbedding(BaseEmbedding):\n    \"\"\"ä¸ LlamaIndex å…¼å®¹çš„ OpenRouter API è‡ªå®šä¹‰åµŒå…¥ç±»ã€‚\"\"\"\n\n    def __init__(\n        self,\n        api_key: str,\n        model: str = \"qwen/qwen3-embedding-8b\",\n        **kwargs: Any\n    ):\n        super().__init__(**kwargs)\n        self._client = OpenAI(\n            base_url=\"https://openrouter.ai/api/v1\",\n            api_key=api_key,\n        )\n        self._model = model\n\n    def _get_query_embedding(self, query: str) -&gt; List[float]:\n        \"\"\"è·å–æŸ¥è¯¢å­—ç¬¦ä¸²çš„åµŒå…¥å‘é‡ã€‚\"\"\"\n        response = self._client.embeddings.create(\n            extra_headers={\n                \"HTTP-Referer\": \"https://ai-blog.com\",\n                \"X-Title\": \"AI Blog RAG\",\n            },\n            model=self._model,\n            input=query,\n            encoding_format=\"float\"\n        )\n        return response.data[0].embedding\n\n    def _get_text_embedding(self, text: str) -&gt; List[float]:\n        \"\"\"è·å–æ–‡æœ¬å­—ç¬¦ä¸²çš„åµŒå…¥å‘é‡ã€‚\"\"\"\n        return self._get_query_embedding(text)\n\n    async def _aget_query_embedding(self, query: str) -&gt; List[float]:\n        \"\"\"å¼‚æ­¥ç‰ˆæœ¬çš„ get_query_embeddingã€‚\"\"\"\n        return self._get_query_embedding(query)\n\n    async def _aget_text_embedding(self, text: str) -&gt; List[float]:\n        \"\"\"å¼‚æ­¥ç‰ˆæœ¬çš„ get_text_embeddingã€‚\"\"\"\n        return self._get_text_embedding(text)\n\n# 1. é…ç½®åµŒå…¥æ¨¡å‹\nembed_model = OpenRouterEmbedding(\n    api_key=openrouter_api_key,\n    model=\"qwen/qwen3-embedding-8b\"\n)\nSettings.embed_model = embed_model\n\n# 2. åŠ è½½ç´¢å¼•\ntry:\n    vector_store = DuckDBVectorStore(database_name=\"openrouter.duckdb\", persist_dir=\"./persist/\", read_only=True)\n    index = VectorStoreIndex.from_vector_store(vector_store=vector_store)\n    retriever = index.as_retriever(similarity_top_k=3)\nexcept Exception as e:\n    print(f\"âš ï¸ æ— æ³•åŠ è½½å‘é‡æ•°æ®åº“: {e}\")\n    index = None\n    retriever = None\n\n# 3. å®šä¹‰èŠå¤©å·¥å…·\ndef retrieve_trusted_content(question: str) -&gt; str:\n    \"\"\"\n    åœ¨çŸ¥è¯†åº“ä¸­æ£€ç´¢ä¿¡ä»»çš„å†…å®¹æ¥å›ç­”é—®é¢˜ã€‚\n    \"\"\"\n    if not retriever:\n        return \"çŸ¥è¯†åº“å½“å‰ä¸å¯ç”¨ï¼ˆç”±äºæ•°æ®åº“é”å®šï¼‰ã€‚\"\n    nodes = retriever.retrieve(question)\n    combined_text = \"\\n\\n\".join([f\"Source Content {i+1}:\\n{node.text}\" for i, node in enumerate(nodes)])\n    return combined_text\n\n# 4. è®¾ç½®èŠå¤©æ¨¡å‹å¹¶æ³¨å†Œå·¥å…·\nchat = ctl.ChatOpenRouter(\n    model=\"openai/gpt-oss-120b\",\n    api_key=openrouter_api_key,\n    base_url=\"https://openrouter.ai/api/v1\",\n    system_prompt=\"\"\"\n    ä½ æ˜¯ä¸€ä¸ªè´Ÿè´£é—®ç­”ä»»åŠ¡åŠ©æ‰‹ã€‚è¯·ä¿æŒå›å¤ç®€ç»ƒã€‚\n    åœ¨å›å¤ä¹‹å‰ï¼Œå§‹ç»ˆé€šè¿‡ retrieve_trusted_content å·¥å…·æ£€ç´¢ç›¸å…³ç´ æã€‚\n    \"\"\"\n)\n\nchat.register_tool(retrieve_trusted_content)\n\n# 5. æ‰§è¡ŒèŠå¤©\ntry:\n    response = chat.chat(\"What are model variants?\")\n    print(response)\nexcept Exception as e:\n    print(f\"âš ï¸ èŠå¤©è¿‡ç¨‹å‡ºé”™ (å¯èƒ½æ˜¯æ˜¾ç¤ºå¤„ç†é—®é¢˜): {e}\")\n\n\n&lt;IPython.core.display.HTML object&gt;\n&lt;IPython.core.display.Markdown object&gt;\nâš ï¸ èŠå¤©è¿‡ç¨‹å‡ºé”™ (å¯èƒ½æ˜¯æ˜¾ç¤ºå¤„ç†é—®é¢˜): Failed to create display handle\n\n\n\n\n\nåœ¨ Python çš„ LangChain ä¸­ï¼Œæˆ‘ä»¬è®¾ç½®äº†ä¸€ä¸ªå®Œæ•´çš„ RAG æµæ°´çº¿ã€‚è¿™åŒ…æ‹¬ï¼š 1. æ£€ç´¢å™¨ (Retriever)ï¼šä½¿ç”¨æˆ‘ä»¬çš„ Chroma å‘é‡æ•°æ®åº“ã€‚ 2. æç¤ºè¯æ¨¡ç‰ˆ (Prompt Template)ï¼šæŒ‡ç¤ºæ¨¡å‹ä½¿ç”¨æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡æ¥å›ç­”é—®é¢˜ã€‚ 3. èŠå¤©æ¨¡å‹ (Chat Model)ï¼šä½¿ç”¨ OpenRouter æä¾›çš„ gpt-4oã€‚ 4. è¾“å‡ºè§£æå™¨ (Output Parser)ï¼šç”¨äºæ ¼å¼åŒ–æœ€ç»ˆå“åº”ã€‚\nè¿™ç§æ¨¡å—åŒ–æ–¹æ³•æ˜¯æ„å»ºç”Ÿäº§çº§ AI åº”ç”¨ç¨‹åºçš„å…¸å‹æ–¹å¼ã€‚\n\né—®é¢˜ï¼šä»€ä¹ˆæ˜¯æ¨¡å‹å˜ä½“ï¼Ÿ(What are model variants?)\n\n\nCode\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.output_parsers import StrOutputParser\nfrom openai import OpenAI\nfrom langchain_core.embeddings import Embeddings\nfrom langchain_chroma import Chroma\nfrom typing import List\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\n\nTrue\n\n\nCode\n# é’ˆå¯¹ LangChain çš„è‡ªå®šä¹‰ OpenRouter åµŒå…¥ç±»\nclass OpenRouterEmbeddings(Embeddings):\n    def __init__(self, api_key: str, model: str = \"qwen/qwen3-embedding-8b\"):\n        self._client = OpenAI(\n            base_url=\"https://openrouter.ai/api/v1\",\n            api_key=api_key,\n        )\n        self._model = model\n\n    def embed_documents(self, texts: List[str]) -&gt; List[List[float]]:\n        \"\"\"åµŒå…¥æ–‡æ¡£åˆ—è¡¨ã€‚\"\"\"\n        response = self._client.embeddings.create(\n            model=self._model,\n            input=texts\n        )\n        return [d.embedding for d in response.data]\n\n    def embed_query(self, text: str) -&gt; List[float]:\n        \"\"\"åµŒå…¥å•ä¸ªæŸ¥è¯¢ã€‚\"\"\"\n        response = self._client.embeddings.create(\n            model=self._model,\n            input=text\n        )\n        return response.data[0].embedding\n\n# è·å– OpenRouter API å¯†é’¥\nopenrouter_api_key = os.getenv(\"OPENROUTER_API_KEY\")\nif not openrouter_api_key:\n    raise ValueError(\"æœªåœ¨ç¯å¢ƒå˜é‡ä¸­æ‰¾åˆ° OPENROUTER_API_KEY\")\n\n# ä½¿ç”¨ OpenRouter åˆ›å»ºåµŒå…¥å®ä¾‹\nembeddings = OpenRouterEmbeddings(\n    api_key=openrouter_api_key,\n    model=\"qwen/qwen3-embedding-8b\"\n)\n\n# å®šä¹‰å‘é‡æ•°æ®åº“ä½ç½®\npersist_directory = \"chroma_db_data\"\n\n# åŠ è½½ç°æœ‰çš„å‘é‡æ•°æ®åº“\nprint(f\"æ­£åœ¨ä» {persist_directory} åŠ è½½ç°æœ‰å‘é‡æ•°æ®åº“...\")\n\n\næ­£åœ¨ä» chroma_db_data åŠ è½½ç°æœ‰å‘é‡æ•°æ®åº“...\n\n\nCode\nvectorstore = Chroma(\n    persist_directory=persist_directory,\n    embedding_function=embeddings\n)\nprint(f\"âœ“ å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸ\")\n\n\nâœ“ å‘é‡æ•°æ®åº“åŠ è½½æˆåŠŸ\n\n\nCode\n# ä½¿ç”¨ OpenRouter åˆå§‹åŒ– LLM\nllm = ChatOpenAI(\n    model=\"openai/gpt-oss-120b\",\n    openai_api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n    openai_api_base=\"https://openrouter.ai/api/v1\"\n)\n\n# åˆ›å»ºæç¤ºè¯æ¨¡ç‰ˆ\nsystem_prompt = (\n    \"ä½ æ˜¯ä¸€ä¸ªè´Ÿè´£é—®ç­”ä»»åŠ¡åŠ©æ‰‹ã€‚\"\n    \"è¯·ä½¿ç”¨ä»¥ä¸‹æ£€ç´¢åˆ°çš„ç´ ææ¥å›ç­”é—®é¢˜ã€‚\"\n    \"å¦‚æœä½ ä¸çŸ¥é“ç­”æ¡ˆï¼Œè¯·ä¸è¦èƒ¡ç¼–ä¹±é€ ã€‚\"\n    \"æœ€å¤šä½¿ç”¨ä¸‰å¥è¯ï¼Œå¹¶ä¿æŒå›å¤ç®€ç»ƒã€‚\"\n    \"\\n\\n\"\n    \"ç´ æ: {context}\"\n    \"\\n\\n\"\n    \"é—®é¢˜: {question}\"\n)\n\nprompt = ChatPromptTemplate.from_template(system_prompt)\n\n# åˆ›å»ºæ£€ç´¢å™¨\nretriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n\n# ç”¨äºæ ¼å¼åŒ–æ–‡æ¡£çš„è¾…åŠ©å‡½æ•°\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\n# ä½¿ç”¨ LCEL æ„å»º RAG é“¾\nrag_chain = (\n    {\n        \"context\": retriever | format_docs,\n        \"question\": RunnablePassthrough()\n    }\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n\nprint(\"âœ“ RAG é“¾åˆ›å»ºæˆåŠŸï¼\")\n\n\nâœ“ RAG é“¾åˆ›å»ºæˆåŠŸï¼\n\n\nCode\n# æµ‹è¯• RAG é“¾\nquestion = \"What are model variants?\"\n\nprint(f\"\\næŸ¥è¯¢é—®é¢˜: {question}\")\n\n\n\næŸ¥è¯¢é—®é¢˜: What are model variants?\n\n\nCode\n# ç‹¬ç«‹è·å–ä¸Šä¸‹æ–‡æ–‡æ¡£ä»¥ä¾¿å±•ç¤º\ncontext_docs = retriever.invoke(question)\n\n# è°ƒç”¨ RAG é“¾\nanswer = rag_chain.invoke(question)\nimport textwrap\n\nfor line in answer.split('\\n'):\n    print(textwrap.fill(line, width=80))\n\n\næ¨¡å‹å˜ä½“æ˜¯å¯ä»¥é™„åŠ åœ¨æ¨¡å‹æ ‡è¯†ç¬¦åé¢çš„åç¼€ï¼Œç”¨æ¥æ”¹å˜åŒ–æ¨¡å‹çš„è¡Œä¸ºæˆ–è·¯ç”±æ–¹å¼ã€‚é™æ€å˜ä½“ï¼ˆå¦‚\n`:free`ã€`:beta`ã€`:extended`ã€`:exacto`ã€`:thinking`ï¼‰ä»…é€‚ç”¨äºç‰¹å®šæ¨¡å‹ï¼Œè€ŒåŠ¨æ€å˜ä½“ï¼ˆå¦‚\n`:online`ã€`:nitro`ã€`:floor`ï¼‰å¯åœ¨æ‰€æœ‰æ¨¡å‹ä¸Šä½¿ç”¨ï¼Œåˆ†åˆ«æä¾›ç½‘ç»œæœç´¢ã€ä¼˜å…ˆé«˜ååæˆ–ä½ä»·æ ¼çš„è·¯ç”±ç­–ç•¥ã€‚"
  },
  {
    "objectID": "posts/gdp-trend/index.html",
    "href": "posts/gdp-trend/index.html",
    "title": "ä½¿ç”¨ AI SQL æ„å»ºçš„äº¤äº’å¼ GDP è¶‹åŠ¿çœ‹æ¿",
    "section": "",
    "text": "GDP è¶‹åŠ¿çœ‹æ¿ (GDP Trend Dashboard) æ˜¯ä¸€ä¸ªå¤æ‚çš„ Web åº”ç”¨ç¨‹åºï¼Œç”¨äºå¯è§†åŒ–å’Œåˆ†ææ¥è‡ªä¸–ç•Œé“¶è¡Œ API çš„ç»æµæ•°æ®ã€‚è¯¥ç³»ç»Ÿçš„ç‹¬ç‰¹ä¹‹å¤„åœ¨äºå…¶åŒé‡æ–¹æ³•ï¼šå°†ä¼ ç»Ÿçš„äº¤äº’å¼å¯è§†åŒ–ä¸ AI é©±åŠ¨çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢ç›¸ç»“åˆï¼Œä½¿æŠ€æœ¯åˆ†æå¸ˆå’Œæ™®é€šç”¨æˆ·éƒ½èƒ½è½»æ¾è·å–ç»æµæ•°æ®ã€‚\nåœ¨çº¿æ¼”ç¤ºï¼šhttps://world-GDP-trend.streamlit.app\nGithubï¼šhttps://github.com/JCwinning/GDP_trend\n\nGDP è¶‹åŠ¿AI æŸ¥è¯¢ç•Œé¢AI æ‘˜è¦ç”Ÿæˆ\n\n\näº¤äº’å¼å…¨çƒ GDP è¶‹åŠ¿å¯è§†åŒ–\n\n\n\näº¤äº’å¼ AI é©±åŠ¨çš„è‡ªç„¶è¯­è¨€è½¬ SQL\n\n\n\nAI ç”Ÿæˆçš„ç»æµæ•°æ®æ´è§æ‘˜è¦\n\n\n\n\n\n\n\n\n\nä¸»è¦æ¡†æ¶ï¼šç”¨äºäº¤äº’å¼ Web åº”ç”¨çš„ Streamlit\næ•°æ®å¤„ç†ï¼šç”¨äºæ•°æ®æ“ä½œå’Œåˆ†æçš„ Pandas\nå¯è§†åŒ–ï¼šç”¨äºäº¤äº’å¼å›¾è¡¨çš„ Plotly Express\næ•°æ®åº“ï¼šç”¨äºé«˜æ•ˆ SQL æŸ¥è¯¢çš„ DuckDB\nAI é›†æˆï¼šç”¨äºè‡ªç„¶è¯­è¨€è½¬ SQL çš„ ModelScope GLM-4.6\næ•°æ®æºï¼šé€šè¿‡ wbgapi åº“è°ƒç”¨çš„ä¸–ç•Œé“¶è¡Œ API\n\n\n\n\n\nå¤šå›½ GDP è¶‹åŠ¿å¯¹æ¯”\næ”¯æŒå¤šç§ç»æµæŒ‡æ ‡ï¼ˆGDPã€äººå‡ GDPã€äººå£ã€åŒæ¯”å¢é•¿ç‡ï¼‰\nAI é©±åŠ¨çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢\nä½¿ç”¨ DuckDB çš„ç›´æ¥ SQL æ¥å£\nå®Œå–„çš„åŒè¯­æ”¯æŒï¼ˆä¸­/è‹±æ–‡ï¼‰\nå¸¦äº¤äº’æ§åˆ¶çš„æ—¶é—´èŒƒå›´ç­›é€‰ï¼ˆ2000å¹´è‡³ä»Šï¼‰\n\n\n\n\n\nè¯¥åº”ç”¨ç¨‹åºå®ç°äº†ä¸€ä¸ªå¤æ‚çš„æ•°æ®æµæ°´çº¿ï¼Œä»¥ç¡®ä¿æ•°æ®è´¨é‡å’Œå®æ—¶å¯ç”¨æ€§ï¼š\n\n\n\n\n\nflowchart TD\n    A[ä¸–ç•Œé“¶è¡Œ API] --&gt; B[æ•°æ®é‡‡é›†&lt;br/&gt;download_data.py]\n    B --&gt; C[æ•°æ®å¤„ç†&lt;br/&gt;å›½å®¶æ˜ å°„ã€æŒ‡æ ‡è®¡ç®—]\n    C --&gt; D[æ•°æ®å­˜å‚¨&lt;br/&gt;CSV æ–‡ä»¶]\n\n    D --&gt; E[Streamlit åº”ç”¨&lt;br/&gt;app.py]\n    E --&gt; F[DuckDB&lt;br/&gt;å†…å­˜ SQL]\n\n    F --&gt; G[å¯è§†åŒ–å¼•æ“&lt;br/&gt;Plotly Express]\n    F --&gt; H[AI æŸ¥è¯¢å¼•æ“&lt;br/&gt;ModelScope API]\n    F --&gt; I[ä¼šè¯ç®¡ç†&lt;br/&gt;ç”¨æˆ·çŠ¶æ€]\n\n    G --&gt; J[äº¤äº’å¼å›¾è¡¨]\n    H --&gt; K[è‡ªç„¶è¯­è¨€&lt;br/&gt;è½¬ SQL]\n    I --&gt; L[æŒä¹…åŒ–&lt;br/&gt;æŸ¥è¯¢ç»“æœ]\n\n    J --&gt; M[ç”¨æˆ·ç•Œé¢]\n    K --&gt; M\n    L --&gt; M\n\n\n GDP åº”ç”¨æ¶æ„ \n\n\n\n\n\n\n\n\nåº”ç”¨ç¨‹åºä½¿ç”¨ä¸–ç•Œé“¶è¡Œ API é‡‡é›†å…¨é¢çš„ç»æµæ•°æ®ï¼š\n\n\nCode\nimport wbgapi as wb\nimport pycountry\nimport pandas as pd\n\ndef download_economic_data():\n    \"\"\"ä»ä¸–ç•Œé“¶è¡Œ API ä¸‹è½½æ‰€æœ‰å›½å®¶çš„ GDP æ•°æ®\"\"\"\n\n    # å®šä¹‰è¦ä¸‹è½½çš„ç»æµæŒ‡æ ‡\n    indicators = {\n        'gdp_current_usd': 'NY.GDP.MKTP.CD',\n        'gdp_per_capita_current_usd': 'NY.GDP.PCAP.CD',\n        'population_total': 'SP.POP.TOTL'\n    }\n\n    # ä¸‹è½½ 2000 å¹´è‡³ä»Šçš„æ•°æ®\n    data_frames = []\n    for indicator_name, indicator_code in indicators.items():\n        df = wb.get_series(\n            series=indicator_code,\n            economy='all',\n            time='2000:2024',\n            simplify_index=True\n        )\n\n        # å¤„ç†å¹¶æ·»åŠ åˆ°é›†åˆ\n        df = df.reset_index()\n        df['indicator'] = indicator_name\n        data_frames.append(df)\n\n    # åˆå¹¶æ‰€æœ‰æŒ‡æ ‡\n    combined_df = pd.concat(data_frames, ignore_index=True)\n    return combined_df\n\ndef create_country_reference_table():\n    \"\"\"åˆ›å»ºåŒ…å« ISO ä»£ç çš„å®Œæ•´å›½å®¶å…ƒæ•°æ®è¡¨\"\"\"\n    countries = list(pycountry.countries)\n\n    df_all = pd.DataFrame([{\n        'country_name': country.name,\n        'country_code_2': country.alpha_2,\n        'country_code_3': country.alpha_3\n    } for country in countries])\n\n    # æ·»åŠ å¤§æ´²æ˜ å°„\n    iso_to_continent = {\n        \"US\": \"North America\", \"CN\": \"Asia\", \"JP\": \"Asia\",\n        \"DE\": \"Europe\", \"GB\": \"Europe\", \"FR\": \"Europe\"\n        # ... ä¸ºæ‰€æœ‰å›½å®¶å®Œæˆæ˜ å°„\n    }\n\n    df_all['continent'] = df_all['country_code_2'].map(iso_to_continent)\n    return df_all\n\n\n\n\n\nåº”ç”¨ç¨‹åºä½¿ç”¨æ¸…æ™°ã€è§„èŒƒåŒ–çš„æ•°æ®ç»“æ„ï¼š\n\n\nCode\n-- ä¸»è¦æ•°æ®æ¨¡å¼\nCREATE TABLE df_gdp (\n    country_name TEXT,        -- æ˜¾ç¤ºåç§° (è‹±æ–‡)\n    country_code_2 TEXT,      -- ISO alpha-2 ä»£ç \n    country_code_3 TEXT,      -- ISO alpha-3 ä»£ç \n    continent TEXT,            -- å¤§æ´²åˆ†ç±»\n    year INTEGER,              -- æ•°æ®å¹´ä»½\n    indicator TEXT,            -- ç»æµæŒ‡æ ‡åç§°\n    value REAL                -- æŒ‡æ ‡æ•°å€¼\n);\n\n-- ç¤ºä¾‹æ•°æ®\nINSERT INTO df_gdp VALUES\n('United States', 'US', 'USA', 'North America', 2023, 'gdp_current_usd', 27444144.3),\n('United States', 'US', 'USA', 'North America', 2023, 'gdp_per_capita_current_usd', 81254.2),\n('United States', 'US', 'USA', 'North America', 2023, 'population_total', 334914895.0);\n\n\n\n\n\n\n\n\nåº”ç”¨ç¨‹åºä½¿ç”¨ Plotly Express åˆ›å»ºäº¤äº’å¼å›¾è¡¨ï¼Œå¹¶ä¿æŒä¸€è‡´çš„é¢œè‰²ç¼–ç ï¼š\n\n\nCode\nimport plotly.express as px\n\n@st.cache_data\ndef load_data():\n    \"\"\"åŠ è½½å¹¶ç¼“å­˜ GDP æ•°æ®\"\"\"\n    return pd.read_csv('data/gdp_data_2000_present.csv')\n\ndef create_gdp_trend_chart(selected_countries, selected_indicator, year_range):\n    \"\"\"åˆ›å»ºäº¤äº’å¼ GDP è¶‹åŠ¿å¯è§†åŒ–\"\"\"\n\n    # åŠ è½½ç­›é€‰åçš„æ•°æ®\n    df = load_data()\n\n    # åº”ç”¨ç­›é€‰æ¡ä»¶\n    filtered_df = df[\n        (df['country_name'].isin(selected_countries)) &\n        (df['indicator'] == selected_indicator) &\n        (df['year'].between(year_range[0], year_range[1]))\n    ]\n\n    # åˆ›å»ºäº¤äº’å¼æŠ˜çº¿å›¾\n    fig = px.line(\n        filtered_df,\n        x='year',\n        y='value',\n        color='country_name',\n        title=f'{selected_indicator.replace(\"_\", \" \").title()} è¶‹åŠ¿',\n        labels={\n            'year': 'å¹´ä»½',\n            'value': format_indicator_label(selected_indicator),\n            'country_name': 'å›½å®¶'\n        }\n    )\n\n    # è‡ªå®šä¹‰å›¾è¡¨å¤–è§‚\n    fig.update_layout(\n        xaxis_title=\"å¹´ä»½\",\n        yaxis_title=format_indicator_label(selected_indicator),\n        hovermode='x unified',\n        showlegend=True,\n        legend=dict(\n            orientation=\"h\",\n            yanchor=\"bottom\",\n            y=1.02,\n            xanchor=\"right\",\n            x=1\n        )\n    )\n\n    return fig\n\ndef format_indicator_label(indicator):\n    \"\"\"æ ¼å¼åŒ–æŒ‡æ ‡åç§°ä»¥ä¾›æ˜¾ç¤º\"\"\"\n    labels = {\n        'gdp_current_usd': 'GDP (ç°ä»·ç¾å…ƒ)',\n        'gdp_per_capita_current_usd': 'äººå‡ GDP (ç°ä»·ç¾å…ƒ)',\n        'population_total': 'æ€»äººå£',\n        'gdp_per_capita_current_usd_yoy': 'äººå‡ GDP åŒæ¯”å¢é•¿ç‡ (%)'\n    }\n    return labels.get(indicator, indicator.replace('_', ' ').title())\n\n\n\n\n\n\n\n\nè¯¥ç¨‹åºæœ€å…·åˆ›æ–°æ€§çš„åŠŸèƒ½æ˜¯ AI é©±åŠ¨çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼š\n\n\nCode\nfrom openai import OpenAI\nimport duckdb\n\ndef generate_sql_from_question(question, language):\n    \"\"\"ä½¿ç”¨ ModelScope API å°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸º SQL æŸ¥è¯¢\"\"\"\n\n    # è·å–æ•°æ®åº“æ¨¡å¼ä¸Šä¸‹æ–‡\n    schema_info = \"\"\"\n    è¡¨å: df_gdp\n    åˆ—å:\n    - country_name (TEXT): å›½å®¶æ˜¾ç¤ºåç§°\n    - country_code_2 (TEXT): ISO alpha-2 å›½å®¶ä»£ç \n    - continent (TEXT): å¤§æ´²åˆ†ç±»\n    - year (INTEGER): æ•°æ®å¹´ä»½ (2000-2024)\n    - indicator (TEXT): ç»æµæŒ‡æ ‡åç§°\n    - value (REAL): æŒ‡æ ‡æ•°å€¼\n\n    å¯ç”¨æŒ‡æ ‡:\n    - gdp_current_usd: ç°ä»· GDP (ç¾å…ƒ)\n    - gdp_per_capita_current_usd: ç°ä»·äººå‡ GDP (ç¾å…ƒ)\n    - population_total: æ€»äººå£\n    - gdp_per_capita_current_usd_yoy: äººå‡ GDP åŒæ¯”å¢é•¿ç‡ (%)\n    \"\"\"\n\n    # åˆ›å»ºç‰¹å®šè¯­è¨€çš„æç¤ºè¯\n    if language == \"zh\":\n        prompt = f\"\"\"è¯·å°†ä»¥ä¸‹è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸ºSQLæŸ¥è¯¢ï¼Œä»…è¿”å›SQLè¯­å¥ï¼Œä¸è¦è§£é‡Šã€‚\n\næ•°æ®åº“ä¿¡æ¯ï¼š\n{schema_info}\n\nç”¨æˆ·é—®é¢˜ï¼š{question}\n\nè¦æ±‚ï¼š\n1. åªè¿”å›æ ‡å‡†çš„SELECTè¯­å¥\n2. ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ³¨é‡Š\n3. ä½¿ç”¨LIMIT 50é™åˆ¶ç»“æœæ•°é‡\"\"\"\n    else:\n        # (ä¿æŒåŸè‹±æ–‡ prompt)\n        prompt = f\"\"\"Convert the following natural language question to SQL query. Return only the SQL statement, no explanation.\n\nDatabase information:\n{schema_info}\n\nUser question: {question}\n\nRequirements:\n1. Return only standard SELECT statement\n2. Do not add any explanation or comments\n3. Use LIMIT 50 to restrict results\"\"\"\n\n    # è°ƒç”¨ ModelScope API\n    client = OpenAI(\n        api_key=os.getenv('MODELSCOPE_API_KEY'),\n        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n    )\n\n    response = client.chat.completions.create(\n        model=\"qwen/Qwen3-235B\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        temperature=0.1,  # ä½¿ç”¨ä½æ¸©åº¦ä»¥è·å¾—ä¸€è‡´çš„ SQL\n        max_tokens=500\n    )\n\n    return response.choices[0].message.content.strip()\n\n\n\n\n\n\n\nCode\ndef execute_query_with_ai_summary(sql_query, original_question):\n    \"\"\"æ‰§è¡Œ SQL æŸ¥è¯¢å¹¶ç”Ÿæˆ AI æ‘˜è¦\"\"\"\n\n    try:\n        # ä½¿ç”¨ DuckDB æ‰§è¡ŒæŸ¥è¯¢\n        conn = duckdb.connect()\n        result_df = conn.execute(sql_query).fetchdf()\n\n        # å°†ç»“æœå­˜å…¥ä¼šè¯çŠ¶æ€\n        st.session_state.sql_result = result_df\n        st.session_state.sql_query = sql_query\n\n        # å¦‚æœæœ‰æ•°æ®ï¼Œç”Ÿæˆ AI æ‘˜è¦\n        if not result_df.empty:\n            generate_ai_summary(result_df, original_question)\n\n        return result_df\n\n    except Exception as e:\n        st.error(f\"æŸ¥è¯¢æ‰§è¡Œé”™è¯¯: {str(e)}\")\n        return None\n\ndef generate_ai_summary(data_frame, question):\n    \"\"\"ç”ŸæˆæŸ¥è¯¢ç»“æœçš„ AI æ‘˜è¦\"\"\"\n\n    # å°† DataFrame è½¬æ¢ä¸ºæ–‡æœ¬ä»¥ä¾¿åˆ†æ\n    data_summary = data_frame.to_string(index=False)\n\n    summary_prompt = f\"\"\"æ ¹æ®ä»¥ä¸‹æ•°æ®åˆ†æç»“æœï¼Œæä¾›ä¸€ä¸ªç®€æ˜æ‰¼è¦çš„æ‘˜è¦ï¼š\n\nåŸå§‹é—®é¢˜ï¼š{question}\n\næŸ¥è¯¢ç»“æœï¼š\n{data_summary}\n\nè¯·æä¾›ï¼š\n1. å…³é”®å‘ç°çš„ç®€è¦åˆ†æ\n2. ä»»ä½•å€¼å¾—æ³¨æ„çš„è¶‹åŠ¿æˆ–æ¨¡å¼\n3. æ¥è‡ªæ•°æ®çš„é‡è¦è§è§£\n\nè¯·å°†æ‘˜è¦æ§åˆ¶åœ¨ 200 å­—ä»¥å†…ï¼Œå¹¶ç¡®ä¿é€šä¿—æ˜“æ‡‚ã€‚\"\"\"\n\n    # ä½¿ç”¨ AI ç”Ÿæˆæ‘˜è¦\n    client = OpenAI(\n        api_key=os.getenv('MODELSCOPE_API_KEY'),\n        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n    )\n\n    response = client.chat.completions.create(\n        model=\"qwen/Qwen3-235B\",\n        messages=[{\"role\": \"user\", \"content\": summary_prompt}],\n        temperature=0.3,\n        max_tokens=300\n    )\n\n    st.session_state.ai_summary = response.choices[0].message.content\n\n\n\n\n\nAI æŸ¥è¯¢ç•Œé¢ - è‡ªç„¶è¯­è¨€å¤„ç†\n\n\n\n\n\n\n\n\nåº”ç”¨ç¨‹åºå®ç°äº†å…¨é¢çš„ä¸­/è‹±æ–‡æ”¯æŒï¼š\n\n\nCode\n# language.py - å®Œæ•´çš„ç¿»è¯‘ç³»ç»Ÿ\ntranslations = {\n    \"en\": {\n        \"title\": \"ğŸŒ GDP Trend Dashboard\",\n        \"gdp_trend\": \"GDP Trend\",\n        \"ai_powered_chat\": \"AI-Powered Data Chat\",\n        \"default_question\": \"What is the average GDP per capita for China, Japan, and Korea during 2020 to 2023?\"\n    },\n    \"zh\": {\n        \"title\": \"ğŸŒ GDP è¶‹åŠ¿çœ‹æ¿\",\n        \"gdp_trend\": \"GDP è¶‹åŠ¿\",\n        \"ai_powered_chat\": \"AI æ•°æ®å¯¹è¯\",\n        \"default_question\": \"2020å¹´è‡³2023å¹´æœŸé—´ï¼Œä¸­å›½ã€æ—¥æœ¬å’ŒéŸ©å›½çš„å¹³å‡äººå‡GDPæ˜¯å¤šå°‘ï¼Ÿ\"\n    }\n}\n\ndef get_text(key):\n    \"\"\"è·å–å½“å‰è¯­è¨€çš„ç¿»è¯‘æ–‡æœ¬\"\"\"\n    language = st.session_state.get(\"language\", \"en\")\n    return translations.get(language, {}).get(key, key)\n\n# UI ä¸­çš„è¯­è¨€åˆ‡æ¢\ncol1, col2 = st.columns([1, 1])\nwith col1:\n    if st.button(\"English\"):\n        st.session_state.language = \"en\"\n        st.rerun()\nwith col2:\n    if st.button(\"ä¸­æ–‡\"):\n        st.session_state.language = \"zh\"\n        st.rerun()\n\n\n\n\n\n\n\n\n\n\nCode\ndef main():\n    \"\"\"é‡‡ç”¨æ ‡ç­¾é¡µå¯¼èˆªçš„ä¸»åº”ç”¨ç¨‹åº\"\"\"\n\n    # å³ä¸Šè§’çš„è¯­è¨€åˆ‡æ¢\n    with st.container():\n        st.markdown(\"\"\"\n        &lt;div class=\"language-toggle\"&gt;\n            &lt;button onclick=\"setLanguage('en')\"&gt;EN&lt;/button&gt;\n            &lt;button onclick=\"setLanguage('zh')\"&gt;ä¸­æ–‡&lt;/button&gt;\n        &lt;/div&gt;\n        \"\"\", unsafe_allow_html=True)\n\n    st.title(get_text(\"title\"))\n\n    # æ ‡ç­¾é¡µç•Œé¢\n    tab1, tab2 = st.tabs([get_text(\"gdp_trend\"), get_text(\"query\")])\n\n    with tab1:\n        render_gdp_trends_tab()\n\n    with tab2:\n        render_query_interface_tab()\n\ndef render_gdp_trends_tab():\n    \"\"\"æ¸²æŸ“ GDP è¶‹åŠ¿å¯è§†åŒ–æ ‡ç­¾é¡µ\"\"\"\n\n    st.header(get_text(\"gdp_trend\"))\n\n    # åŠ è½½æ•°æ®\n    df = load_data()\n\n    # ç­›é€‰æ§åˆ¶\n    col1, col2, col3 = st.columns([2, 1, 1])\n\n    with col1:\n        selected_countries = st.multiselect(\n            get_text(\"select_countries\"),\n            options=df['country_name'].unique(),\n            default=['United States', 'China', 'Japan']\n        )\n\n    with col2:\n        selected_indicator = st.selectbox(\n            get_text(\"select_indicator\"),\n            options=[\n                'gdp_current_usd',\n                'gdp_per_capita_current_usd',\n                'population_total',\n                'gdp_per_capita_current_usd_yoy'\n            ],\n            format_func=lambda x: format_indicator_label(x)\n        )\n\n    with col3:\n        year_range = st.slider(\n            get_text(\"select_year_range\"),\n            min_value=2000,\n            max_value=2024,\n            value=(2010, 2024),\n            step=1\n        )\n\n    # ç”Ÿæˆå¹¶æ˜¾ç¤ºå›¾è¡¨\n    if selected_countries and selected_indicator:\n        fig = create_gdp_trend_chart(selected_countries, selected_indicator, year_range)\n        st.plotly_chart(fig, use_container_width=True)\n\n        # æ˜¾ç¤ºåŸå§‹æ•°æ®é€‰é¡¹\n        if st.checkbox(get_text(\"show_raw_data\")):\n            display_filtered_data_table(selected_countries, selected_indicator, year_range)\n\ndef render_query_interface_tab():\n    \"\"\"æ¸²æŸ“ AI é©±åŠ¨çš„æŸ¥è¯¢ç•Œé¢æ ‡ç­¾é¡µ\"\"\"\n\n    st.header(get_text(\"ai_powered_chat\"))\n    st.markdown(get_text(\"ai_chat_description\"))\n\n    # è‡ªç„¶è¯­è¨€è¾“å…¥\n    user_question = st.text_input(\n        get_text(\"your_question\"),\n        value=st.session_state.get(\"user_question\", get_text(\"default_question\"))\n    )\n\n    col1, col2 = st.columns([1, 1])\n\n    with col1:\n        if st.button(get_text(\"run_ai\"), type=\"primary\"):\n            if user_question:\n                with st.spinner(\"AI æ­£åœ¨å¤„ç†...\"):\n                    # ä»è‡ªç„¶è¯­è¨€ç”Ÿæˆ SQL\n                    sql_query = generate_sql_from_question(\n                        user_question,\n                        st.session_state.language\n                    )\n\n                    if sql_query:\n                        # æ‰§è¡ŒæŸ¥è¯¢å¹¶ç”Ÿæˆæ‘˜è¦\n                        result_df = execute_query_with_ai_summary(sql_query, user_question)\n\n                        st.session_state.user_question = user_question\n                        st.session_state.should_generate_ai_summary = True\n\n    # æ˜¾ç¤ºç»“æœ\n    if st.session_state.get(\"sql_result\") is not None:\n        display_query_results()\n\n\n\n\n\n\n\n\n\n\nCode\n# Streamlit æ•°æ®æ“ä½œç¼“å­˜\n@st.cache_data(ttl=3600)  # ç¼“å­˜ 1 å°æ—¶\ndef load_data():\n    \"\"\"åŠ è½½å¹¶ç¼“å­˜ GDP æ•°æ®\"\"\"\n    return pd.read_csv('data/gdp_data_2000_present.csv')\n\n@st.cache_data(ttl=1800)  # ç¼“å­˜ 30 åˆ†é’Ÿ\ndef get_country_list():\n    \"\"\"è·å–å¹¶ç¼“å­˜å”¯ä¸€çš„å›½å®¶åˆ—è¡¨\"\"\"\n    df = load_data()\n    return sorted(df['country_name'].unique())\n\n# AI äº¤äº’çš„ä¼šè¯çŠ¶æ€ç®¡ç†\ndef init_session_state():\n    \"\"\"åˆå§‹åŒ–æ‰€æœ‰ä¼šè¯çŠ¶æ€å˜é‡\"\"\"\n    if \"sql_result\" not in st.session_state:\n        st.session_state.sql_result = None\n    if \"ai_summary\" not in st.session_state:\n        st.session_state.ai_summary = None\n    if \"should_generate_ai_summary\" not in st.session_state:\n        st.session_state.should_generate_ai_summary = False\n\n\n\n\n\n\n\nCode\ndef safe_api_call(func, *args, **kwargs):\n    \"\"\"å¸¦é”™è¯¯å¤„ç†çš„å®‰å…¨ API è°ƒç”¨\"\"\"\n    try:\n        return func(*args, **kwargs)\n    except Exception as e:\n        st.error(f\"API é”™è¯¯: {str(e)}\")\n        return None\n\ndef validate_sql_query(sql_query):\n    \"\"\"åŸºç¡€ SQL æŸ¥è¯¢éªŒè¯\"\"\"\n    sql_lower = sql_query.lower().strip()\n\n    # åŸºç¡€å®‰å…¨æ£€æŸ¥\n    dangerous_keywords = ['drop', 'delete', 'update', 'insert', 'alter']\n    for keyword in dangerous_keywords:\n        if keyword in sql_lower:\n            raise ValueError(f\"æ£€æµ‹åˆ°å±é™© SQL å…³é”®å­—: {keyword}\")\n\n    # ç¡®ä¿æŸ¥è¯¢ä»¥ SELECT å¼€å¤´\n    if not sql_lower.startswith('select'):\n        raise ValueError(\"ä»…å…è®¸æ‰§è¡Œ SELECT æŸ¥è¯¢\")\n\n    return True\n\n\n\n\n\n\n\n\n# ç¯å¢ƒé…ç½®\n# .env æ–‡ä»¶\nMODELSCOPE_API_KEY=your_modelscope_key\n\n# å®‰è£…ä¾èµ–\npip install -r requirements.txt\n\n# æ•°æ®é‡‡é›†\npython download_data.py\n\n# è¿è¡Œåº”ç”¨ç¨‹åº\nstreamlit run app.py\n\n\n\nstreamlit&gt;=1.28.0\npandas&gt;=1.5.0\nplotly&gt;=5.15.0\nduckdb&gt;=0.8.0\nopenai&gt;=1.0.0\npython-dotenv&gt;=1.0.0\nwbgapi&gt;=1.0.0\npycountry&gt;=22.0.0\nnumpy&gt;=1.24.0\n\n\n\n\n\n\n\nåŒç•Œé¢æ–¹æ¡ˆï¼šåŒæ—¶æä¾›è§†è§‰å’Œè‡ªç„¶è¯­è¨€è®¿é—®æ•°æ®çš„æ–¹å¼\nAI é©±åŠ¨çš„ SQL ç”Ÿæˆï¼šä½¿ç”¨ç®€å•çš„ä¸­/è‹±æ–‡å³å¯è¿›è¡Œå¤æ‚çš„ç»æµæŸ¥è¯¢\nå®æ—¶æ•°æ®å¤„ç†ï¼šé«˜æ•ˆçš„ç¼“å­˜å’Œä¼šè¯ç®¡ç†\nå…¨é¢çš„å›½é™…åŒ–ï¼šçœŸæ­£çš„åŒè¯­æ”¯æŒåŠæœ¬åœ°åŒ–æ•°æ®æ˜¾ç¤º\nç”Ÿäº§å°±ç»ªçš„éƒ¨ç½²ï¼šå®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ€§èƒ½ä¼˜åŒ–\n\n\n\n\nAI æ‘˜è¦ç”Ÿæˆ\n\n\n\n\n\n\n\n\n\nå¯¹æ¯”åˆ†æ\n\nâ€œå¯¹æ¯” 2010 å¹´è‡³ 2020 å¹´ä¸­å›½å’Œæ—¥æœ¬çš„ GDP å¢é•¿â€\nâ€œ2023 å¹´å“ªäº›å›½å®¶çš„äººå‡ GDP æœ€é«˜ï¼Ÿâ€\n\næ—¶åºåˆ†æ\n\nâ€œæ˜¾ç¤ºè¿‡å»åå¹´é‡‘ç –å›½å®¶çš„ GDP è¶‹åŠ¿â€\nâ€œ2000 å¹´è‡³ 2020 å¹´å°åº¦çš„äººå£å¢é•¿ç‡æ˜¯å¤šå°‘ï¼Ÿâ€\n\nç»Ÿè®¡æŸ¥è¯¢\n\nâ€œè®¡ç®—æ¬§æ´²å›½å®¶çš„å¹³å‡ GDP å¢é•¿ç‡â€\nâ€œæ‰¾å‡º 2022 å¹´äººå‡ GDP è¶…è¿‡ 50,000 ç¾å…ƒçš„å›½å®¶â€\n\nå¤æ‚å¤šå˜é‡åˆ†æ\n\nâ€œäºšæ´²å›½å®¶çš„äººå£ä¸ GDP ä¹‹é—´æœ‰ä»€ä¹ˆç›¸å…³æ€§ï¼Ÿâ€\nâ€œåˆ—å‡ºè¿ç»­ 3 å¹´äººå‡ GDP å¢é•¿è¶…è¿‡ 5% çš„å›½å®¶â€\n\n\n\n\n\n\nè¿™ä¸ª GDP è¶‹åŠ¿çœ‹æ¿ä»£è¡¨äº†ç»æµæ•°æ®åˆ†æçš„åˆ›æ–°æ–¹æ³•ï¼Œå°†ä¼ ç»Ÿçš„è§†è§‰åŒ–æŠ€æœ¯ä¸å°–ç«¯çš„ AI èƒ½åŠ›ç›¸ç»“åˆã€‚è¯¥é¡¹ç›®å±•ç¤ºäº†ï¼š\n\nå…ˆè¿›çš„æ•°æ®é›†æˆï¼šé›†æˆä¸–ç•Œé“¶è¡Œ API ä¸å…¨é¢çš„ç»æµæŒ‡æ ‡\nè‡ªç„¶è¯­è¨€å¤„ç†ï¼šAI é©±åŠ¨çš„ SQL ç”Ÿæˆï¼Œå®ç°ä¾¿æ·çš„æ•°æ®æŸ¥è¯¢\nä¸“ä¸šçš„è§†è§‰åŒ–ï¼šé‡‡ç”¨ä¸€è‡´è®¾è®¡çš„äº¤äº’å¼ Plotly å›¾è¡¨\nåŒè¯­æ”¯æŒï¼šå®Œæ•´çš„è‹±/ä¸­æœ¬åœ°åŒ–\nç”Ÿäº§çº§æ¶æ„ï¼šç¨³å¥çš„é”™è¯¯å¤„ç†ã€ç¼“å­˜å’Œéƒ¨ç½²\n\næ— è®ºæ‚¨æ˜¯ç»æµå­¦å®¶ã€æ•°æ®ç§‘å­¦å®¶è¿˜æ˜¯æ”¿ç­–åˆ†æå¸ˆï¼Œè¯¥åº”ç”¨ç¨‹åºéƒ½å±•ç¤ºäº†ç°ä»£ AI æŠ€æœ¯å¦‚ä½•é€šè¿‡ç›´è§‚çš„ç•Œé¢å’Œæ™ºèƒ½è‡ªåŠ¨åŒ–ï¼Œä½¿å¤æ‚çš„ç»æµæ•°æ®å˜å¾—æ›´åŠ æ˜“äºè·å–å’Œåˆ©ç”¨ã€‚\n\næŠ€æœ¯æ ˆï¼šStreamlit, DuckDB, Plotly, ModelScope API, World Bank API\næ•°æ®æºï¼šä¸–ç•Œé“¶è¡Œ (2000-2024, 200+ å›½å®¶, 15,000+ æ•°æ®ç‚¹)"
  },
  {
    "objectID": "posts/gdp-trend/index.html#æ ¸å¿ƒæ¶æ„",
    "href": "posts/gdp-trend/index.html#æ ¸å¿ƒæ¶æ„",
    "title": "ä½¿ç”¨ AI SQL æ„å»ºçš„äº¤äº’å¼ GDP è¶‹åŠ¿çœ‹æ¿",
    "section": "",
    "text": "ä¸»è¦æ¡†æ¶ï¼šç”¨äºäº¤äº’å¼ Web åº”ç”¨çš„ Streamlit\næ•°æ®å¤„ç†ï¼šç”¨äºæ•°æ®æ“ä½œå’Œåˆ†æçš„ Pandas\nå¯è§†åŒ–ï¼šç”¨äºäº¤äº’å¼å›¾è¡¨çš„ Plotly Express\næ•°æ®åº“ï¼šç”¨äºé«˜æ•ˆ SQL æŸ¥è¯¢çš„ DuckDB\nAI é›†æˆï¼šç”¨äºè‡ªç„¶è¯­è¨€è½¬ SQL çš„ ModelScope GLM-4.6\næ•°æ®æºï¼šé€šè¿‡ wbgapi åº“è°ƒç”¨çš„ä¸–ç•Œé“¶è¡Œ API\n\n\n\n\n\nå¤šå›½ GDP è¶‹åŠ¿å¯¹æ¯”\næ”¯æŒå¤šç§ç»æµæŒ‡æ ‡ï¼ˆGDPã€äººå‡ GDPã€äººå£ã€åŒæ¯”å¢é•¿ç‡ï¼‰\nAI é©±åŠ¨çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢\nä½¿ç”¨ DuckDB çš„ç›´æ¥ SQL æ¥å£\nå®Œå–„çš„åŒè¯­æ”¯æŒï¼ˆä¸­/è‹±æ–‡ï¼‰\nå¸¦äº¤äº’æ§åˆ¶çš„æ—¶é—´èŒƒå›´ç­›é€‰ï¼ˆ2000å¹´è‡³ä»Šï¼‰"
  },
  {
    "objectID": "posts/gdp-trend/index.html#æ•°æ®æµæ°´çº¿æ¶æ„",
    "href": "posts/gdp-trend/index.html#æ•°æ®æµæ°´çº¿æ¶æ„",
    "title": "ä½¿ç”¨ AI SQL æ„å»ºçš„äº¤äº’å¼ GDP è¶‹åŠ¿çœ‹æ¿",
    "section": "",
    "text": "è¯¥åº”ç”¨ç¨‹åºå®ç°äº†ä¸€ä¸ªå¤æ‚çš„æ•°æ®æµæ°´çº¿ï¼Œä»¥ç¡®ä¿æ•°æ®è´¨é‡å’Œå®æ—¶å¯ç”¨æ€§ï¼š\n\n\n\n\n\nflowchart TD\n    A[ä¸–ç•Œé“¶è¡Œ API] --&gt; B[æ•°æ®é‡‡é›†&lt;br/&gt;download_data.py]\n    B --&gt; C[æ•°æ®å¤„ç†&lt;br/&gt;å›½å®¶æ˜ å°„ã€æŒ‡æ ‡è®¡ç®—]\n    C --&gt; D[æ•°æ®å­˜å‚¨&lt;br/&gt;CSV æ–‡ä»¶]\n\n    D --&gt; E[Streamlit åº”ç”¨&lt;br/&gt;app.py]\n    E --&gt; F[DuckDB&lt;br/&gt;å†…å­˜ SQL]\n\n    F --&gt; G[å¯è§†åŒ–å¼•æ“&lt;br/&gt;Plotly Express]\n    F --&gt; H[AI æŸ¥è¯¢å¼•æ“&lt;br/&gt;ModelScope API]\n    F --&gt; I[ä¼šè¯ç®¡ç†&lt;br/&gt;ç”¨æˆ·çŠ¶æ€]\n\n    G --&gt; J[äº¤äº’å¼å›¾è¡¨]\n    H --&gt; K[è‡ªç„¶è¯­è¨€&lt;br/&gt;è½¬ SQL]\n    I --&gt; L[æŒä¹…åŒ–&lt;br/&gt;æŸ¥è¯¢ç»“æœ]\n\n    J --&gt; M[ç”¨æˆ·ç•Œé¢]\n    K --&gt; M\n    L --&gt; M\n\n\n GDP åº”ç”¨æ¶æ„"
  },
  {
    "objectID": "posts/gdp-trend/index.html#æ•°æ®é‡‡é›†ä¸å¤„ç†",
    "href": "posts/gdp-trend/index.html#æ•°æ®é‡‡é›†ä¸å¤„ç†",
    "title": "ä½¿ç”¨ AI SQL æ„å»ºçš„äº¤äº’å¼ GDP è¶‹åŠ¿çœ‹æ¿",
    "section": "",
    "text": "åº”ç”¨ç¨‹åºä½¿ç”¨ä¸–ç•Œé“¶è¡Œ API é‡‡é›†å…¨é¢çš„ç»æµæ•°æ®ï¼š\n\n\nCode\nimport wbgapi as wb\nimport pycountry\nimport pandas as pd\n\ndef download_economic_data():\n    \"\"\"ä»ä¸–ç•Œé“¶è¡Œ API ä¸‹è½½æ‰€æœ‰å›½å®¶çš„ GDP æ•°æ®\"\"\"\n\n    # å®šä¹‰è¦ä¸‹è½½çš„ç»æµæŒ‡æ ‡\n    indicators = {\n        'gdp_current_usd': 'NY.GDP.MKTP.CD',\n        'gdp_per_capita_current_usd': 'NY.GDP.PCAP.CD',\n        'population_total': 'SP.POP.TOTL'\n    }\n\n    # ä¸‹è½½ 2000 å¹´è‡³ä»Šçš„æ•°æ®\n    data_frames = []\n    for indicator_name, indicator_code in indicators.items():\n        df = wb.get_series(\n            series=indicator_code,\n            economy='all',\n            time='2000:2024',\n            simplify_index=True\n        )\n\n        # å¤„ç†å¹¶æ·»åŠ åˆ°é›†åˆ\n        df = df.reset_index()\n        df['indicator'] = indicator_name\n        data_frames.append(df)\n\n    # åˆå¹¶æ‰€æœ‰æŒ‡æ ‡\n    combined_df = pd.concat(data_frames, ignore_index=True)\n    return combined_df\n\ndef create_country_reference_table():\n    \"\"\"åˆ›å»ºåŒ…å« ISO ä»£ç çš„å®Œæ•´å›½å®¶å…ƒæ•°æ®è¡¨\"\"\"\n    countries = list(pycountry.countries)\n\n    df_all = pd.DataFrame([{\n        'country_name': country.name,\n        'country_code_2': country.alpha_2,\n        'country_code_3': country.alpha_3\n    } for country in countries])\n\n    # æ·»åŠ å¤§æ´²æ˜ å°„\n    iso_to_continent = {\n        \"US\": \"North America\", \"CN\": \"Asia\", \"JP\": \"Asia\",\n        \"DE\": \"Europe\", \"GB\": \"Europe\", \"FR\": \"Europe\"\n        # ... ä¸ºæ‰€æœ‰å›½å®¶å®Œæˆæ˜ å°„\n    }\n\n    df_all['continent'] = df_all['country_code_2'].map(iso_to_continent)\n    return df_all\n\n\n\n\n\nåº”ç”¨ç¨‹åºä½¿ç”¨æ¸…æ™°ã€è§„èŒƒåŒ–çš„æ•°æ®ç»“æ„ï¼š\n\n\nCode\n-- ä¸»è¦æ•°æ®æ¨¡å¼\nCREATE TABLE df_gdp (\n    country_name TEXT,        -- æ˜¾ç¤ºåç§° (è‹±æ–‡)\n    country_code_2 TEXT,      -- ISO alpha-2 ä»£ç \n    country_code_3 TEXT,      -- ISO alpha-3 ä»£ç \n    continent TEXT,            -- å¤§æ´²åˆ†ç±»\n    year INTEGER,              -- æ•°æ®å¹´ä»½\n    indicator TEXT,            -- ç»æµæŒ‡æ ‡åç§°\n    value REAL                -- æŒ‡æ ‡æ•°å€¼\n);\n\n-- ç¤ºä¾‹æ•°æ®\nINSERT INTO df_gdp VALUES\n('United States', 'US', 'USA', 'North America', 2023, 'gdp_current_usd', 27444144.3),\n('United States', 'US', 'USA', 'North America', 2023, 'gdp_per_capita_current_usd', 81254.2),\n('United States', 'US', 'USA', 'North America', 2023, 'population_total', 334914895.0);"
  },
  {
    "objectID": "posts/gdp-trend/index.html#äº¤äº’å¼å¯è§†åŒ–ç³»ç»Ÿ",
    "href": "posts/gdp-trend/index.html#äº¤äº’å¼å¯è§†åŒ–ç³»ç»Ÿ",
    "title": "ä½¿ç”¨ AI SQL æ„å»ºçš„äº¤äº’å¼ GDP è¶‹åŠ¿çœ‹æ¿",
    "section": "",
    "text": "åº”ç”¨ç¨‹åºä½¿ç”¨ Plotly Express åˆ›å»ºäº¤äº’å¼å›¾è¡¨ï¼Œå¹¶ä¿æŒä¸€è‡´çš„é¢œè‰²ç¼–ç ï¼š\n\n\nCode\nimport plotly.express as px\n\n@st.cache_data\ndef load_data():\n    \"\"\"åŠ è½½å¹¶ç¼“å­˜ GDP æ•°æ®\"\"\"\n    return pd.read_csv('data/gdp_data_2000_present.csv')\n\ndef create_gdp_trend_chart(selected_countries, selected_indicator, year_range):\n    \"\"\"åˆ›å»ºäº¤äº’å¼ GDP è¶‹åŠ¿å¯è§†åŒ–\"\"\"\n\n    # åŠ è½½ç­›é€‰åçš„æ•°æ®\n    df = load_data()\n\n    # åº”ç”¨ç­›é€‰æ¡ä»¶\n    filtered_df = df[\n        (df['country_name'].isin(selected_countries)) &\n        (df['indicator'] == selected_indicator) &\n        (df['year'].between(year_range[0], year_range[1]))\n    ]\n\n    # åˆ›å»ºäº¤äº’å¼æŠ˜çº¿å›¾\n    fig = px.line(\n        filtered_df,\n        x='year',\n        y='value',\n        color='country_name',\n        title=f'{selected_indicator.replace(\"_\", \" \").title()} è¶‹åŠ¿',\n        labels={\n            'year': 'å¹´ä»½',\n            'value': format_indicator_label(selected_indicator),\n            'country_name': 'å›½å®¶'\n        }\n    )\n\n    # è‡ªå®šä¹‰å›¾è¡¨å¤–è§‚\n    fig.update_layout(\n        xaxis_title=\"å¹´ä»½\",\n        yaxis_title=format_indicator_label(selected_indicator),\n        hovermode='x unified',\n        showlegend=True,\n        legend=dict(\n            orientation=\"h\",\n            yanchor=\"bottom\",\n            y=1.02,\n            xanchor=\"right\",\n            x=1\n        )\n    )\n\n    return fig\n\ndef format_indicator_label(indicator):\n    \"\"\"æ ¼å¼åŒ–æŒ‡æ ‡åç§°ä»¥ä¾›æ˜¾ç¤º\"\"\"\n    labels = {\n        'gdp_current_usd': 'GDP (ç°ä»·ç¾å…ƒ)',\n        'gdp_per_capita_current_usd': 'äººå‡ GDP (ç°ä»·ç¾å…ƒ)',\n        'population_total': 'æ€»äººå£',\n        'gdp_per_capita_current_usd_yoy': 'äººå‡ GDP åŒæ¯”å¢é•¿ç‡ (%)'\n    }\n    return labels.get(indicator, indicator.replace('_', ' ').title())"
  },
  {
    "objectID": "posts/gdp-trend/index.html#ai-é©±åŠ¨çš„åˆ†æ",
    "href": "posts/gdp-trend/index.html#ai-é©±åŠ¨çš„åˆ†æ",
    "title": "ä½¿ç”¨ AI SQL æ„å»ºçš„äº¤äº’å¼ GDP è¶‹åŠ¿çœ‹æ¿",
    "section": "",
    "text": "è¯¥ç¨‹åºæœ€å…·åˆ›æ–°æ€§çš„åŠŸèƒ½æ˜¯ AI é©±åŠ¨çš„è‡ªç„¶è¯­è¨€æŸ¥è¯¢ï¼š\n\n\nCode\nfrom openai import OpenAI\nimport duckdb\n\ndef generate_sql_from_question(question, language):\n    \"\"\"ä½¿ç”¨ ModelScope API å°†è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸º SQL æŸ¥è¯¢\"\"\"\n\n    # è·å–æ•°æ®åº“æ¨¡å¼ä¸Šä¸‹æ–‡\n    schema_info = \"\"\"\n    è¡¨å: df_gdp\n    åˆ—å:\n    - country_name (TEXT): å›½å®¶æ˜¾ç¤ºåç§°\n    - country_code_2 (TEXT): ISO alpha-2 å›½å®¶ä»£ç \n    - continent (TEXT): å¤§æ´²åˆ†ç±»\n    - year (INTEGER): æ•°æ®å¹´ä»½ (2000-2024)\n    - indicator (TEXT): ç»æµæŒ‡æ ‡åç§°\n    - value (REAL): æŒ‡æ ‡æ•°å€¼\n\n    å¯ç”¨æŒ‡æ ‡:\n    - gdp_current_usd: ç°ä»· GDP (ç¾å…ƒ)\n    - gdp_per_capita_current_usd: ç°ä»·äººå‡ GDP (ç¾å…ƒ)\n    - population_total: æ€»äººå£\n    - gdp_per_capita_current_usd_yoy: äººå‡ GDP åŒæ¯”å¢é•¿ç‡ (%)\n    \"\"\"\n\n    # åˆ›å»ºç‰¹å®šè¯­è¨€çš„æç¤ºè¯\n    if language == \"zh\":\n        prompt = f\"\"\"è¯·å°†ä»¥ä¸‹è‡ªç„¶è¯­è¨€é—®é¢˜è½¬æ¢ä¸ºSQLæŸ¥è¯¢ï¼Œä»…è¿”å›SQLè¯­å¥ï¼Œä¸è¦è§£é‡Šã€‚\n\næ•°æ®åº“ä¿¡æ¯ï¼š\n{schema_info}\n\nç”¨æˆ·é—®é¢˜ï¼š{question}\n\nè¦æ±‚ï¼š\n1. åªè¿”å›æ ‡å‡†çš„SELECTè¯­å¥\n2. ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šæˆ–æ³¨é‡Š\n3. ä½¿ç”¨LIMIT 50é™åˆ¶ç»“æœæ•°é‡\"\"\"\n    else:\n        # (ä¿æŒåŸè‹±æ–‡ prompt)\n        prompt = f\"\"\"Convert the following natural language question to SQL query. Return only the SQL statement, no explanation.\n\nDatabase information:\n{schema_info}\n\nUser question: {question}\n\nRequirements:\n1. Return only standard SELECT statement\n2. Do not add any explanation or comments\n3. Use LIMIT 50 to restrict results\"\"\"\n\n    # è°ƒç”¨ ModelScope API\n    client = OpenAI(\n        api_key=os.getenv('MODELSCOPE_API_KEY'),\n        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n    )\n\n    response = client.chat.completions.create(\n        model=\"qwen/Qwen3-235B\",\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        temperature=0.1,  # ä½¿ç”¨ä½æ¸©åº¦ä»¥è·å¾—ä¸€è‡´çš„ SQL\n        max_tokens=500\n    )\n\n    return response.choices[0].message.content.strip()\n\n\n\n\n\n\n\nCode\ndef execute_query_with_ai_summary(sql_query, original_question):\n    \"\"\"æ‰§è¡Œ SQL æŸ¥è¯¢å¹¶ç”Ÿæˆ AI æ‘˜è¦\"\"\"\n\n    try:\n        # ä½¿ç”¨ DuckDB æ‰§è¡ŒæŸ¥è¯¢\n        conn = duckdb.connect()\n        result_df = conn.execute(sql_query).fetchdf()\n\n        # å°†ç»“æœå­˜å…¥ä¼šè¯çŠ¶æ€\n        st.session_state.sql_result = result_df\n        st.session_state.sql_query = sql_query\n\n        # å¦‚æœæœ‰æ•°æ®ï¼Œç”Ÿæˆ AI æ‘˜è¦\n        if not result_df.empty:\n            generate_ai_summary(result_df, original_question)\n\n        return result_df\n\n    except Exception as e:\n        st.error(f\"æŸ¥è¯¢æ‰§è¡Œé”™è¯¯: {str(e)}\")\n        return None\n\ndef generate_ai_summary(data_frame, question):\n    \"\"\"ç”ŸæˆæŸ¥è¯¢ç»“æœçš„ AI æ‘˜è¦\"\"\"\n\n    # å°† DataFrame è½¬æ¢ä¸ºæ–‡æœ¬ä»¥ä¾¿åˆ†æ\n    data_summary = data_frame.to_string(index=False)\n\n    summary_prompt = f\"\"\"æ ¹æ®ä»¥ä¸‹æ•°æ®åˆ†æç»“æœï¼Œæä¾›ä¸€ä¸ªç®€æ˜æ‰¼è¦çš„æ‘˜è¦ï¼š\n\nåŸå§‹é—®é¢˜ï¼š{question}\n\næŸ¥è¯¢ç»“æœï¼š\n{data_summary}\n\nè¯·æä¾›ï¼š\n1. å…³é”®å‘ç°çš„ç®€è¦åˆ†æ\n2. ä»»ä½•å€¼å¾—æ³¨æ„çš„è¶‹åŠ¿æˆ–æ¨¡å¼\n3. æ¥è‡ªæ•°æ®çš„é‡è¦è§è§£\n\nè¯·å°†æ‘˜è¦æ§åˆ¶åœ¨ 200 å­—ä»¥å†…ï¼Œå¹¶ç¡®ä¿é€šä¿—æ˜“æ‡‚ã€‚\"\"\"\n\n    # ä½¿ç”¨ AI ç”Ÿæˆæ‘˜è¦\n    client = OpenAI(\n        api_key=os.getenv('MODELSCOPE_API_KEY'),\n        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n    )\n\n    response = client.chat.completions.create(\n        model=\"qwen/Qwen3-235B\",\n        messages=[{\"role\": \"user\", \"content\": summary_prompt}],\n        temperature=0.3,\n        max_tokens=300\n    )\n\n    st.session_state.ai_summary = response.choices[0].message.content\n\n\n\n\n\nAI æŸ¥è¯¢ç•Œé¢ - è‡ªç„¶è¯­è¨€å¤„ç†"
  },
  {
    "objectID": "posts/gdp-trend/index.html#åŒè¯­æ”¯æŒç³»ç»Ÿ",
    "href": "posts/gdp-trend/index.html#åŒè¯­æ”¯æŒç³»ç»Ÿ",
    "title": "ä½¿ç”¨ AI SQL æ„å»ºçš„äº¤äº’å¼ GDP è¶‹åŠ¿çœ‹æ¿",
    "section": "",
    "text": "åº”ç”¨ç¨‹åºå®ç°äº†å…¨é¢çš„ä¸­/è‹±æ–‡æ”¯æŒï¼š\n\n\nCode\n# language.py - å®Œæ•´çš„ç¿»è¯‘ç³»ç»Ÿ\ntranslations = {\n    \"en\": {\n        \"title\": \"ğŸŒ GDP Trend Dashboard\",\n        \"gdp_trend\": \"GDP Trend\",\n        \"ai_powered_chat\": \"AI-Powered Data Chat\",\n        \"default_question\": \"What is the average GDP per capita for China, Japan, and Korea during 2020 to 2023?\"\n    },\n    \"zh\": {\n        \"title\": \"ğŸŒ GDP è¶‹åŠ¿çœ‹æ¿\",\n        \"gdp_trend\": \"GDP è¶‹åŠ¿\",\n        \"ai_powered_chat\": \"AI æ•°æ®å¯¹è¯\",\n        \"default_question\": \"2020å¹´è‡³2023å¹´æœŸé—´ï¼Œä¸­å›½ã€æ—¥æœ¬å’ŒéŸ©å›½çš„å¹³å‡äººå‡GDPæ˜¯å¤šå°‘ï¼Ÿ\"\n    }\n}\n\ndef get_text(key):\n    \"\"\"è·å–å½“å‰è¯­è¨€çš„ç¿»è¯‘æ–‡æœ¬\"\"\"\n    language = st.session_state.get(\"language\", \"en\")\n    return translations.get(language, {}).get(key, key)\n\n# UI ä¸­çš„è¯­è¨€åˆ‡æ¢\ncol1, col2 = st.columns([1, 1])\nwith col1:\n    if st.button(\"English\"):\n        st.session_state.language = \"en\"\n        st.rerun()\nwith col2:\n    if st.button(\"ä¸­æ–‡\"):\n        st.session_state.language = \"zh\"\n        st.rerun()"
  },
  {
    "objectID": "posts/gdp-trend/index.html#ç”¨æˆ·ç•Œé¢è®¾è®¡",
    "href": "posts/gdp-trend/index.html#ç”¨æˆ·ç•Œé¢è®¾è®¡",
    "title": "ä½¿ç”¨ AI SQL æ„å»ºçš„äº¤äº’å¼ GDP è¶‹åŠ¿çœ‹æ¿",
    "section": "",
    "text": "Code\ndef main():\n    \"\"\"é‡‡ç”¨æ ‡ç­¾é¡µå¯¼èˆªçš„ä¸»åº”ç”¨ç¨‹åº\"\"\"\n\n    # å³ä¸Šè§’çš„è¯­è¨€åˆ‡æ¢\n    with st.container():\n        st.markdown(\"\"\"\n        &lt;div class=\"language-toggle\"&gt;\n            &lt;button onclick=\"setLanguage('en')\"&gt;EN&lt;/button&gt;\n            &lt;button onclick=\"setLanguage('zh')\"&gt;ä¸­æ–‡&lt;/button&gt;\n        &lt;/div&gt;\n        \"\"\", unsafe_allow_html=True)\n\n    st.title(get_text(\"title\"))\n\n    # æ ‡ç­¾é¡µç•Œé¢\n    tab1, tab2 = st.tabs([get_text(\"gdp_trend\"), get_text(\"query\")])\n\n    with tab1:\n        render_gdp_trends_tab()\n\n    with tab2:\n        render_query_interface_tab()\n\ndef render_gdp_trends_tab():\n    \"\"\"æ¸²æŸ“ GDP è¶‹åŠ¿å¯è§†åŒ–æ ‡ç­¾é¡µ\"\"\"\n\n    st.header(get_text(\"gdp_trend\"))\n\n    # åŠ è½½æ•°æ®\n    df = load_data()\n\n    # ç­›é€‰æ§åˆ¶\n    col1, col2, col3 = st.columns([2, 1, 1])\n\n    with col1:\n        selected_countries = st.multiselect(\n            get_text(\"select_countries\"),\n            options=df['country_name'].unique(),\n            default=['United States', 'China', 'Japan']\n        )\n\n    with col2:\n        selected_indicator = st.selectbox(\n            get_text(\"select_indicator\"),\n            options=[\n                'gdp_current_usd',\n                'gdp_per_capita_current_usd',\n                'population_total',\n                'gdp_per_capita_current_usd_yoy'\n            ],\n            format_func=lambda x: format_indicator_label(x)\n        )\n\n    with col3:\n        year_range = st.slider(\n            get_text(\"select_year_range\"),\n            min_value=2000,\n            max_value=2024,\n            value=(2010, 2024),\n            step=1\n        )\n\n    # ç”Ÿæˆå¹¶æ˜¾ç¤ºå›¾è¡¨\n    if selected_countries and selected_indicator:\n        fig = create_gdp_trend_chart(selected_countries, selected_indicator, year_range)\n        st.plotly_chart(fig, use_container_width=True)\n\n        # æ˜¾ç¤ºåŸå§‹æ•°æ®é€‰é¡¹\n        if st.checkbox(get_text(\"show_raw_data\")):\n            display_filtered_data_table(selected_countries, selected_indicator, year_range)\n\ndef render_query_interface_tab():\n    \"\"\"æ¸²æŸ“ AI é©±åŠ¨çš„æŸ¥è¯¢ç•Œé¢æ ‡ç­¾é¡µ\"\"\"\n\n    st.header(get_text(\"ai_powered_chat\"))\n    st.markdown(get_text(\"ai_chat_description\"))\n\n    # è‡ªç„¶è¯­è¨€è¾“å…¥\n    user_question = st.text_input(\n        get_text(\"your_question\"),\n        value=st.session_state.get(\"user_question\", get_text(\"default_question\"))\n    )\n\n    col1, col2 = st.columns([1, 1])\n\n    with col1:\n        if st.button(get_text(\"run_ai\"), type=\"primary\"):\n            if user_question:\n                with st.spinner(\"AI æ­£åœ¨å¤„ç†...\"):\n                    # ä»è‡ªç„¶è¯­è¨€ç”Ÿæˆ SQL\n                    sql_query = generate_sql_from_question(\n                        user_question,\n                        st.session_state.language\n                    )\n\n                    if sql_query:\n                        # æ‰§è¡ŒæŸ¥è¯¢å¹¶ç”Ÿæˆæ‘˜è¦\n                        result_df = execute_query_with_ai_summary(sql_query, user_question)\n\n                        st.session_state.user_question = user_question\n                        st.session_state.should_generate_ai_summary = True\n\n    # æ˜¾ç¤ºç»“æœ\n    if st.session_state.get(\"sql_result\") is not None:\n        display_query_results()"
  },
  {
    "objectID": "posts/gdp-trend/index.html#æ€§èƒ½ä¼˜åŒ–",
    "href": "posts/gdp-trend/index.html#æ€§èƒ½ä¼˜åŒ–",
    "title": "ä½¿ç”¨ AI SQL æ„å»ºçš„äº¤äº’å¼ GDP è¶‹åŠ¿çœ‹æ¿",
    "section": "",
    "text": "Code\n# Streamlit æ•°æ®æ“ä½œç¼“å­˜\n@st.cache_data(ttl=3600)  # ç¼“å­˜ 1 å°æ—¶\ndef load_data():\n    \"\"\"åŠ è½½å¹¶ç¼“å­˜ GDP æ•°æ®\"\"\"\n    return pd.read_csv('data/gdp_data_2000_present.csv')\n\n@st.cache_data(ttl=1800)  # ç¼“å­˜ 30 åˆ†é’Ÿ\ndef get_country_list():\n    \"\"\"è·å–å¹¶ç¼“å­˜å”¯ä¸€çš„å›½å®¶åˆ—è¡¨\"\"\"\n    df = load_data()\n    return sorted(df['country_name'].unique())\n\n# AI äº¤äº’çš„ä¼šè¯çŠ¶æ€ç®¡ç†\ndef init_session_state():\n    \"\"\"åˆå§‹åŒ–æ‰€æœ‰ä¼šè¯çŠ¶æ€å˜é‡\"\"\"\n    if \"sql_result\" not in st.session_state:\n        st.session_state.sql_result = None\n    if \"ai_summary\" not in st.session_state:\n        st.session_state.ai_summary = None\n    if \"should_generate_ai_summary\" not in st.session_state:\n        st.session_state.should_generate_ai_summary = False\n\n\n\n\n\n\n\nCode\ndef safe_api_call(func, *args, **kwargs):\n    \"\"\"å¸¦é”™è¯¯å¤„ç†çš„å®‰å…¨ API è°ƒç”¨\"\"\"\n    try:\n        return func(*args, **kwargs)\n    except Exception as e:\n        st.error(f\"API é”™è¯¯: {str(e)}\")\n        return None\n\ndef validate_sql_query(sql_query):\n    \"\"\"åŸºç¡€ SQL æŸ¥è¯¢éªŒè¯\"\"\"\n    sql_lower = sql_query.lower().strip()\n\n    # åŸºç¡€å®‰å…¨æ£€æŸ¥\n    dangerous_keywords = ['drop', 'delete', 'update', 'insert', 'alter']\n    for keyword in dangerous_keywords:\n        if keyword in sql_lower:\n            raise ValueError(f\"æ£€æµ‹åˆ°å±é™© SQL å…³é”®å­—: {keyword}\")\n\n    # ç¡®ä¿æŸ¥è¯¢ä»¥ SELECT å¼€å¤´\n    if not sql_lower.startswith('select'):\n        raise ValueError(\"ä»…å…è®¸æ‰§è¡Œ SELECT æŸ¥è¯¢\")\n\n    return True"
  },
  {
    "objectID": "posts/gdp-trend/index.html#éƒ¨ç½²ä¸å¯è®¿é—®æ€§",
    "href": "posts/gdp-trend/index.html#éƒ¨ç½²ä¸å¯è®¿é—®æ€§",
    "title": "ä½¿ç”¨ AI SQL æ„å»ºçš„äº¤äº’å¼ GDP è¶‹åŠ¿çœ‹æ¿",
    "section": "",
    "text": "# ç¯å¢ƒé…ç½®\n# .env æ–‡ä»¶\nMODELSCOPE_API_KEY=your_modelscope_key\n\n# å®‰è£…ä¾èµ–\npip install -r requirements.txt\n\n# æ•°æ®é‡‡é›†\npython download_data.py\n\n# è¿è¡Œåº”ç”¨ç¨‹åº\nstreamlit run app.py\n\n\n\nstreamlit&gt;=1.28.0\npandas&gt;=1.5.0\nplotly&gt;=5.15.0\nduckdb&gt;=0.8.0\nopenai&gt;=1.0.0\npython-dotenv&gt;=1.0.0\nwbgapi&gt;=1.0.0\npycountry&gt;=22.0.0\nnumpy&gt;=1.24.0"
  },
  {
    "objectID": "posts/gdp-trend/index.html#æŠ€æœ¯äº®ç‚¹",
    "href": "posts/gdp-trend/index.html#æŠ€æœ¯äº®ç‚¹",
    "title": "ä½¿ç”¨ AI SQL æ„å»ºçš„äº¤äº’å¼ GDP è¶‹åŠ¿çœ‹æ¿",
    "section": "",
    "text": "åŒç•Œé¢æ–¹æ¡ˆï¼šåŒæ—¶æä¾›è§†è§‰å’Œè‡ªç„¶è¯­è¨€è®¿é—®æ•°æ®çš„æ–¹å¼\nAI é©±åŠ¨çš„ SQL ç”Ÿæˆï¼šä½¿ç”¨ç®€å•çš„ä¸­/è‹±æ–‡å³å¯è¿›è¡Œå¤æ‚çš„ç»æµæŸ¥è¯¢\nå®æ—¶æ•°æ®å¤„ç†ï¼šé«˜æ•ˆçš„ç¼“å­˜å’Œä¼šè¯ç®¡ç†\nå…¨é¢çš„å›½é™…åŒ–ï¼šçœŸæ­£çš„åŒè¯­æ”¯æŒåŠæœ¬åœ°åŒ–æ•°æ®æ˜¾ç¤º\nç”Ÿäº§å°±ç»ªçš„éƒ¨ç½²ï¼šå®Œå–„çš„é”™è¯¯å¤„ç†å’Œæ€§èƒ½ä¼˜åŒ–\n\n\n\n\nAI æ‘˜è¦ç”Ÿæˆ"
  },
  {
    "objectID": "posts/gdp-trend/index.html#ç»æµåˆ†æç¤ºä¾‹",
    "href": "posts/gdp-trend/index.html#ç»æµåˆ†æç¤ºä¾‹",
    "title": "ä½¿ç”¨ AI SQL æ„å»ºçš„äº¤äº’å¼ GDP è¶‹åŠ¿çœ‹æ¿",
    "section": "",
    "text": "å¯¹æ¯”åˆ†æ\n\nâ€œå¯¹æ¯” 2010 å¹´è‡³ 2020 å¹´ä¸­å›½å’Œæ—¥æœ¬çš„ GDP å¢é•¿â€\nâ€œ2023 å¹´å“ªäº›å›½å®¶çš„äººå‡ GDP æœ€é«˜ï¼Ÿâ€\n\næ—¶åºåˆ†æ\n\nâ€œæ˜¾ç¤ºè¿‡å»åå¹´é‡‘ç –å›½å®¶çš„ GDP è¶‹åŠ¿â€\nâ€œ2000 å¹´è‡³ 2020 å¹´å°åº¦çš„äººå£å¢é•¿ç‡æ˜¯å¤šå°‘ï¼Ÿâ€\n\nç»Ÿè®¡æŸ¥è¯¢\n\nâ€œè®¡ç®—æ¬§æ´²å›½å®¶çš„å¹³å‡ GDP å¢é•¿ç‡â€\nâ€œæ‰¾å‡º 2022 å¹´äººå‡ GDP è¶…è¿‡ 50,000 ç¾å…ƒçš„å›½å®¶â€\n\nå¤æ‚å¤šå˜é‡åˆ†æ\n\nâ€œäºšæ´²å›½å®¶çš„äººå£ä¸ GDP ä¹‹é—´æœ‰ä»€ä¹ˆç›¸å…³æ€§ï¼Ÿâ€\nâ€œåˆ—å‡ºè¿ç»­ 3 å¹´äººå‡ GDP å¢é•¿è¶…è¿‡ 5% çš„å›½å®¶â€"
  },
  {
    "objectID": "posts/gdp-trend/index.html#ç»“è®º",
    "href": "posts/gdp-trend/index.html#ç»“è®º",
    "title": "ä½¿ç”¨ AI SQL æ„å»ºçš„äº¤äº’å¼ GDP è¶‹åŠ¿çœ‹æ¿",
    "section": "",
    "text": "è¿™ä¸ª GDP è¶‹åŠ¿çœ‹æ¿ä»£è¡¨äº†ç»æµæ•°æ®åˆ†æçš„åˆ›æ–°æ–¹æ³•ï¼Œå°†ä¼ ç»Ÿçš„è§†è§‰åŒ–æŠ€æœ¯ä¸å°–ç«¯çš„ AI èƒ½åŠ›ç›¸ç»“åˆã€‚è¯¥é¡¹ç›®å±•ç¤ºäº†ï¼š\n\nå…ˆè¿›çš„æ•°æ®é›†æˆï¼šé›†æˆä¸–ç•Œé“¶è¡Œ API ä¸å…¨é¢çš„ç»æµæŒ‡æ ‡\nè‡ªç„¶è¯­è¨€å¤„ç†ï¼šAI é©±åŠ¨çš„ SQL ç”Ÿæˆï¼Œå®ç°ä¾¿æ·çš„æ•°æ®æŸ¥è¯¢\nä¸“ä¸šçš„è§†è§‰åŒ–ï¼šé‡‡ç”¨ä¸€è‡´è®¾è®¡çš„äº¤äº’å¼ Plotly å›¾è¡¨\nåŒè¯­æ”¯æŒï¼šå®Œæ•´çš„è‹±/ä¸­æœ¬åœ°åŒ–\nç”Ÿäº§çº§æ¶æ„ï¼šç¨³å¥çš„é”™è¯¯å¤„ç†ã€ç¼“å­˜å’Œéƒ¨ç½²\n\næ— è®ºæ‚¨æ˜¯ç»æµå­¦å®¶ã€æ•°æ®ç§‘å­¦å®¶è¿˜æ˜¯æ”¿ç­–åˆ†æå¸ˆï¼Œè¯¥åº”ç”¨ç¨‹åºéƒ½å±•ç¤ºäº†ç°ä»£ AI æŠ€æœ¯å¦‚ä½•é€šè¿‡ç›´è§‚çš„ç•Œé¢å’Œæ™ºèƒ½è‡ªåŠ¨åŒ–ï¼Œä½¿å¤æ‚çš„ç»æµæ•°æ®å˜å¾—æ›´åŠ æ˜“äºè·å–å’Œåˆ©ç”¨ã€‚\n\næŠ€æœ¯æ ˆï¼šStreamlit, DuckDB, Plotly, ModelScope API, World Bank API\næ•°æ®æºï¼šä¸–ç•Œé“¶è¡Œ (2000-2024, 200+ å›½å®¶, 15,000+ æ•°æ®ç‚¹)"
  },
  {
    "objectID": "posts/openrouter/index.html",
    "href": "posts/openrouter/index.html",
    "title": "OpenRouterï¼šå¤š AI æ¨¡å‹çš„ç»Ÿä¸€ API",
    "section": "",
    "text": "OpenRouter æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¹³å°ï¼Œå®ƒæä¾›äº†ä¸€ä¸ªç»Ÿä¸€çš„ API æ¥å£ï¼Œç”¨äºè®¿é—®æ¥è‡ªä¸åŒæä¾›å•†çš„å¤šä¸ª AI æ¨¡å‹ã€‚å¼€å‘äººå‘˜æ— éœ€åˆ†åˆ«ä¸ºæ¯ä¸ª AI æœåŠ¡è¿›è¡Œé›†æˆï¼Œè€Œæ˜¯å¯ä»¥ä½¿ç”¨ OpenRouter çš„å•ä¸€ç«¯ç‚¹è®¿é—®æ¥è‡ª OpenAIã€Anthropicã€Google ç­‰å…¬å¸çš„æ¨¡å‹ã€‚\n\n\nä½¿ç”¨ OpenRouter éå¸¸ç®€å•ï¼Œåªéœ€å‡ ä¸ªæ­¥éª¤å³å¯å®Œæˆã€‚è¯¥å¹³å°æ—¨åœ¨æœ€å¤§é™åº¦åœ°å‡å°‘è®¾ç½®æ—¶é—´ï¼ŒåŒæ—¶ä¿æŒå®‰å…¨æœ€ä½³å®è·µã€‚\n\n\n\né¦–å…ˆï¼Œè®¿é—® openrouter.ai å¹¶åˆ›å»ºä¸€ä¸ªè´¦æˆ·ã€‚æ³¨å†Œè¿‡ç¨‹éå¸¸ç®€å•ï¼š\n\næ³¨å†Œï¼šä½¿ç”¨æ‚¨çš„ç”µå­é‚®ç®±æˆ–ç¤¾äº¤ç™»å½•ï¼ˆGoogleã€GitHubï¼‰\néªŒè¯é‚®ç®±ï¼šé€šè¿‡éªŒè¯é“¾æ¥ç¡®è®¤æ‚¨çš„ç”µå­é‚®ç®±åœ°å€\nè®¿é—®ä»ªè¡¨æ¿ï¼šå¯¼èˆªåˆ°ä»ªè¡¨æ¿ï¼Œæ‚¨å¯ä»¥åœ¨é‚£é‡Œæ‰¾åˆ°æ‚¨çš„ API å¯†é’¥\n\nğŸ’¡ ä¸“å®¶æç¤ºï¼šæ‚¨çš„ä»ªè¡¨æ¿æä¾›äº†å®è´µçš„æ´å¯Ÿï¼ŒåŒ…æ‹¬ï¼š - ä½¿ç”¨ç»Ÿè®¡å’Œæˆæœ¬è¿½è¸ª - æ¨¡å‹æ€§èƒ½æŒ‡æ ‡ - API å¯†é’¥ç®¡ç† - è´¦å•ä¿¡æ¯\n\n\n\nåœ¨ä½¿ç”¨ AI API æ—¶ï¼Œå®‰å…¨è‡³å…³é‡è¦ã€‚åˆ‡å‹¿ç›´æ¥åœ¨ä»£ç ä¸­ç¡¬ç¼–ç  API å¯†é’¥ã€‚ç›¸åï¼Œä½¿ç”¨ç¯å¢ƒå˜æ¥ç¡®ä¿æ‚¨çš„å‡­æ®å®‰å…¨ï¼š\n\n\n\nå®‰å…¨æ€§ï¼šé˜²æ­¢åœ¨ç‰ˆæœ¬æ§åˆ¶ä¸­æ„å¤–æ³„éœ²\nçµæ´»æ€§ï¼šå…è®¸ä¸ºå¼€å‘ã€æµ‹è¯•å’Œç”Ÿäº§ç¯å¢ƒä½¿ç”¨ä¸åŒçš„å¯†é’¥\nåä½œï¼šå›¢é˜Ÿæˆå‘˜å¯ä»¥åœ¨ä¸å…±äº«çš„æƒ…å†µä¸‹ä½¿ç”¨è‡ªå·±çš„å¯†é’¥\néƒ¨ç½²ï¼šæ˜“äºåœ¨ä¸åŒçš„æ‰˜ç®¡ç¯å¢ƒä¸­è¿›è¡Œç®¡ç†\n\n\n\n\nåœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ª .env æ–‡ä»¶ï¼š\nOPENROUTER_API_KEY=your_actual_api_key_here\nå®‰è£… python-dotenv åº“ä»¥åŠ è½½ç¯å¢ƒå˜é‡ï¼š\npip install python-dotenv\n\n\n\n\nç°åœ¨æ‚¨å·²ç»è®¾ç½®å¥½äº† API å¯†é’¥ï¼Œè®©æˆ‘ä»¬è¿›è¡Œç¬¬ä¸€æ¬¡ API è°ƒç”¨ã€‚OpenRouter å·§å¦™åœ°ä½¿ç”¨äº†ä¸ OpenAI ç›¸åŒçš„ API æ ¼å¼ï¼Œè¿™æ„å‘³ç€æ‚¨å¯ä»¥ä½¿ç”¨ç†Ÿæ‚‰çš„ openai Python åº“ â€”â€” åªæ˜¯ä½¿ç”¨ä¸åŒçš„åŸºç«¯ç‚¹ URLã€‚\n\n\nğŸ”§ å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼šOpenRouter å……å½“æ™ºèƒ½ä»£ç†ï¼Œè´Ÿè´£ï¼š 1. æ¥æ”¶æ‚¨çš„æ ‡å‡†åŒ– API è¯·æ±‚ 2. å°†å…¶è·¯ç”±åˆ°é€‚å½“çš„ AI æ¨¡å‹æä¾›å•† 3. å¤„ç†ç‰¹å®šäºæä¾›å•†çš„èº«ä»½éªŒè¯å’Œæ ¼å¼åŒ– 4. ä»¥ä¸€è‡´çš„æ ¼å¼è¿”å›å“åº” 5. è¿½è¸ªæ‰€æœ‰æ¨¡å‹çš„ä½¿ç”¨æƒ…å†µå’Œæˆæœ¬\n\n\n\nåœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²å®‰è£…å¿…è¦çš„ Python åŒ…ï¼š\npip install openai python-dotenv\n\nopenai: å®˜æ–¹çš„ OpenAI Python å®¢æˆ·ç«¯ï¼ˆä¸ OpenRouter å…¼å®¹ï¼‰\npython-dotenv: ç”¨äºä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡\n\n\n\n\n\nPython (ä½¿ç”¨ OpenAI åŒ…)Python (ä½¿ç”¨ Chatlas åŒ…)R (ä½¿ç”¨ Ellmer åŒ…)\n\n\n\n\nCode\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\n# ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡\nload_dotenv()\n\n# ä½¿ç”¨ OpenRouter åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯\nclient = OpenAI(\n  base_url=\"https://openrouter.ai/api/v1\",  # OpenRouter çš„ API ç«¯ç‚¹\n  api_key=os.getenv(\"OPENROUTER_API_KEY\"),  # æ‚¨å®‰å…¨çš„ API å¯†é’¥\n)\n\n# ä½¿ç”¨ OpenRouter åˆ›å»ºå¯¹è¯è¡¥å…¨\ncompletion = client.chat.completions.create(\n  extra_headers={\n    \"HTTP-Referer\": \"https://your-site.com\",  # å¯é€‰ï¼šå¸®åŠ© OpenRouter æ”¹è¿›æœåŠ¡\n    \"X-Title\": \"Your Site Name\",             # å¯é€‰ï¼šç”¨äº OpenRouter æ’åçš„ç½‘ç«™åç§°\n  },\n  model=\"openai/gpt-oss-20b:free\",          # ç”¨äºæµ‹è¯•/å¼€å‘çš„å…è´¹æ¨¡å‹\n  messages=[\n    {\n      \"role\": \"user\",\n      \"content\": \"ä½ å¥½ï¼ä½ èƒ½ç”¨ç®€å•çš„æœ¯è¯­è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯ OpenRouter å—ï¼Ÿ\"\n    }\n  ],\n  temperature=0.7  # æ§åˆ¶åˆ›é€ åŠ› (0.0 = ç¡®å®šæ€§, 1.0 = éå¸¸æœ‰åˆ›æ„)\n)\n\n# æå–å¹¶æ‰“å°å“åº”\nprint(completion.choices[0].message.content)\n\n\n\n\n\n\nCode\nfrom chatlas import ChatOpenRouter\nimport os\nfrom dotenv import load_dotenv\n\n# ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡\nload_dotenv()\n\n# ä½¿ç”¨ OpenRouter åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯\nclient = ChatOpenRouter(api_key=os.getenv(\"OPENROUTER_API_KEY\")\n,base_url='https://openrouter.ai/api/v1'\n ,system_prompt=None\n ,model=\"openai/gpt-oss-20b:free\")\n\n\n\n\nCode\nresponse=client.chat(\"æ³•å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼Ÿ\")\n#str(response)\n\n\n\n\n\n\nCode\nlibrary(ellmer)\nlibrary(dotenv)\nload_dot_env(file = \".env\")\n\nchat &lt;- chat_openrouter(\n  system_prompt = NULL,\n  api_key = Sys.getenv(\"OPENROUTER_API_KEY\"),\n \n  model = \"openai/gpt-oss-20b:free\",\n  echo = \"none\"\n)\n\n\n\n\nCode\nchat$chat(\"ç»™æˆ‘è®²ä¸‰ä¸ªå…³äºç»Ÿè®¡å­¦å®¶çš„ç¬‘è¯\")\n\n\n\n\n\næ ¸å¿ƒç»„ä»¶è¯´æ˜ï¼š\n\nbase_urlï¼šæŒ‡å‘ OpenRouter çš„ API è€Œé OpenAI çš„\nmodelï¼šä½¿ç”¨ OpenRouter çš„æ¨¡å‹å‘½åæ ¼å¼ (æä¾›å•†/æ¨¡å‹åç§°)\nextra_headersï¼šå¯é€‰ï¼Œä½†å»ºè®®ç”¨äº OpenRouter çš„åˆ†æ\ntemperatureï¼šæ§åˆ¶å“åº”çš„åˆ›é€ åŠ›ï¼ˆèŒƒå›´ 0.0-2.0ï¼‰\nmessagesï¼šæ ‡å‡†çš„èŠå¤©æ ¼å¼ï¼Œé‡‡ç”¨åŸºäºè§’è‰²çš„å¯¹è¯ç»“æ„\n\nğŸ’¡ æ¨¡å‹é€‰æ‹©å»ºè®®ï¼š - å…è´¹æ¨¡å‹ï¼šéå¸¸é€‚åˆå¼€å‘é˜¶æ®µï¼ˆä»¥ *free ç»“å°¾ï¼‰ - ç»æµå‹æ¨¡å‹ï¼šé€‚åˆç”Ÿäº§ç¯å¢ƒçš„æˆæœ¬æ•ˆç›Šæ¨¡å‹ï¼ˆä»¥ *:budget ç»“å°¾ï¼‰ - é«˜çº§æ¨¡å‹ï¼šæœ€ä½³æ€§èƒ½ï¼ˆ*ã€*:proã€*:latestï¼‰ - ä¸“ä¸šæ¨¡å‹ï¼šé’ˆå¯¹ç‰¹å®šä»»åŠ¡ä¼˜åŒ–çš„æ¨¡å‹ï¼ˆç¼–ç¨‹ã€æ•°å­¦ã€åˆ›æ„å†™ä½œï¼‰\n\n\n\n\nç³»ç»Ÿæç¤ºè¯æ˜¯å¡‘é€  AI è¡Œä¸ºã€ä¸ªæ€§å’Œå›å¤é£æ ¼çš„å¼ºå¤§å·¥å…·ã€‚å®ƒä»¬è®¾ç½®äº†æ•´ä¸ªå¯¹è¯çš„ä¸Šä¸‹æ–‡å’Œè§„åˆ™ï¼Œåœ¨å¯¹è¯æµä¸­å‡ºç°åœ¨ç”¨æˆ·æ¶ˆæ¯ä¹‹å‰ã€‚\n\n\nç³»ç»Ÿæç¤ºè¯å……å½“å…ƒæŒ‡ä»¤ï¼ŒæŒ‡å¯¼ AI åœ¨æ•´ä¸ªå¯¹è¯ä¸­åº”å¦‚ä½•ååº”ã€‚å®ƒä»¬æœ€å…ˆè¢«å¤„ç†ï¼Œå¹¶å½±å“æ‰€æœ‰åç»­çš„äº¤äº’ã€‚\n\n\n\n\nä¸€è‡´çš„è¡Œä¸ºï¼šç¡®ä¿ AI åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­ä¿æŒæ‰€éœ€çš„ä¸ªæ€§\nè¾“å‡ºæ ¼å¼ï¼šè§„å®šå“åº”ç»“æ„ï¼ˆJSONã€Markdownã€ä»£ç å—ï¼‰\nå®‰å…¨çº¦æŸï¼šè®¾ç½®å›å¤çš„è¾¹ç•Œå’Œé™åˆ¶\nä¸Šä¸‹æ–‡è®¾ç½®ï¼šæä¾›èƒŒæ™¯ä¿¡æ¯ä»¥è·å¾—æ›´å¥½çš„å›å¤\nä»»åŠ¡ä¸“é—¨åŒ–ï¼šé’ˆå¯¹ç‰¹å®šç”¨ä¾‹ä¼˜åŒ– AI\n\n\n\n\n\n\nCode\n# å¸¦æœ‰ç³»ç»Ÿæç¤ºè¯çš„ç¤ºä¾‹\ncompletion = client.chat.completions.create(\n  model=\"openai/gpt-oss-20b:free\",\n  messages=[\n    {\n      \"role\": \"system\",\n      \"content\": \"ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ AI åŠ©æ‰‹ï¼Œå¯ä»¥ç”¨ç®€å•çš„æœ¯è¯­è§£é‡ŠæŠ€æœ¯æ¦‚å¿µã€‚å§‹ç»ˆä¿æŒå‹å¥½ï¼Œå¹¶å°½å¯èƒ½ä½¿ç”¨ç±»æ¯”ï¼Œä¿æŒç®€å•ã€‚\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"LLM æ¨¡å‹ä¸­çš„æ¸©åº¦ (temperature) æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ\"\n    }\n  ],\n  temperature=0.7\n)\n\nprint(completion.choices[0].message.content)\n\n\nå¸¸è§çš„ç³»ç»Ÿæç¤ºè¯æ¨¡å¼ï¼š\n\n\nCode\n# ä¸åŒçš„ç³»ç»Ÿæç¤ºè¯ç¤ºä¾‹\nsystem_prompts = {\n    \"coding_assistant\": \"ä½ æ˜¯ä¸€ä¸ªä¸“å®¶çº§ç¨‹åºå‘˜ã€‚æä¾›æ•´æ´ã€æ³¨é‡Šè‰¯å¥½çš„ä»£ç è§£å†³æ–¹æ¡ˆï¼Œå¹¶è§£é‡Šä½ çš„æ¨ç†ã€‚\",\n    \"creative_writer\": \"ä½ æ˜¯ä¸€ä¸ªåˆ›æ„æ•…äº‹è®²è¿°è€…ã€‚ç¼–å†™å…·æœ‰ç”ŸåŠ¨æè¿°å’Œå¼•äººå…¥èƒœè§’è‰²çš„åŠ¨äººå™è¿°ã€‚\",\n    \"data_analyst\": \"ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æå¸ˆã€‚æ ¹æ®æ•°æ®æä¾›è§è§£ï¼Œå»ºè®®å¯è§†åŒ–æ–¹å¼ï¼Œå¹¶æ¸…æ™°åœ°è§£é‡Šç»Ÿè®¡æ¦‚å¿µã€‚\",\n    \"tutor\": \"ä½ æ˜¯ä¸€ä¸ªè€å¿ƒçš„å¯¼å¸ˆã€‚å°†å¤æ‚çš„ä¸»é¢˜åˆ†è§£ä¸ºç®€å•çš„æ­¥éª¤å¹¶æä¾›é¼“åŠ±æ€§çš„åé¦ˆã€‚\"\n}\n\ndef chat_with_persona(persona, user_message):\n    completion = client.chat.completions.create(\n        model=\"openai/gpt-oss-20b:free\",\n        messages=[\n            {\"role\": \"system\", \"content\": system_prompts[persona]},\n            {\"role\": \"user\", \"content\": user_message}\n        ],\n        temperature=0.7\n    )\n    return completion.choices[0].message.content\n\n# ç¤ºä¾‹ç”¨æ³•\n#response = chat_with_persona(\"coding_assistant\", \"å¦‚ä½•ç”¨ Python åè½¬å­—ç¬¦ä¸²ï¼Ÿ\")\n#print(response)\n\n\n\n\n\n\næµå¼ä¼ è¾“ (Streaming) æ˜¯æå‡ç”¨æˆ·ä½“éªŒçš„åˆ©å™¨ï¼Œç‰¹åˆ«æ˜¯åœ¨èŠå¤©åº”ç”¨å’Œäº¤äº’å¼å·¥å…·ä¸­ã€‚æµå¼ä¼ è¾“ä¸æ˜¯ç­‰å¾…å®Œæ•´çš„å“åº”ï¼Œè€Œæ˜¯åœ¨ç”Ÿæˆå†…å®¹æ—¶ç«‹å³äº¤ä»˜ï¼Œä»è€Œåˆ›é€ è‡ªç„¶ä¸”å¼•äººå…¥èƒœçš„å¯¹è¯ã€‚\n\n\nğŸš€ ç”¨æˆ·ä½“éªŒä¼˜åŠ¿ï¼š - ç«‹å³åé¦ˆï¼šç”¨æˆ·èƒ½ç«‹å³çœ‹åˆ°å“åº”å¼€å§‹ç”Ÿæˆ - é™ä½æ„ŸçŸ¥å»¶è¿Ÿï¼šå†…å®¹åœ¨ç”Ÿæˆæ—¶å³åˆ»æ˜¾ç¤º - è‡ªç„¶çš„å¯¹è¯æµï¼šæ¨¡ä»¿äººç±»è¯´è¯çš„æ¨¡å¼ - è¿›åº¦æŒ‡ç¤ºï¼šç”¨æˆ·çŸ¥é“ AI æ­£åœ¨å·¥ä½œ - åŠæ—©ç»ˆæ­¢ï¼šå¦‚æœéœ€è¦ï¼Œç”¨æˆ·å¯ä»¥åœæ­¢è¿‡é•¿çš„å›å¤\nâš¡ æŠ€æœ¯ä¼˜åŠ¿ï¼š - æ›´ä½çš„å†…å­˜å ç”¨ï¼šæ— éœ€ç¼“å†²å®Œæ•´å“åº” - æ›´å¿«çš„é¦–å­—èŠ‚æ—¶é—´ï¼šå†…å®¹ç«‹å³å¼€å§‹æµåŠ¨ - æ›´å¥½çš„é”™è¯¯å¤„ç†ï¼šåœ¨è¿‡ç¨‹ä¸­æ›´æ—©å‘ç°é—®é¢˜ - èµ„æºæ•ˆç‡ï¼šå¢é‡å¤„ç†æ•°æ®\n\n\n\n\n\nCode\n# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ˆå¦‚æœå°šæœªå®Œæˆï¼‰\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\nclient = OpenAI(\n  base_url=\"https://openrouter.ai/api/v1\",\n  api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n)\n\ndef stream_response(model, message):\n    stream = client.chat.completions.create(\n        model=model,\n        messages=[{\"role\": \"user\", \"content\": message}],\n        stream=True\n    )\n\n    for chunk in stream:\n        if chunk.choices[0].delta.content is not None:\n            print(chunk.choices[0].delta.content, end='', flush=True)\n\n# æµå¼ä¼ è¾“ç¤ºä¾‹\nprint(\"æ­£åœ¨æµå¼ä¼ è¾“å“åº”ï¼š\")\nstream_response(\"openai/gpt-oss-20b:free\", \"è¯·ç»™æˆ‘è®²ä¸€ä¸ªå…³äº AI çš„çŸ­ç¯‡æ•…äº‹\")\nprint()  # æµå¼ä¼ è¾“ç»“æŸåæ·»åŠ æ¢è¡Œ\n\n\n\n\n\n\n\nCode\nfrom openai import OpenAI\nimport base64\nimport datetime\n\n\n\n\nCode\n# | eval: false\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\n# ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡\nload_dotenv()\n\n# ä½¿ç”¨ OpenRouter åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯\nclient = OpenAI(\n    base_url=\"https://openrouter.ai/api/v1\",\n    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n)\n\n\n\n\nCode\n# å›¾åƒç”Ÿæˆè¯·æ±‚\nresponse = client.chat.completions.create(\n    extra_headers={\n        \"HTTP-Referer\": \"www.tonydotdev.com\",\n        \"X-Title\": \"TT_AI_blog\",\n    },\n    model=\"google/gemini-2.5-flash-image\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"ç”Ÿæˆä¸€å¼ å®é™ä¸”å†™å®çš„æ—¥å‡ºé›ªå±±é£æ™¯å›¾ã€‚\",\n        }\n    ],\n    modalities=[\"image\", \"text\"],\n    #image_size=\"1024x1024\",\n)\n\n\n\n\nCode\nimport base64\nimport datetime\n# æå–æ¶ˆæ¯\nmessage = response.choices[0].message\n\n# å¤„ç†å›¾åƒè¾“å‡ºï¼ˆbase64 å­—ç¬¦ä¸²ä½äº \"data:image/png;base64,...\" ä¸­ï¼‰\nif message.images:\n    data_url = message.images[0][\"image_url\"][\"url\"]\n\n    # å¦‚æœå­˜åœ¨å‰ç¼€åˆ™å°†å…¶å‰¥ç¦»\n    if data_url.startswith(\"data:image\"):\n        _, base64_data = data_url.split(\",\", 1)\n    else:\n        base64_data = data_url\n\n    # è§£ç å¹¶ä¿å­˜ä¸º PNG\n    image_bytes = base64.b64decode(base64_data)\n    current_time = datetime.datetime.now().strftime(\"%H%M\")\n    output_file = f\"text_image_gemini_25_openrouter_{current_time}.png\"\n    with open(output_file, \"wb\") as f:\n        f.write(image_bytes)\n\n    print(f\"âœ… å›¾åƒå·²ä¿å­˜ä¸º {output_file}\")\nelse:\n    print(\"âŒ å“åº”ä¸­æœªè¿”å›å›¾åƒ\")\n\n\n\n\nCode\nfrom IPython.display import Image, display\n\ndisplay(Image(filename=\"text_image_gemini_25_openrouter_1352.png\"))\n\n\n&lt;IPython.core.display.Image object&gt;\n\n\n\n\n\n\n\nCode\nimport base64\n\n# å°†æœ¬åœ°å›¾åƒè½¬æ¢ä¸º data URL\nwith open(\"text_image_gemini_25_openrouter_1352.png\", \"rb\") as image_file:\n    base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n    data_url = f\"data:image/png;base64,{base64_image}\"\n\ncompletion = client.chat.completions.create(\n  extra_headers={\n    \"HTTP-Referer\": \"&lt;æ‚¨çš„ç½‘ç«™URL&gt;\", # å¯é€‰ï¼šOpenRouter æ’åç”¨çš„ç½‘ç«™ URL\n    \"X-Title\": \"&lt;æ‚¨çš„ç½‘ç«™åç§°&gt;\", # å¯é€‰ï¼šOpenRouter æ’åç”¨çš„ç½‘ç«™åç§°\n  },\n  extra_body={},\n  model=\"nvidia/nemotron-nano-12b-v2-vl:free\",\n  messages=[\n              {\n                \"role\": \"user\",\n                \"content\": [\n                  {\n                    \"type\": \"text\",\n                    \"text\": \"è¿™å¼ å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆï¼Ÿ\"\n                  },\n                  {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\n                      \"url\": data_url\n                    }\n                  }\n                ]\n              }\n            ]\n)\nprint(completion.choices[0].message.content)\n\n\n\n\n\n\n\nCode\n# | eval: false\nimport base64\n\n# å°†ä¹‹å‰ç”Ÿæˆçš„å›¾åƒè½¬æ¢ä¸º base64\nwith open(\"text_image_gemini_25_openrouter_1352.png\", \"rb\") as image_file:\n    base64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n\nresponse = client.chat.completions.create(\n    extra_headers={\n        \"HTTP-Referer\": \"www.tonydotdev.com\",\n        \"X-Title\": \"TT_AI_blog\",\n    },\n    model=\"google/gemini-2.5-flash-image\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"text\",\n                    \"text\": \"å°†è¿™å¼ å›¾ç‰‡è½¬æ¢ä¸ºæ—¥è½ç‰ˆæœ¬ï¼Œä½¿ç”¨æ›´æ¸©æš–çš„è‰²å½©å’Œé‡‘è‰²çš„å…‰çº¿ã€‚åœ¨å‰æ™¯ä¸­å¢åŠ ä¸€ä¸ªæ­£åœ¨æ»‘é›ªçš„äººã€‚\",\n                },\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"},\n                },\n            ],\n        }\n    ],\n    modalities=[\"image\", \"text\"],\n    # image_size=\"1024x1024\",\n)\n\n\n\n\nCode\nimport base64\nimport datetime\n# æå–æ¶ˆæ¯\nmessage = response.choices[0].message\n\n# å¤„ç†å›¾åƒè¾“å‡ºï¼ˆbase64 å­—ç¬¦ä¸²ä½äº \"data:image/png;base64,...\" ä¸­ï¼‰\nif message.images:\n    data_url = message.images[0][\"image_url\"][\"url\"]\n\n    # å¦‚æœå­˜åœ¨å‰ç¼€åˆ™å°†å…¶å‰¥ç¦»\n    if data_url.startswith(\"data:image\"):\n        _, base64_data = data_url.split(\",\", 1)\n    else:\n        base64_data = data_url\n\n    # è§£ç å¹¶ä¿å­˜ä¸º PNG\n    image_bytes = base64.b64decode(base64_data)\n    current_time = datetime.datetime.now().strftime(\"%H%M\")\n    output_file = f\"text_image_gemini_25_openrouter_{current_time}.png\"\n    with open(output_file, \"wb\") as f:\n        f.write(image_bytes)\n\n    print(f\"âœ… å›¾åƒå·²ä¿å­˜ä¸º {output_file}\")\nelse:\n    print(\"âŒ å“åº”ä¸­æœªè¿”å›å›¾åƒ\")\n\n\n\n\nCode\nfrom IPython.display import Image, display\n\ndisplay(Image(filename=\"text_image_gemini_25_openrouter_1405.png\"))\n\n\n\n\n\n\n\nCode\nfrom openai import OpenAI\n## 8. æ–‡æœ¬åµŒå…¥ (Embedding)\n\n\n\n\nCode\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\n# ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡\nload_dotenv()\n\n# ä½¿ç”¨ OpenRouter åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯\nclient = OpenAI(\n    base_url=\"https://openrouter.ai/api/v1\",\n    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n)\n\n\nembedding = client.embeddings.create(\n  extra_headers={\n    \"HTTP-Referer\": \"&lt;YOUR_SITE_URL&gt;\", # å¯é€‰ï¼šOpenRouter æ’åç”¨çš„ç½‘ç«™ URL\n    \"X-Title\": \"&lt;YOUR_SITE_NAME&gt;\", # å¯é€‰ï¼šOpenRouter æ’åç”¨çš„ç½‘ç«™åç§°\n  },\n  model=\"thenlper/gte-base\",\n  input=\"I can\",\n  encoding_format=\"float\"\n)\n\n#print(embedding.data[0].embedding) \n\n\n\n\nCode\nlen(embedding.data[0].embedding)\n\n\n\n\nCode\nprint(embedding.data[0].embedding[:5])  # æ‰“å°å‰ 5 ä¸ªç»´åº¦\n\n\n\n\n\n\nOpenRouter æœ€å¼ºå¤§çš„åŠŸèƒ½ä¹‹ä¸€æ˜¯å…¶é€æ˜çš„å®šä»·æ¨¡å‹å’Œæˆæœ¬ç®¡ç†èƒ½åŠ›ã€‚å¯¹äºç”Ÿäº§çº§ AI åº”ç”¨æ¥è¯´ï¼Œç†è§£å’Œç®¡ç†æˆæœ¬è‡³å…³é‡è¦ã€‚\n\n\n\nğŸ’° è´¢åŠ¡è§„åˆ’ï¼š - å¯é¢„æµ‹çš„æ¯æœˆæ”¯å‡º - ä¸ºä¸åŒç”¨ä¾‹åˆ†é…é¢„ç®— - AI åŠŸèƒ½çš„ ROI åˆ†æ - æ¯ä¸ªç”¨æˆ·çš„æˆæœ¬è¿½è¸ª\nğŸ” æŠ€æœ¯ä¼˜åŒ–ï¼š - æ ¹æ®æˆæœ¬/æ€§èƒ½æ¯”é€‰æ‹©æ¨¡å‹ - æç¤ºè¯å·¥ç¨‹ä»¥å‡å°‘ Token ä½¿ç”¨ - é‡å¤è¯·æ±‚çš„ç¼“å­˜ç­–ç•¥ - æé«˜æ•ˆç‡çš„æ‰¹é‡å¤„ç†\n\n\n\nOpenRouter æä¾›äº†é€šè¿‡ç¼–ç¨‹æ–¹å¼è®¿é—®æ‰€æœ‰æ¨¡å‹å½“å‰å®šä»·çš„æ¥å£ï¼š\n\n\nCode\n# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ˆå¦‚æœå°šæœªå®Œæˆï¼‰\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\nimport pandas as pd\n\nload_dotenv()\n\n\nTrue\n\n\nCode\nclient = OpenAI(\n  base_url=\"https://openrouter.ai/api/v1\",\n  api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n)\n\ndef get_model_pricing():\n    models_list = client.models.list()\n    pricing_data = []\n\n    for model in models_list.data:\n        name = model.id\n        pricing = model.pricing\n\n        # è·å–æ¨¡å‹å…ƒæ•°æ®\n        context_length = getattr(model, 'context_length', None)\n        description = getattr(model, 'description', '')\n\n        # è·å–åˆ›å»ºæ—¥æœŸå¹¶è½¬æ¢ä¸ºå¯è¯»æ ¼å¼\n        created_timestamp = getattr(model, 'created', None)\n        if created_timestamp:\n            import datetime\n            created_date = datetime.datetime.fromtimestamp(created_timestamp).strftime('%Y-%m-%d')\n        else:\n            created_date = None\n\n        # ä»æ¨¡å‹åç§°ä¸­æå–å…¬å¸ï¼ˆ'/' å‰çš„ç¬¬ä¸€éƒ¨åˆ†ï¼‰\n        company = name.split('/')[0] if '/' in name else 'Unknown'\n\n        # å°†æ¯ä¸ª Token çš„ä»·æ ¼è½¬æ¢ä¸ºæ¯ 100 ä¸‡ä¸ª Token çš„æˆæœ¬\n        prompt_cost = float(pricing.get('prompt', 0)) * 1000000 if pricing and pricing.get('prompt') else 0\n        completion_cost = float(pricing.get('completion', 0)) * 1000000 if pricing and pricing.get('completion') else 0\n        request_cost = float(pricing.get('request', 0)) * 1000000 if pricing and pricing.get('request') else 0\n        image_cost = float(pricing.get('image', 0)) * 1000000 if pricing and pricing.get('image') else 0\n\n        pricing_data.append({\n            'æ¨¡å‹': name,\n            'å…¬å¸': company,\n            'æè¿°': description,\n            'ä¸Šä¸‹æ–‡é•¿åº¦': context_length,\n            'åˆ›å»ºæ—¥æœŸ': created_date,\n            'æç¤ºè¯æˆæœ¬_æ¯1M': prompt_cost,\n            'è¡¥å…¨æˆæœ¬_æ¯1M': completion_cost,\n            'è¯·æ±‚æˆæœ¬_æ¯1M': request_cost,\n            'å›¾åƒæˆæœ¬_æ¯1M': image_cost\n        })\n\n    # åˆ›å»º Pandas DataFrame\n    df = pd.DataFrame(pricing_data)\n\n    # æŒ‰å…¬å¸ã€æ¨¡å‹åç§°æ’åºï¼Œæ–¹ä¾¿æ•´ç†\n    df = df.sort_values(['å…¬å¸', 'æ¨¡å‹']).reset_index(drop=True)\n\n    return df\n\n# è·å–ä»·æ ¼ DataFrameï¼ˆå…¨é‡æ¨¡å‹ä»¥åŠä»…ä»˜è´¹æ¨¡å‹ï¼‰\nall_models_df = get_model_pricing()\n\n\n\n\n\n\nCode\nimport panel as pn\n\n\ndf = all_models_df[\n    [\n        \"æ¨¡å‹\",\n        \"ä¸Šä¸‹æ–‡é•¿åº¦\",\n        \"åˆ›å»ºæ—¥æœŸ\",\n        \"æç¤ºè¯æˆæœ¬_æ¯1M\",\n        \"è¡¥å…¨æˆæœ¬_æ¯1M\",\n    ]\n].sort_values(\"æç¤ºè¯æˆæœ¬_æ¯1M\", ascending=False)\n\n# åˆ›å»ºä¸€ä¸ªå¸¦åˆ†é¡µçš„è¡¨æ ¼\npn.extension(\"tabulator\")\ntable = pn.widgets.Tabulator(df, pagination=\"local\", page_size=10, show_index=False)\ntable\n\n\nTabulator(page_size=10, pagination='local', show_index=False, value=              ...)\n\n\n\n\n\n\néµå¾ªè¿™äº›æœ€ä½³å®è·µå°†å¸®åŠ©æ‚¨ä½¿ç”¨ OpenRouter æ„å»ºç¨³å¥ã€å®‰å…¨ä¸”é«˜æ•ˆçš„ AI åº”ç”¨ç¨‹åºã€‚\n\n\n\n\n\n\nåˆ‡å‹¿ç¡¬ç¼–ç  API å¯†é’¥åœ¨æºä»£ç æˆ–é…ç½®æ–‡ä»¶ä¸­\nä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–ç§˜å¯†ç®¡ç†ç³»ç»Ÿï¼ˆå¦‚ AWS Secrets Managerã€Azure Key Vaultï¼‰\nå®šæœŸè½®æ¢ API å¯†é’¥å¹¶å®æ–½å¯†é’¥è½®æ¢ç­–ç•¥\nä½¿ç”¨ä¸åŒçš„å¯†é’¥ç”¨äºå¼€å‘ã€æµ‹è¯•å’Œç”Ÿäº§ç¯å¢ƒ\nå°† .env æ·»åŠ åˆ° .gitignore â€”â€” æ°¸è¿œä¸è¦å°†å‡­æ®æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶ä¸­\n\n\n\n\n\nåœ¨å‘é€åˆ° AI æ¨¡å‹ä¹‹å‰éªŒè¯ç”¨æˆ·è¾“å…¥\næ¸…ç†æç¤ºè¯ä»¥é˜²æ­¢æç¤ºè¯æ³¨å…¥æ”»å‡»\nå®æ–½é€Ÿç‡é™åˆ¶ä»¥é˜²æ­¢æ»¥ç”¨\nè®°å½•å¹¶ç›‘æ§å¼‚å¸¸æ´»åŠ¨æ¨¡å¼\n\n\n\n\n\n\n\n\nä¸ºæ‚¨çš„ç”¨ä¾‹é€‰æ‹©åˆé€‚çš„æ¨¡å‹ â€”â€” å¹¶éæ‰€æœ‰ä»»åŠ¡éƒ½éœ€è¦æœ€æ˜‚è´µçš„æ¨¡å‹\né’ˆå¯¹æ‚¨çš„ç‰¹å®šç”¨ä¾‹è¿›è¡Œæ¨¡å‹åŸºå‡†æµ‹è¯•\nä½¿ç”¨å…è´¹æ¨¡å‹è¿›è¡Œå¼€å‘å’Œæµ‹è¯•\nè€ƒè™‘ä¸“ç”¨æ¨¡å‹å¤„ç†ç‰¹å®šä»»åŠ¡ï¼ˆç¼–ç¨‹ã€æ•°å­¦ã€åˆ›æ„å†™ä½œï¼‰\n\n\n\n\n\nå®æ–½ç¼“å­˜ä»¥å‡å°‘é‡å¤è¯·æ±‚çš„æˆæœ¬\nä½¿ç”¨æµå¼ä¼ è¾“ä»¥è·å¾—æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ\nåœ¨é€‚å½“æƒ…å†µä¸‹è¿›è¡Œæ‰¹é‡è¯·æ±‚ä»¥æé«˜æ•ˆç‡\nä¼˜åŒ–æç¤ºè¯ â€”â€” ç²¾å¿ƒè®¾è®¡çš„æç¤ºè¯å¯ä»¥å‡å°‘ Token ä½¿ç”¨å¹¶æ”¹å–„ç»“æœ\n\n\n\n\n\n\n\n\nå®æ–½å…¨é¢çš„é”™è¯¯å¤„ç† â€”â€” æ¨¡å‹å¯èƒ½ä¼šä¸å¯ç”¨æˆ–å—åˆ°é€Ÿç‡é™åˆ¶\nä½¿ç”¨å¤‡ç”¨æ¨¡å‹ â€”â€” ç¡®ä¿å³ä½¿ä¸€ä¸ªæ¨¡å‹å®•æœºï¼Œæ‚¨çš„åº”ç”¨ç¨‹åºä»èƒ½æ­£å¸¸è¿è¡Œ\nå®æ–½å¸¦æœ‰æŒ‡æ•°é€€é¿çš„é‡è¯•é€»è¾‘\nç›‘æ§å“åº”æ—¶é—´å¹¶è®¾ç½®é€‚å½“çš„è¶…æ—¶\n\n\n\n\n\nç›‘æ§ä½¿ç”¨æƒ…å†µ â€”â€” è¿½è¸ªæˆæœ¬å¹¶è®¾ç½®é™åˆ¶\nè¿½è¸ªæ€§èƒ½æŒ‡æ ‡ï¼ˆå»¶è¿Ÿã€æˆåŠŸç‡ã€é”™è¯¯ç‡ï¼‰\nä¸ºå¼‚å¸¸æ´»åŠ¨æ¨¡å¼è®¾ç½®å‘Šè­¦\nåˆ›å»ºå®æ—¶ç›‘æ§ä»ªè¡¨æ¿\n\n\n\n\n\n\n\n\nåœ¨ OpenRouter ä»ªè¡¨æ¿ä¸­è®¾ç½®æ”¯å‡ºé™åˆ¶å’Œå‘Šè­¦\nä¸ºéå…³é”®ä»»åŠ¡ä½¿ç”¨é«˜æ€§ä»·æ¯”æ¨¡å‹\nå®æ–½ Token è®¡æ•°ä»¥åœ¨è¯·æ±‚å‰ä¼°ç®—æˆæœ¬\nå®šæœŸæŸ¥çœ‹ä½¿ç”¨æŠ¥å‘Šä»¥è¯†åˆ«ä¼˜åŒ–æœºä¼š\n\n\n\n\n\nOpenRouter ä»£è¡¨äº†å¼€å‘äººå‘˜ä¸ AI æ¨¡å‹äº¤äº’æ–¹å¼çš„èŒƒå¼è½¬å˜ã€‚é€šè¿‡æä¾›è®¿é—®ä¸–ç•Œä¸Šæœ€å…ˆè¿› AI æ¨¡å‹çš„ç»Ÿä¸€ã€å¯é ä¸”æå…·æˆæœ¬æ•ˆç›Šçš„ç½‘å…³ï¼ŒOpenRouter è®©å¼€å‘äººå‘˜èƒ½å¤Ÿä¸“æ³¨äºåˆ›é€ ä»·å€¼ï¼Œè€Œä¸æ˜¯å¤„ç†å¤æ‚çš„åŸºç¡€è®¾æ–½ã€‚"
  },
  {
    "objectID": "posts/openrouter/index.html#openrouter-å…¥é—¨",
    "href": "posts/openrouter/index.html#openrouter-å…¥é—¨",
    "title": "OpenRouterï¼šå¤š AI æ¨¡å‹çš„ç»Ÿä¸€ API",
    "section": "",
    "text": "ä½¿ç”¨ OpenRouter éå¸¸ç®€å•ï¼Œåªéœ€å‡ ä¸ªæ­¥éª¤å³å¯å®Œæˆã€‚è¯¥å¹³å°æ—¨åœ¨æœ€å¤§é™åº¦åœ°å‡å°‘è®¾ç½®æ—¶é—´ï¼ŒåŒæ—¶ä¿æŒå®‰å…¨æœ€ä½³å®è·µã€‚"
  },
  {
    "objectID": "posts/openrouter/index.html#åˆ›å»ºæ‚¨çš„-openrouter-è´¦æˆ·",
    "href": "posts/openrouter/index.html#åˆ›å»ºæ‚¨çš„-openrouter-è´¦æˆ·",
    "title": "OpenRouterï¼šå¤š AI æ¨¡å‹çš„ç»Ÿä¸€ API",
    "section": "",
    "text": "é¦–å…ˆï¼Œè®¿é—® openrouter.ai å¹¶åˆ›å»ºä¸€ä¸ªè´¦æˆ·ã€‚æ³¨å†Œè¿‡ç¨‹éå¸¸ç®€å•ï¼š\n\næ³¨å†Œï¼šä½¿ç”¨æ‚¨çš„ç”µå­é‚®ç®±æˆ–ç¤¾äº¤ç™»å½•ï¼ˆGoogleã€GitHubï¼‰\néªŒè¯é‚®ç®±ï¼šé€šè¿‡éªŒè¯é“¾æ¥ç¡®è®¤æ‚¨çš„ç”µå­é‚®ç®±åœ°å€\nè®¿é—®ä»ªè¡¨æ¿ï¼šå¯¼èˆªåˆ°ä»ªè¡¨æ¿ï¼Œæ‚¨å¯ä»¥åœ¨é‚£é‡Œæ‰¾åˆ°æ‚¨çš„ API å¯†é’¥\n\nğŸ’¡ ä¸“å®¶æç¤ºï¼šæ‚¨çš„ä»ªè¡¨æ¿æä¾›äº†å®è´µçš„æ´å¯Ÿï¼ŒåŒ…æ‹¬ï¼š - ä½¿ç”¨ç»Ÿè®¡å’Œæˆæœ¬è¿½è¸ª - æ¨¡å‹æ€§èƒ½æŒ‡æ ‡ - API å¯†é’¥ç®¡ç† - è´¦å•ä¿¡æ¯"
  },
  {
    "objectID": "posts/openrouter/index.html#å®‰å…¨çš„-api-å¯†é’¥ç®¡ç†",
    "href": "posts/openrouter/index.html#å®‰å…¨çš„-api-å¯†é’¥ç®¡ç†",
    "title": "OpenRouterï¼šå¤š AI æ¨¡å‹çš„ç»Ÿä¸€ API",
    "section": "",
    "text": "åœ¨ä½¿ç”¨ AI API æ—¶ï¼Œå®‰å…¨è‡³å…³é‡è¦ã€‚åˆ‡å‹¿ç›´æ¥åœ¨ä»£ç ä¸­ç¡¬ç¼–ç  API å¯†é’¥ã€‚ç›¸åï¼Œä½¿ç”¨ç¯å¢ƒå˜æ¥ç¡®ä¿æ‚¨çš„å‡­æ®å®‰å…¨ï¼š\n\n\n\nå®‰å…¨æ€§ï¼šé˜²æ­¢åœ¨ç‰ˆæœ¬æ§åˆ¶ä¸­æ„å¤–æ³„éœ²\nçµæ´»æ€§ï¼šå…è®¸ä¸ºå¼€å‘ã€æµ‹è¯•å’Œç”Ÿäº§ç¯å¢ƒä½¿ç”¨ä¸åŒçš„å¯†é’¥\nåä½œï¼šå›¢é˜Ÿæˆå‘˜å¯ä»¥åœ¨ä¸å…±äº«çš„æƒ…å†µä¸‹ä½¿ç”¨è‡ªå·±çš„å¯†é’¥\néƒ¨ç½²ï¼šæ˜“äºåœ¨ä¸åŒçš„æ‰˜ç®¡ç¯å¢ƒä¸­è¿›è¡Œç®¡ç†\n\n\n\n\nåœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ª .env æ–‡ä»¶ï¼š\nOPENROUTER_API_KEY=your_actual_api_key_here\nå®‰è£… python-dotenv åº“ä»¥åŠ è½½ç¯å¢ƒå˜é‡ï¼š\npip install python-dotenv"
  },
  {
    "objectID": "posts/openrouter/index.html#æ‚¨çš„ç¬¬ä¸€æ¬¡-api-è°ƒç”¨",
    "href": "posts/openrouter/index.html#æ‚¨çš„ç¬¬ä¸€æ¬¡-api-è°ƒç”¨",
    "title": "OpenRouterï¼šå¤š AI æ¨¡å‹çš„ç»Ÿä¸€ API",
    "section": "",
    "text": "ç°åœ¨æ‚¨å·²ç»è®¾ç½®å¥½äº† API å¯†é’¥ï¼Œè®©æˆ‘ä»¬è¿›è¡Œç¬¬ä¸€æ¬¡ API è°ƒç”¨ã€‚OpenRouter å·§å¦™åœ°ä½¿ç”¨äº†ä¸ OpenAI ç›¸åŒçš„ API æ ¼å¼ï¼Œè¿™æ„å‘³ç€æ‚¨å¯ä»¥ä½¿ç”¨ç†Ÿæ‚‰çš„ openai Python åº“ â€”â€” åªæ˜¯ä½¿ç”¨ä¸åŒçš„åŸºç«¯ç‚¹ URLã€‚\n\n\nğŸ”§ å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼šOpenRouter å……å½“æ™ºèƒ½ä»£ç†ï¼Œè´Ÿè´£ï¼š 1. æ¥æ”¶æ‚¨çš„æ ‡å‡†åŒ– API è¯·æ±‚ 2. å°†å…¶è·¯ç”±åˆ°é€‚å½“çš„ AI æ¨¡å‹æä¾›å•† 3. å¤„ç†ç‰¹å®šäºæä¾›å•†çš„èº«ä»½éªŒè¯å’Œæ ¼å¼åŒ– 4. ä»¥ä¸€è‡´çš„æ ¼å¼è¿”å›å“åº” 5. è¿½è¸ªæ‰€æœ‰æ¨¡å‹çš„ä½¿ç”¨æƒ…å†µå’Œæˆæœ¬\n\n\n\nåœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨å·²å®‰è£…å¿…è¦çš„ Python åŒ…ï¼š\npip install openai python-dotenv\n\nopenai: å®˜æ–¹çš„ OpenAI Python å®¢æˆ·ç«¯ï¼ˆä¸ OpenRouter å…¼å®¹ï¼‰\npython-dotenv: ç”¨äºä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡\n\n\n\n\n\nPython (ä½¿ç”¨ OpenAI åŒ…)Python (ä½¿ç”¨ Chatlas åŒ…)R (ä½¿ç”¨ Ellmer åŒ…)\n\n\n\n\nCode\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\n# ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡\nload_dotenv()\n\n# ä½¿ç”¨ OpenRouter åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯\nclient = OpenAI(\n  base_url=\"https://openrouter.ai/api/v1\",  # OpenRouter çš„ API ç«¯ç‚¹\n  api_key=os.getenv(\"OPENROUTER_API_KEY\"),  # æ‚¨å®‰å…¨çš„ API å¯†é’¥\n)\n\n# ä½¿ç”¨ OpenRouter åˆ›å»ºå¯¹è¯è¡¥å…¨\ncompletion = client.chat.completions.create(\n  extra_headers={\n    \"HTTP-Referer\": \"https://your-site.com\",  # å¯é€‰ï¼šå¸®åŠ© OpenRouter æ”¹è¿›æœåŠ¡\n    \"X-Title\": \"Your Site Name\",             # å¯é€‰ï¼šç”¨äº OpenRouter æ’åçš„ç½‘ç«™åç§°\n  },\n  model=\"openai/gpt-oss-20b:free\",          # ç”¨äºæµ‹è¯•/å¼€å‘çš„å…è´¹æ¨¡å‹\n  messages=[\n    {\n      \"role\": \"user\",\n      \"content\": \"ä½ å¥½ï¼ä½ èƒ½ç”¨ç®€å•çš„æœ¯è¯­è§£é‡Šä¸€ä¸‹ä»€ä¹ˆæ˜¯ OpenRouter å—ï¼Ÿ\"\n    }\n  ],\n  temperature=0.7  # æ§åˆ¶åˆ›é€ åŠ› (0.0 = ç¡®å®šæ€§, 1.0 = éå¸¸æœ‰åˆ›æ„)\n)\n\n# æå–å¹¶æ‰“å°å“åº”\nprint(completion.choices[0].message.content)\n\n\n\n\n\n\nCode\nfrom chatlas import ChatOpenRouter\nimport os\nfrom dotenv import load_dotenv\n\n# ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡\nload_dotenv()\n\n# ä½¿ç”¨ OpenRouter åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯\nclient = ChatOpenRouter(api_key=os.getenv(\"OPENROUTER_API_KEY\")\n,base_url='https://openrouter.ai/api/v1'\n ,system_prompt=None\n ,model=\"openai/gpt-oss-20b:free\")\n\n\n\n\nCode\nresponse=client.chat(\"æ³•å›½çš„é¦–éƒ½æ˜¯å“ªé‡Œï¼Ÿ\")\n#str(response)\n\n\n\n\n\n\nCode\nlibrary(ellmer)\nlibrary(dotenv)\nload_dot_env(file = \".env\")\n\nchat &lt;- chat_openrouter(\n  system_prompt = NULL,\n  api_key = Sys.getenv(\"OPENROUTER_API_KEY\"),\n \n  model = \"openai/gpt-oss-20b:free\",\n  echo = \"none\"\n)\n\n\n\n\nCode\nchat$chat(\"ç»™æˆ‘è®²ä¸‰ä¸ªå…³äºç»Ÿè®¡å­¦å®¶çš„ç¬‘è¯\")\n\n\n\n\n\næ ¸å¿ƒç»„ä»¶è¯´æ˜ï¼š\n\nbase_urlï¼šæŒ‡å‘ OpenRouter çš„ API è€Œé OpenAI çš„\nmodelï¼šä½¿ç”¨ OpenRouter çš„æ¨¡å‹å‘½åæ ¼å¼ (æä¾›å•†/æ¨¡å‹åç§°)\nextra_headersï¼šå¯é€‰ï¼Œä½†å»ºè®®ç”¨äº OpenRouter çš„åˆ†æ\ntemperatureï¼šæ§åˆ¶å“åº”çš„åˆ›é€ åŠ›ï¼ˆèŒƒå›´ 0.0-2.0ï¼‰\nmessagesï¼šæ ‡å‡†çš„èŠå¤©æ ¼å¼ï¼Œé‡‡ç”¨åŸºäºè§’è‰²çš„å¯¹è¯ç»“æ„\n\nğŸ’¡ æ¨¡å‹é€‰æ‹©å»ºè®®ï¼š - å…è´¹æ¨¡å‹ï¼šéå¸¸é€‚åˆå¼€å‘é˜¶æ®µï¼ˆä»¥ *free ç»“å°¾ï¼‰ - ç»æµå‹æ¨¡å‹ï¼šé€‚åˆç”Ÿäº§ç¯å¢ƒçš„æˆæœ¬æ•ˆç›Šæ¨¡å‹ï¼ˆä»¥ *:budget ç»“å°¾ï¼‰ - é«˜çº§æ¨¡å‹ï¼šæœ€ä½³æ€§èƒ½ï¼ˆ*ã€*:proã€*:latestï¼‰ - ä¸“ä¸šæ¨¡å‹ï¼šé’ˆå¯¹ç‰¹å®šä»»åŠ¡ä¼˜åŒ–çš„æ¨¡å‹ï¼ˆç¼–ç¨‹ã€æ•°å­¦ã€åˆ›æ„å†™ä½œï¼‰"
  },
  {
    "objectID": "posts/openrouter/index.html#æŒæ¡ç³»ç»Ÿæç¤ºè¯-system-prompts",
    "href": "posts/openrouter/index.html#æŒæ¡ç³»ç»Ÿæç¤ºè¯-system-prompts",
    "title": "OpenRouterï¼šå¤š AI æ¨¡å‹çš„ç»Ÿä¸€ API",
    "section": "",
    "text": "ç³»ç»Ÿæç¤ºè¯æ˜¯å¡‘é€  AI è¡Œä¸ºã€ä¸ªæ€§å’Œå›å¤é£æ ¼çš„å¼ºå¤§å·¥å…·ã€‚å®ƒä»¬è®¾ç½®äº†æ•´ä¸ªå¯¹è¯çš„ä¸Šä¸‹æ–‡å’Œè§„åˆ™ï¼Œåœ¨å¯¹è¯æµä¸­å‡ºç°åœ¨ç”¨æˆ·æ¶ˆæ¯ä¹‹å‰ã€‚\n\n\nç³»ç»Ÿæç¤ºè¯å……å½“å…ƒæŒ‡ä»¤ï¼ŒæŒ‡å¯¼ AI åœ¨æ•´ä¸ªå¯¹è¯ä¸­åº”å¦‚ä½•ååº”ã€‚å®ƒä»¬æœ€å…ˆè¢«å¤„ç†ï¼Œå¹¶å½±å“æ‰€æœ‰åç»­çš„äº¤äº’ã€‚\n\n\n\n\nä¸€è‡´çš„è¡Œä¸ºï¼šç¡®ä¿ AI åœ¨æ•´ä¸ªè¿‡ç¨‹ä¸­ä¿æŒæ‰€éœ€çš„ä¸ªæ€§\nè¾“å‡ºæ ¼å¼ï¼šè§„å®šå“åº”ç»“æ„ï¼ˆJSONã€Markdownã€ä»£ç å—ï¼‰\nå®‰å…¨çº¦æŸï¼šè®¾ç½®å›å¤çš„è¾¹ç•Œå’Œé™åˆ¶\nä¸Šä¸‹æ–‡è®¾ç½®ï¼šæä¾›èƒŒæ™¯ä¿¡æ¯ä»¥è·å¾—æ›´å¥½çš„å›å¤\nä»»åŠ¡ä¸“é—¨åŒ–ï¼šé’ˆå¯¹ç‰¹å®šç”¨ä¾‹ä¼˜åŒ– AI\n\n\n\n\n\n\nCode\n# å¸¦æœ‰ç³»ç»Ÿæç¤ºè¯çš„ç¤ºä¾‹\ncompletion = client.chat.completions.create(\n  model=\"openai/gpt-oss-20b:free\",\n  messages=[\n    {\n      \"role\": \"system\",\n      \"content\": \"ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„ AI åŠ©æ‰‹ï¼Œå¯ä»¥ç”¨ç®€å•çš„æœ¯è¯­è§£é‡ŠæŠ€æœ¯æ¦‚å¿µã€‚å§‹ç»ˆä¿æŒå‹å¥½ï¼Œå¹¶å°½å¯èƒ½ä½¿ç”¨ç±»æ¯”ï¼Œä¿æŒç®€å•ã€‚\"\n    },\n    {\n      \"role\": \"user\",\n      \"content\": \"LLM æ¨¡å‹ä¸­çš„æ¸©åº¦ (temperature) æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ\"\n    }\n  ],\n  temperature=0.7\n)\n\nprint(completion.choices[0].message.content)\n\n\nå¸¸è§çš„ç³»ç»Ÿæç¤ºè¯æ¨¡å¼ï¼š\n\n\nCode\n# ä¸åŒçš„ç³»ç»Ÿæç¤ºè¯ç¤ºä¾‹\nsystem_prompts = {\n    \"coding_assistant\": \"ä½ æ˜¯ä¸€ä¸ªä¸“å®¶çº§ç¨‹åºå‘˜ã€‚æä¾›æ•´æ´ã€æ³¨é‡Šè‰¯å¥½çš„ä»£ç è§£å†³æ–¹æ¡ˆï¼Œå¹¶è§£é‡Šä½ çš„æ¨ç†ã€‚\",\n    \"creative_writer\": \"ä½ æ˜¯ä¸€ä¸ªåˆ›æ„æ•…äº‹è®²è¿°è€…ã€‚ç¼–å†™å…·æœ‰ç”ŸåŠ¨æè¿°å’Œå¼•äººå…¥èƒœè§’è‰²çš„åŠ¨äººå™è¿°ã€‚\",\n    \"data_analyst\": \"ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æå¸ˆã€‚æ ¹æ®æ•°æ®æä¾›è§è§£ï¼Œå»ºè®®å¯è§†åŒ–æ–¹å¼ï¼Œå¹¶æ¸…æ™°åœ°è§£é‡Šç»Ÿè®¡æ¦‚å¿µã€‚\",\n    \"tutor\": \"ä½ æ˜¯ä¸€ä¸ªè€å¿ƒçš„å¯¼å¸ˆã€‚å°†å¤æ‚çš„ä¸»é¢˜åˆ†è§£ä¸ºç®€å•çš„æ­¥éª¤å¹¶æä¾›é¼“åŠ±æ€§çš„åé¦ˆã€‚\"\n}\n\ndef chat_with_persona(persona, user_message):\n    completion = client.chat.completions.create(\n        model=\"openai/gpt-oss-20b:free\",\n        messages=[\n            {\"role\": \"system\", \"content\": system_prompts[persona]},\n            {\"role\": \"user\", \"content\": user_message}\n        ],\n        temperature=0.7\n    )\n    return completion.choices[0].message.content\n\n# ç¤ºä¾‹ç”¨æ³•\n#response = chat_with_persona(\"coding_assistant\", \"å¦‚ä½•ç”¨ Python åè½¬å­—ç¬¦ä¸²ï¼Ÿ\")\n#print(response)"
  },
  {
    "objectID": "posts/openrouter/index.html#æµå¼å“åº”å®æ—¶-ai-äº¤äº’",
    "href": "posts/openrouter/index.html#æµå¼å“åº”å®æ—¶-ai-äº¤äº’",
    "title": "OpenRouterï¼šå¤š AI æ¨¡å‹çš„ç»Ÿä¸€ API",
    "section": "",
    "text": "æµå¼ä¼ è¾“ (Streaming) æ˜¯æå‡ç”¨æˆ·ä½“éªŒçš„åˆ©å™¨ï¼Œç‰¹åˆ«æ˜¯åœ¨èŠå¤©åº”ç”¨å’Œäº¤äº’å¼å·¥å…·ä¸­ã€‚æµå¼ä¼ è¾“ä¸æ˜¯ç­‰å¾…å®Œæ•´çš„å“åº”ï¼Œè€Œæ˜¯åœ¨ç”Ÿæˆå†…å®¹æ—¶ç«‹å³äº¤ä»˜ï¼Œä»è€Œåˆ›é€ è‡ªç„¶ä¸”å¼•äººå…¥èƒœçš„å¯¹è¯ã€‚\n\n\nğŸš€ ç”¨æˆ·ä½“éªŒä¼˜åŠ¿ï¼š - ç«‹å³åé¦ˆï¼šç”¨æˆ·èƒ½ç«‹å³çœ‹åˆ°å“åº”å¼€å§‹ç”Ÿæˆ - é™ä½æ„ŸçŸ¥å»¶è¿Ÿï¼šå†…å®¹åœ¨ç”Ÿæˆæ—¶å³åˆ»æ˜¾ç¤º - è‡ªç„¶çš„å¯¹è¯æµï¼šæ¨¡ä»¿äººç±»è¯´è¯çš„æ¨¡å¼ - è¿›åº¦æŒ‡ç¤ºï¼šç”¨æˆ·çŸ¥é“ AI æ­£åœ¨å·¥ä½œ - åŠæ—©ç»ˆæ­¢ï¼šå¦‚æœéœ€è¦ï¼Œç”¨æˆ·å¯ä»¥åœæ­¢è¿‡é•¿çš„å›å¤\nâš¡ æŠ€æœ¯ä¼˜åŠ¿ï¼š - æ›´ä½çš„å†…å­˜å ç”¨ï¼šæ— éœ€ç¼“å†²å®Œæ•´å“åº” - æ›´å¿«çš„é¦–å­—èŠ‚æ—¶é—´ï¼šå†…å®¹ç«‹å³å¼€å§‹æµåŠ¨ - æ›´å¥½çš„é”™è¯¯å¤„ç†ï¼šåœ¨è¿‡ç¨‹ä¸­æ›´æ—©å‘ç°é—®é¢˜ - èµ„æºæ•ˆç‡ï¼šå¢é‡å¤„ç†æ•°æ®\n\n\n\n\n\nCode\n# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ˆå¦‚æœå°šæœªå®Œæˆï¼‰\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\nload_dotenv()\nclient = OpenAI(\n  base_url=\"https://openrouter.ai/api/v1\",\n  api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n)\n\ndef stream_response(model, message):\n    stream = client.chat.completions.create(\n        model=model,\n        messages=[{\"role\": \"user\", \"content\": message}],\n        stream=True\n    )\n\n    for chunk in stream:\n        if chunk.choices[0].delta.content is not None:\n            print(chunk.choices[0].delta.content, end='', flush=True)\n\n# æµå¼ä¼ è¾“ç¤ºä¾‹\nprint(\"æ­£åœ¨æµå¼ä¼ è¾“å“åº”ï¼š\")\nstream_response(\"openai/gpt-oss-20b:free\", \"è¯·ç»™æˆ‘è®²ä¸€ä¸ªå…³äº AI çš„çŸ­ç¯‡æ•…äº‹\")\nprint()  # æµå¼ä¼ è¾“ç»“æŸåæ·»åŠ æ¢è¡Œ\n\n\n\n\n\n\n\nCode\nfrom openai import OpenAI\nimport base64\nimport datetime\n\n\n\n\nCode\n# | eval: false\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\n# ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡\nload_dotenv()\n\n# ä½¿ç”¨ OpenRouter åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯\nclient = OpenAI(\n    base_url=\"https://openrouter.ai/api/v1\",\n    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n)\n\n\n\n\nCode\n# å›¾åƒç”Ÿæˆè¯·æ±‚\nresponse = client.chat.completions.create(\n    extra_headers={\n        \"HTTP-Referer\": \"www.tonydotdev.com\",\n        \"X-Title\": \"TT_AI_blog\",\n    },\n    model=\"google/gemini-2.5-flash-image\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": \"ç”Ÿæˆä¸€å¼ å®é™ä¸”å†™å®çš„æ—¥å‡ºé›ªå±±é£æ™¯å›¾ã€‚\",\n        }\n    ],\n    modalities=[\"image\", \"text\"],\n    #image_size=\"1024x1024\",\n)\n\n\n\n\nCode\nimport base64\nimport datetime\n# æå–æ¶ˆæ¯\nmessage = response.choices[0].message\n\n# å¤„ç†å›¾åƒè¾“å‡ºï¼ˆbase64 å­—ç¬¦ä¸²ä½äº \"data:image/png;base64,...\" ä¸­ï¼‰\nif message.images:\n    data_url = message.images[0][\"image_url\"][\"url\"]\n\n    # å¦‚æœå­˜åœ¨å‰ç¼€åˆ™å°†å…¶å‰¥ç¦»\n    if data_url.startswith(\"data:image\"):\n        _, base64_data = data_url.split(\",\", 1)\n    else:\n        base64_data = data_url\n\n    # è§£ç å¹¶ä¿å­˜ä¸º PNG\n    image_bytes = base64.b64decode(base64_data)\n    current_time = datetime.datetime.now().strftime(\"%H%M\")\n    output_file = f\"text_image_gemini_25_openrouter_{current_time}.png\"\n    with open(output_file, \"wb\") as f:\n        f.write(image_bytes)\n\n    print(f\"âœ… å›¾åƒå·²ä¿å­˜ä¸º {output_file}\")\nelse:\n    print(\"âŒ å“åº”ä¸­æœªè¿”å›å›¾åƒ\")\n\n\n\n\nCode\nfrom IPython.display import Image, display\n\ndisplay(Image(filename=\"text_image_gemini_25_openrouter_1352.png\"))\n\n\n&lt;IPython.core.display.Image object&gt;\n\n\n\n\n\n\n\nCode\nimport base64\n\n# å°†æœ¬åœ°å›¾åƒè½¬æ¢ä¸º data URL\nwith open(\"text_image_gemini_25_openrouter_1352.png\", \"rb\") as image_file:\n    base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n    data_url = f\"data:image/png;base64,{base64_image}\"\n\ncompletion = client.chat.completions.create(\n  extra_headers={\n    \"HTTP-Referer\": \"&lt;æ‚¨çš„ç½‘ç«™URL&gt;\", # å¯é€‰ï¼šOpenRouter æ’åç”¨çš„ç½‘ç«™ URL\n    \"X-Title\": \"&lt;æ‚¨çš„ç½‘ç«™åç§°&gt;\", # å¯é€‰ï¼šOpenRouter æ’åç”¨çš„ç½‘ç«™åç§°\n  },\n  extra_body={},\n  model=\"nvidia/nemotron-nano-12b-v2-vl:free\",\n  messages=[\n              {\n                \"role\": \"user\",\n                \"content\": [\n                  {\n                    \"type\": \"text\",\n                    \"text\": \"è¿™å¼ å›¾ç‰‡é‡Œæœ‰ä»€ä¹ˆï¼Ÿ\"\n                  },\n                  {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\n                      \"url\": data_url\n                    }\n                  }\n                ]\n              }\n            ]\n)\nprint(completion.choices[0].message.content)\n\n\n\n\n\n\n\nCode\n# | eval: false\nimport base64\n\n# å°†ä¹‹å‰ç”Ÿæˆçš„å›¾åƒè½¬æ¢ä¸º base64\nwith open(\"text_image_gemini_25_openrouter_1352.png\", \"rb\") as image_file:\n    base64_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n\nresponse = client.chat.completions.create(\n    extra_headers={\n        \"HTTP-Referer\": \"www.tonydotdev.com\",\n        \"X-Title\": \"TT_AI_blog\",\n    },\n    model=\"google/gemini-2.5-flash-image\",\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"text\",\n                    \"text\": \"å°†è¿™å¼ å›¾ç‰‡è½¬æ¢ä¸ºæ—¥è½ç‰ˆæœ¬ï¼Œä½¿ç”¨æ›´æ¸©æš–çš„è‰²å½©å’Œé‡‘è‰²çš„å…‰çº¿ã€‚åœ¨å‰æ™¯ä¸­å¢åŠ ä¸€ä¸ªæ­£åœ¨æ»‘é›ªçš„äººã€‚\",\n                },\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"},\n                },\n            ],\n        }\n    ],\n    modalities=[\"image\", \"text\"],\n    # image_size=\"1024x1024\",\n)\n\n\n\n\nCode\nimport base64\nimport datetime\n# æå–æ¶ˆæ¯\nmessage = response.choices[0].message\n\n# å¤„ç†å›¾åƒè¾“å‡ºï¼ˆbase64 å­—ç¬¦ä¸²ä½äº \"data:image/png;base64,...\" ä¸­ï¼‰\nif message.images:\n    data_url = message.images[0][\"image_url\"][\"url\"]\n\n    # å¦‚æœå­˜åœ¨å‰ç¼€åˆ™å°†å…¶å‰¥ç¦»\n    if data_url.startswith(\"data:image\"):\n        _, base64_data = data_url.split(\",\", 1)\n    else:\n        base64_data = data_url\n\n    # è§£ç å¹¶ä¿å­˜ä¸º PNG\n    image_bytes = base64.b64decode(base64_data)\n    current_time = datetime.datetime.now().strftime(\"%H%M\")\n    output_file = f\"text_image_gemini_25_openrouter_{current_time}.png\"\n    with open(output_file, \"wb\") as f:\n        f.write(image_bytes)\n\n    print(f\"âœ… å›¾åƒå·²ä¿å­˜ä¸º {output_file}\")\nelse:\n    print(\"âŒ å“åº”ä¸­æœªè¿”å›å›¾åƒ\")\n\n\n\n\nCode\nfrom IPython.display import Image, display\n\ndisplay(Image(filename=\"text_image_gemini_25_openrouter_1405.png\"))\n\n\n\n\n\n\n\nCode\nfrom openai import OpenAI\n## 8. æ–‡æœ¬åµŒå…¥ (Embedding)\n\n\n\n\nCode\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\n\n# ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡\nload_dotenv()\n\n# ä½¿ç”¨ OpenRouter åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯\nclient = OpenAI(\n    base_url=\"https://openrouter.ai/api/v1\",\n    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n)\n\n\nembedding = client.embeddings.create(\n  extra_headers={\n    \"HTTP-Referer\": \"&lt;YOUR_SITE_URL&gt;\", # å¯é€‰ï¼šOpenRouter æ’åç”¨çš„ç½‘ç«™ URL\n    \"X-Title\": \"&lt;YOUR_SITE_NAME&gt;\", # å¯é€‰ï¼šOpenRouter æ’åç”¨çš„ç½‘ç«™åç§°\n  },\n  model=\"thenlper/gte-base\",\n  input=\"I can\",\n  encoding_format=\"float\"\n)\n\n#print(embedding.data[0].embedding) \n\n\n\n\nCode\nlen(embedding.data[0].embedding)\n\n\n\n\nCode\nprint(embedding.data[0].embedding[:5])  # æ‰“å°å‰ 5 ä¸ªç»´åº¦"
  },
  {
    "objectID": "posts/openrouter/index.html#æˆæœ¬ç®¡ç†ä¼˜åŒ–æ‚¨çš„-ai-æ”¯å‡º",
    "href": "posts/openrouter/index.html#æˆæœ¬ç®¡ç†ä¼˜åŒ–æ‚¨çš„-ai-æ”¯å‡º",
    "title": "OpenRouterï¼šå¤š AI æ¨¡å‹çš„ç»Ÿä¸€ API",
    "section": "",
    "text": "OpenRouter æœ€å¼ºå¤§çš„åŠŸèƒ½ä¹‹ä¸€æ˜¯å…¶é€æ˜çš„å®šä»·æ¨¡å‹å’Œæˆæœ¬ç®¡ç†èƒ½åŠ›ã€‚å¯¹äºç”Ÿäº§çº§ AI åº”ç”¨æ¥è¯´ï¼Œç†è§£å’Œç®¡ç†æˆæœ¬è‡³å…³é‡è¦ã€‚"
  },
  {
    "objectID": "posts/openrouter/index.html#ä¸ºä»€ä¹ˆæˆæœ¬ç®¡ç†å¾ˆé‡è¦",
    "href": "posts/openrouter/index.html#ä¸ºä»€ä¹ˆæˆæœ¬ç®¡ç†å¾ˆé‡è¦",
    "title": "OpenRouterï¼šå¤š AI æ¨¡å‹çš„ç»Ÿä¸€ API",
    "section": "",
    "text": "ğŸ’° è´¢åŠ¡è§„åˆ’ï¼š - å¯é¢„æµ‹çš„æ¯æœˆæ”¯å‡º - ä¸ºä¸åŒç”¨ä¾‹åˆ†é…é¢„ç®— - AI åŠŸèƒ½çš„ ROI åˆ†æ - æ¯ä¸ªç”¨æˆ·çš„æˆæœ¬è¿½è¸ª\nğŸ” æŠ€æœ¯ä¼˜åŒ–ï¼š - æ ¹æ®æˆæœ¬/æ€§èƒ½æ¯”é€‰æ‹©æ¨¡å‹ - æç¤ºè¯å·¥ç¨‹ä»¥å‡å°‘ Token ä½¿ç”¨ - é‡å¤è¯·æ±‚çš„ç¼“å­˜ç­–ç•¥ - æé«˜æ•ˆç‡çš„æ‰¹é‡å¤„ç†"
  },
  {
    "objectID": "posts/openrouter/index.html#å®æ—¶æˆæœ¬è¿½è¸ª",
    "href": "posts/openrouter/index.html#å®æ—¶æˆæœ¬è¿½è¸ª",
    "title": "OpenRouterï¼šå¤š AI æ¨¡å‹çš„ç»Ÿä¸€ API",
    "section": "",
    "text": "OpenRouter æä¾›äº†é€šè¿‡ç¼–ç¨‹æ–¹å¼è®¿é—®æ‰€æœ‰æ¨¡å‹å½“å‰å®šä»·çš„æ¥å£ï¼š\n\n\nCode\n# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ˆå¦‚æœå°šæœªå®Œæˆï¼‰\nfrom openai import OpenAI\nimport os\nfrom dotenv import load_dotenv\nimport pandas as pd\n\nload_dotenv()\n\n\nTrue\n\n\nCode\nclient = OpenAI(\n  base_url=\"https://openrouter.ai/api/v1\",\n  api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n)\n\ndef get_model_pricing():\n    models_list = client.models.list()\n    pricing_data = []\n\n    for model in models_list.data:\n        name = model.id\n        pricing = model.pricing\n\n        # è·å–æ¨¡å‹å…ƒæ•°æ®\n        context_length = getattr(model, 'context_length', None)\n        description = getattr(model, 'description', '')\n\n        # è·å–åˆ›å»ºæ—¥æœŸå¹¶è½¬æ¢ä¸ºå¯è¯»æ ¼å¼\n        created_timestamp = getattr(model, 'created', None)\n        if created_timestamp:\n            import datetime\n            created_date = datetime.datetime.fromtimestamp(created_timestamp).strftime('%Y-%m-%d')\n        else:\n            created_date = None\n\n        # ä»æ¨¡å‹åç§°ä¸­æå–å…¬å¸ï¼ˆ'/' å‰çš„ç¬¬ä¸€éƒ¨åˆ†ï¼‰\n        company = name.split('/')[0] if '/' in name else 'Unknown'\n\n        # å°†æ¯ä¸ª Token çš„ä»·æ ¼è½¬æ¢ä¸ºæ¯ 100 ä¸‡ä¸ª Token çš„æˆæœ¬\n        prompt_cost = float(pricing.get('prompt', 0)) * 1000000 if pricing and pricing.get('prompt') else 0\n        completion_cost = float(pricing.get('completion', 0)) * 1000000 if pricing and pricing.get('completion') else 0\n        request_cost = float(pricing.get('request', 0)) * 1000000 if pricing and pricing.get('request') else 0\n        image_cost = float(pricing.get('image', 0)) * 1000000 if pricing and pricing.get('image') else 0\n\n        pricing_data.append({\n            'æ¨¡å‹': name,\n            'å…¬å¸': company,\n            'æè¿°': description,\n            'ä¸Šä¸‹æ–‡é•¿åº¦': context_length,\n            'åˆ›å»ºæ—¥æœŸ': created_date,\n            'æç¤ºè¯æˆæœ¬_æ¯1M': prompt_cost,\n            'è¡¥å…¨æˆæœ¬_æ¯1M': completion_cost,\n            'è¯·æ±‚æˆæœ¬_æ¯1M': request_cost,\n            'å›¾åƒæˆæœ¬_æ¯1M': image_cost\n        })\n\n    # åˆ›å»º Pandas DataFrame\n    df = pd.DataFrame(pricing_data)\n\n    # æŒ‰å…¬å¸ã€æ¨¡å‹åç§°æ’åºï¼Œæ–¹ä¾¿æ•´ç†\n    df = df.sort_values(['å…¬å¸', 'æ¨¡å‹']).reset_index(drop=True)\n\n    return df\n\n# è·å–ä»·æ ¼ DataFrameï¼ˆå…¨é‡æ¨¡å‹ä»¥åŠä»…ä»˜è´¹æ¨¡å‹ï¼‰\nall_models_df = get_model_pricing()\n\n\n\n\n\n\nCode\nimport panel as pn\n\n\ndf = all_models_df[\n    [\n        \"æ¨¡å‹\",\n        \"ä¸Šä¸‹æ–‡é•¿åº¦\",\n        \"åˆ›å»ºæ—¥æœŸ\",\n        \"æç¤ºè¯æˆæœ¬_æ¯1M\",\n        \"è¡¥å…¨æˆæœ¬_æ¯1M\",\n    ]\n].sort_values(\"æç¤ºè¯æˆæœ¬_æ¯1M\", ascending=False)\n\n# åˆ›å»ºä¸€ä¸ªå¸¦åˆ†é¡µçš„è¡¨æ ¼\npn.extension(\"tabulator\")\ntable = pn.widgets.Tabulator(df, pagination=\"local\", page_size=10, show_index=False)\ntable\n\n\nTabulator(page_size=10, pagination='local', show_index=False, value=              ...)"
  },
  {
    "objectID": "posts/openrouter/index.html#æœ€ä½³å®è·µç”Ÿäº§å°±ç»ªçš„-ai-å¼€å‘",
    "href": "posts/openrouter/index.html#æœ€ä½³å®è·µç”Ÿäº§å°±ç»ªçš„-ai-å¼€å‘",
    "title": "OpenRouterï¼šå¤š AI æ¨¡å‹çš„ç»Ÿä¸€ API",
    "section": "",
    "text": "éµå¾ªè¿™äº›æœ€ä½³å®è·µå°†å¸®åŠ©æ‚¨ä½¿ç”¨ OpenRouter æ„å»ºç¨³å¥ã€å®‰å…¨ä¸”é«˜æ•ˆçš„ AI åº”ç”¨ç¨‹åºã€‚"
  },
  {
    "objectID": "posts/openrouter/index.html#å®‰å…¨æœ€ä½³å®è·µ",
    "href": "posts/openrouter/index.html#å®‰å…¨æœ€ä½³å®è·µ",
    "title": "OpenRouterï¼šå¤š AI æ¨¡å‹çš„ç»Ÿä¸€ API",
    "section": "",
    "text": "åˆ‡å‹¿ç¡¬ç¼–ç  API å¯†é’¥åœ¨æºä»£ç æˆ–é…ç½®æ–‡ä»¶ä¸­\nä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–ç§˜å¯†ç®¡ç†ç³»ç»Ÿï¼ˆå¦‚ AWS Secrets Managerã€Azure Key Vaultï¼‰\nå®šæœŸè½®æ¢ API å¯†é’¥å¹¶å®æ–½å¯†é’¥è½®æ¢ç­–ç•¥\nä½¿ç”¨ä¸åŒçš„å¯†é’¥ç”¨äºå¼€å‘ã€æµ‹è¯•å’Œç”Ÿäº§ç¯å¢ƒ\nå°† .env æ·»åŠ åˆ° .gitignore â€”â€” æ°¸è¿œä¸è¦å°†å‡­æ®æäº¤åˆ°ç‰ˆæœ¬æ§åˆ¶ä¸­\n\n\n\n\n\nåœ¨å‘é€åˆ° AI æ¨¡å‹ä¹‹å‰éªŒè¯ç”¨æˆ·è¾“å…¥\næ¸…ç†æç¤ºè¯ä»¥é˜²æ­¢æç¤ºè¯æ³¨å…¥æ”»å‡»\nå®æ–½é€Ÿç‡é™åˆ¶ä»¥é˜²æ­¢æ»¥ç”¨\nè®°å½•å¹¶ç›‘æ§å¼‚å¸¸æ´»åŠ¨æ¨¡å¼"
  },
  {
    "objectID": "posts/openrouter/index.html#æ€§èƒ½æœ€ä½³å®è·µ",
    "href": "posts/openrouter/index.html#æ€§èƒ½æœ€ä½³å®è·µ",
    "title": "OpenRouterï¼šå¤š AI æ¨¡å‹çš„ç»Ÿä¸€ API",
    "section": "",
    "text": "ä¸ºæ‚¨çš„ç”¨ä¾‹é€‰æ‹©åˆé€‚çš„æ¨¡å‹ â€”â€” å¹¶éæ‰€æœ‰ä»»åŠ¡éƒ½éœ€è¦æœ€æ˜‚è´µçš„æ¨¡å‹\né’ˆå¯¹æ‚¨çš„ç‰¹å®šç”¨ä¾‹è¿›è¡Œæ¨¡å‹åŸºå‡†æµ‹è¯•\nä½¿ç”¨å…è´¹æ¨¡å‹è¿›è¡Œå¼€å‘å’Œæµ‹è¯•\nè€ƒè™‘ä¸“ç”¨æ¨¡å‹å¤„ç†ç‰¹å®šä»»åŠ¡ï¼ˆç¼–ç¨‹ã€æ•°å­¦ã€åˆ›æ„å†™ä½œï¼‰\n\n\n\n\n\nå®æ–½ç¼“å­˜ä»¥å‡å°‘é‡å¤è¯·æ±‚çš„æˆæœ¬\nä½¿ç”¨æµå¼ä¼ è¾“ä»¥è·å¾—æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ\nåœ¨é€‚å½“æƒ…å†µä¸‹è¿›è¡Œæ‰¹é‡è¯·æ±‚ä»¥æé«˜æ•ˆç‡\nä¼˜åŒ–æç¤ºè¯ â€”â€” ç²¾å¿ƒè®¾è®¡çš„æç¤ºè¯å¯ä»¥å‡å°‘ Token ä½¿ç”¨å¹¶æ”¹å–„ç»“æœ"
  },
  {
    "objectID": "posts/openrouter/index.html#å¯é æ€§æœ€ä½³å®è·µ",
    "href": "posts/openrouter/index.html#å¯é æ€§æœ€ä½³å®è·µ",
    "title": "OpenRouterï¼šå¤š AI æ¨¡å‹çš„ç»Ÿä¸€ API",
    "section": "",
    "text": "å®æ–½å…¨é¢çš„é”™è¯¯å¤„ç† â€”â€” æ¨¡å‹å¯èƒ½ä¼šä¸å¯ç”¨æˆ–å—åˆ°é€Ÿç‡é™åˆ¶\nä½¿ç”¨å¤‡ç”¨æ¨¡å‹ â€”â€” ç¡®ä¿å³ä½¿ä¸€ä¸ªæ¨¡å‹å®•æœºï¼Œæ‚¨çš„åº”ç”¨ç¨‹åºä»èƒ½æ­£å¸¸è¿è¡Œ\nå®æ–½å¸¦æœ‰æŒ‡æ•°é€€é¿çš„é‡è¯•é€»è¾‘\nç›‘æ§å“åº”æ—¶é—´å¹¶è®¾ç½®é€‚å½“çš„è¶…æ—¶\n\n\n\n\n\nç›‘æ§ä½¿ç”¨æƒ…å†µ â€”â€” è¿½è¸ªæˆæœ¬å¹¶è®¾ç½®é™åˆ¶\nè¿½è¸ªæ€§èƒ½æŒ‡æ ‡ï¼ˆå»¶è¿Ÿã€æˆåŠŸç‡ã€é”™è¯¯ç‡ï¼‰\nä¸ºå¼‚å¸¸æ´»åŠ¨æ¨¡å¼è®¾ç½®å‘Šè­¦\nåˆ›å»ºå®æ—¶ç›‘æ§ä»ªè¡¨æ¿"
  },
  {
    "objectID": "posts/openrouter/index.html#æˆæœ¬ç®¡ç†æœ€ä½³å®è·µ",
    "href": "posts/openrouter/index.html#æˆæœ¬ç®¡ç†æœ€ä½³å®è·µ",
    "title": "OpenRouterï¼šå¤š AI æ¨¡å‹çš„ç»Ÿä¸€ API",
    "section": "",
    "text": "åœ¨ OpenRouter ä»ªè¡¨æ¿ä¸­è®¾ç½®æ”¯å‡ºé™åˆ¶å’Œå‘Šè­¦\nä¸ºéå…³é”®ä»»åŠ¡ä½¿ç”¨é«˜æ€§ä»·æ¯”æ¨¡å‹\nå®æ–½ Token è®¡æ•°ä»¥åœ¨è¯·æ±‚å‰ä¼°ç®—æˆæœ¬\nå®šæœŸæŸ¥çœ‹ä½¿ç”¨æŠ¥å‘Šä»¥è¯†åˆ«ä¼˜åŒ–æœºä¼š"
  },
  {
    "objectID": "posts/openrouter/index.html#ç»“è®ºæ„å»º-ai-åº”ç”¨çš„æœªæ¥",
    "href": "posts/openrouter/index.html#ç»“è®ºæ„å»º-ai-åº”ç”¨çš„æœªæ¥",
    "title": "OpenRouterï¼šå¤š AI æ¨¡å‹çš„ç»Ÿä¸€ API",
    "section": "",
    "text": "OpenRouter ä»£è¡¨äº†å¼€å‘äººå‘˜ä¸ AI æ¨¡å‹äº¤äº’æ–¹å¼çš„èŒƒå¼è½¬å˜ã€‚é€šè¿‡æä¾›è®¿é—®ä¸–ç•Œä¸Šæœ€å…ˆè¿› AI æ¨¡å‹çš„ç»Ÿä¸€ã€å¯é ä¸”æå…·æˆæœ¬æ•ˆç›Šçš„ç½‘å…³ï¼ŒOpenRouter è®©å¼€å‘äººå‘˜èƒ½å¤Ÿä¸“æ³¨äºåˆ›é€ ä»·å€¼ï¼Œè€Œä¸æ˜¯å¤„ç†å¤æ‚çš„åŸºç¡€è®¾æ–½ã€‚"
  },
  {
    "objectID": "posts/weather-trend/index.html",
    "href": "posts/weather-trend/index.html",
    "title": "ç»“åˆ AI é¢„æµ‹çš„ Streamlit å¤©æ°”é¢„æŠ¥åº”ç”¨",
    "section": "",
    "text": "åœ¨è¿™ä¸€è¯¦å°½çš„æ•™ç¨‹ä¸­ï¼Œæˆ‘å°†æŒ‡å¯¼æ‚¨åˆ›å»ºä¸€ä¸ªç²¾è‡´çš„å¤©æ°”é¢„æŠ¥åº”ç”¨ç¨‹åºï¼Œè¯¥åº”ç”¨å°†ç°ä»£ Web å¼€å‘ä¸äººå·¥æ™ºèƒ½ç›¸ç»“åˆã€‚æœ¬é¡¹ç›®æ¼”ç¤ºäº†å¦‚ä½•æ„å»ºä¸€ä¸ªå…·å¤‡äº¤äº’å¼åœ°å›¾ã€åŒè¯­æ”¯æŒã€å®æ—¶æ•°æ®å¯è§†åŒ–å’Œ AI é©±åŠ¨çš„å¤©æ°”åˆ†æåŠŸèƒ½çš„ç”Ÿäº§çº§å¤©æ°”åº”ç”¨ã€‚\nåœ¨çº¿æ¼”ç¤º: https://weather-trend.streamlit.app/\nGithub: https://github.com/JCwinning/weather_trend\n\n\n\nå¤©æ°”é¢„æŠ¥åº”ç”¨ä¸»ç•Œé¢\n\n\nè¿™æ¬¾å¤©æ°”é¢„æŠ¥åº”ç”¨ä¸ä»…ä»…æä¾›åŸºç¡€çš„å¤©æ°”æ•°æ®ï¼Œè¿˜é›†æˆäº†å¤šé¡¹é«˜çº§åŠŸèƒ½ï¼š\n\näº¤äº’å¼ä½ç½®é€‰æ‹©ï¼šç‚¹å‡»åœ°å›¾ä¸Šçš„ä»»æ„ä½ç½®æˆ–é€šè¿‡åŸå¸‚åç§°æœç´¢\nåŒè¯­ç•Œé¢ï¼šå®Œæ•´çš„è‹±æ–‡/ä¸­æ–‡è¯­è¨€æ”¯æŒåŠåˆ‡æ¢åŠŸèƒ½\nAI é©±åŠ¨çš„åˆ†æï¼šä½¿ç”¨ DeepSeek AI æä¾›å¤©æ°”åˆ†æå’Œå»ºè®®\né«˜çº§å¯è§†åŒ–ï¼šæ¸©åº¦è¶‹åŠ¿ã€ç©ºæ°”è´¨é‡ç›‘æµ‹å’Œé™é›¨æ¦‚ç‡\nå®æ—¶æ•°æ®ï¼š7 å¤©å†å²æ•°æ®å’Œ 5 å¤©é¢„æŠ¥æ•°æ®\nå“åº”å¼è®¾è®¡ï¼šåœ¨æ¡Œé¢ã€å¹³æ¿å’Œç§»åŠ¨è®¾å¤‡ä¸Šè¿è¡Œæ— é˜»\n\n\n\n\n\n\n\n\nflowchart TD\n    A[ç”¨æˆ·ç•Œé¢&lt;br/&gt;Streamlit Web åº”ç”¨] --&gt; B[ä½ç½®æœåŠ¡]\n    A --&gt; C[å¤©æ°”æ•°æ® API]\n    A --&gt; D[AI é›†æˆå±‚]\n    A --&gt; E[å¯è§†åŒ–å¼•æ“]\n\n    B --&gt; F[äº¤äº’å¼åœ°å›¾&lt;br/&gt;Folium + OpenStreetMap]\n    B --&gt; G[åŸå¸‚æœç´¢&lt;br/&gt;Nominatim åœ°ç†ç¼–ç ]\n\n    C --&gt; H[Open-Meteo API&lt;br/&gt;å¤©æ°” + ç©ºæ°”è´¨é‡]\n    C --&gt; I[æ•°æ®å¤„ç†&lt;br/&gt;Pandas DataFrame]\n\n    D --&gt; J[ModelScope API&lt;br/&gt;DeepSeek-V3.2 AI]\n    D --&gt; K[æ™ºèƒ½åˆ†æ&lt;br/&gt;å¤©æ°”å»ºè®®]\n\n    E --&gt; L[Altair å›¾è¡¨&lt;br/&gt;æ¸©åº¦è¶‹åŠ¿]\n    E --&gt; M[æ•°æ®è¡¨æ ¼&lt;br/&gt;å¤©æ°”è¯¦æƒ…]\n\n    F --&gt; A\n    G --&gt; A\n    I --&gt; E\n    K --&gt; A\n\n\n å¤©æ°”åº”ç”¨æ¶æ„ \n\n\n\n\n\n\nå‰ç«¯æ¡†æ¶ï¼šStreamlitï¼Œç”¨äºå¿«é€Ÿå¼€å‘ Web åº”ç”¨ç¨‹åº\nåœ°å›¾ï¼šFolium é…åˆ OpenStreetMap å›¾å±‚ï¼Œå®ç°äº¤äº’å¼ä½ç½®é€‰æ‹©\næ•°æ®å¯è§†åŒ–ï¼šAltairï¼Œç”¨äºä¸“ä¸šçš„å›¾è¡¨å’Œå›¾å½¢\nAPI é›†æˆï¼šOpen-Meteoï¼Œè·å–å¤©æ°”å’Œç©ºæ°”è´¨é‡æ•°æ®\nAI æœåŠ¡ï¼šé€šè¿‡ ModelScope API ä½¿ç”¨ DeepSeek-V3.2 è¿›è¡Œæ™ºèƒ½åˆ†æ\nåœ°ç†ç¼–ç ï¼šNominatimï¼Œç”¨äºåœ°å€ä¸åæ ‡çš„è½¬æ¢\nå›½é™…åŒ–ï¼šè‡ªå®šä¹‰è¯­è¨€ç³»ç»Ÿï¼Œæ”¯æŒä¸­è‹±æ–‡åˆ‡æ¢\n\n\n\n\n\n\n\nåœ¨æ·±å…¥ä»£ç ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆæ­å»ºå¥½å¼€å‘ç¯å¢ƒï¼š\n# 1. å…‹éš†ä»“åº“\ngit clone &lt;your-repo-url&gt;\ncd weather_trend\n\n# 2. å®‰è£…æ‰€éœ€è½¯ä»¶åŒ…\npip install streamlit pandas requests altair folium streamlit-folium geopy python-dotenv openai\n\n# 3. ä¸º AI åŠŸèƒ½è®¾ç½®ç¯å¢ƒå˜é‡\necho \"modelscope=æ‚¨çš„ API å¯†é’¥\" &gt; .env\n\n\n\n\nstreamlitï¼šå…·å¤‡å“åº”å¼ UI ç»„ä»¶çš„ Web åº”ç”¨æ¡†æ¶\npandasï¼šç”¨äºå¤©æ°”æ•°æ®é›†çš„æ•°æ®æ“ä½œå’Œåˆ†æ\nrequestsï¼šç”¨äº API é€šä¿¡çš„ HTTP å®¢æˆ·ç«¯\naltairï¼šå£°æ˜å¼ç»Ÿè®¡å¯è§†åŒ–åº“\nfolium + streamlit-foliumï¼šäº¤äº’å¼åœ°å›¾é›†æˆ\ngeopyï¼šç”¨äºä½ç½®æŸ¥æ‰¾çš„åœ°ç†ç¼–ç æœåŠ¡\npython-dotenvï¼šç¯å¢ƒå˜é‡ç®¡ç†\nopenaiï¼šAI æ¨¡å‹é›†æˆï¼ˆä¸ ModelScope å…¼å®¹ï¼‰\n\n\n\n\n\n\n\nåœ°å›¾åŠŸèƒ½å…è®¸ç”¨æˆ·ç‚¹å‡»ä»»æ„ä½ç½®å¹¶è·å–è¯¥åœ°ç‚¹çš„å®æ—¶å¤©æ°”æ•°æ®ï¼š\n\n\nCode\nimport folium\nfrom streamlit_folium import st_folium\n\n# åˆ›å»ºä»¥é»˜è®¤ä½ç½®ä¸ºä¸­å¿ƒçš„äº¤äº’å¼åœ°å›¾\ndef create_interactive_map(lat=40.7128, lon=-74.0060, zoom=10):\n    \"\"\"åˆ›å»ºäº¤äº’å¼ Folium åœ°å›¾\"\"\"\n    m = folium.Map(\n        location=[lat, lon],\n        zoom_start=zoom,\n        tiles=\"OpenStreetMap\"\n    )\n\n    # æ·»åŠ ç‚¹å‡»äº‹ä»¶å¤„ç†å™¨ä»¥æ•è·åæ ‡\n    m.add_child(folium.LatLngPopup())\n\n    return m\n\n# åœ¨ Streamlit ä¸­æ˜¾ç¤ºåœ°å›¾\nif 'map_data' not in st.session_state:\n    st.session_state.map_data = None\n\nmap_object = create_interactive_map()\nst_data = st_folium(map_object, width=700, height=500)\n\n# æ•è·ç‚¹å‡»å¤„çš„åæ ‡\nif st_data['last_clicked']:\n    lat = st_data['last_clicked']['lat']\n    lon = st_data['last_clicked']['lng']\n    st.session_state.clicked_location = (lat, lon)\n    get_weather_for_coordinates(lat, lon)\n\n\nå…³é”®ç‰¹æ€§ï¼š - ç‚¹å‡»é€‰æ‹©ï¼šç”¨æˆ·å¯ä»¥ç‚¹å‡»åœ°å›¾ä¸Šçš„ä»»ä½•åœ°æ–¹ - ç¼©æ”¾æ§åˆ¶ï¼šæ ‡å‡†çš„åœ°å›¾å¯¼èˆªåŠŸèƒ½ - å“åº”å¼è®¾è®¡ï¼šé€‚åº”ä¸åŒçš„å±å¹•å°ºå¯¸ - åæ ‡æ•è·ï¼šè‡ªåŠ¨æå–æ‰€é€‰ä½ç½®çš„ä¿¡æ¯\n\n\n\næ­¤åº”ç”¨æ”¯æŒä¸­è‹±æ–‡åŸå¸‚åç§°ï¼Œå¹¶å…·å¤‡æ™ºèƒ½çš„å›é€€æœºåˆ¶ï¼š\n\n\nCode\nimport re\nfrom geopy.geocoders import Nominatim\n\n# æ‰©å±•çš„ä¸­æ–‡å­—ç¬¦æ£€æµ‹\ndef contains_chinese(text):\n    \"\"\"æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦ï¼ŒåŒ…æ‹¬ CJK ç»Ÿä¸€æ±‰å­—\"\"\"\n    chinese_pattern = re.compile(\n        r\"[\\u4e00-\\u9fff\\u3400-\\u4dbf\\U00020000-\\U0002a6df\\U0002a700-\\U0002b73f]\"\n    )\n    return bool(chinese_pattern.search(text))\n\n# ä¸­æ–‡åŸå¸‚æ˜ å°„ï¼Œä»¥è·å¾—æ›´å¥½çš„è§£ææ•ˆæœ\nCHINESE_CITY_MAPPING = {\n    \"çº½çº¦\": \"New York\",\n    \"ä¸œäº¬\": \"Tokyo\",\n    \"ä¼¦æ•¦\": \"London\",\n    \"å·´é»\": \"Paris\",\n    \"æ´›æ‰çŸ¶\": \"Los Angeles\",\n    # ... æ›´å¤šæ˜ å°„\n}\n\ndef get_coordinates_for_city(city_name):\n    \"\"\"è·å–åŸå¸‚åæ ‡ï¼Œæ”¯æŒå¤šè¯­è¨€\"\"\"\n    # æ£€æŸ¥ä¸­æ–‡åŸå¸‚åç§°æ˜ å°„\n    if contains_chinese(city_name) and city_name in CHINESE_CITY_MAPPING:\n        city_name = CHINESE_CITY_MAPPING[city_name]\n\n    # å¯¹åŸå¸‚è¿›è¡Œåœ°ç†ç¼–ç \n    geolocator = Nominatim(user_agent=\"weather_app\")\n    try:\n        location = geolocator.geocode(city_name)\n        return (location.latitude, location.longitude) if location else None\n    except:\n        return None\n\n\nåŒè¯­ç‰¹æ€§ï¼š - ä¸­æ–‡å­—ç¬¦æ£€æµ‹ï¼šé’ˆå¯¹ CJK å­—ç¬¦çš„é«˜çº§æ­£åˆ™æ¨¡å¼ - åŸå¸‚åç§°æ˜ å°„ï¼šä¸»è¦åŸå¸‚çš„ç¿»è¯‘æ•°æ®åº“ - é”™è¯¯å¤„ç†ï¼šå½“åœ°ç†ç¼–ç å¤±è´¥æ—¶ä¿æŒç³»ç»Ÿç¨³å®š - Unicode æ”¯æŒï¼šå®Œæ•´æ”¯æŒå›½é™…åŒ–å­—ç¬¦\n\n\n\nè¯¥åº”ç”¨ç¨‹åºä» Open-Meteo API è·å–å…¨é¢çš„å¤©æ°”æ•°æ®ï¼š\n\n\nCode\nimport requests\nimport pandas as pd\n\ndef get_weather_data(latitude, longitude):\n    \"\"\"è·å– 12 å¤©çš„å¤©æ°”æ•°æ®ï¼ˆ7 å¤©å†å² + 5 å¤©é¢„æŠ¥ï¼‰\"\"\"\n\n    # API ç«¯ç‚¹é…ç½®\n    url = \"https://api.open-meteo.com/v1/forecast\"\n    params = {\n        'latitude': latitude,\n        'longitude': longitude,\n        'daily': [\n            'temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean',\n            'weathercode', 'windspeed_10m_max', 'precipitation_probability_max',\n            'pm10', 'pm2_5'\n        ],\n        'timezone': 'auto',\n        'past_days': 7,  # è·å–å†å²æ•°æ®\n        'forecast_days': 5  # è·å–æœªæ¥é¢„æŠ¥\n    }\n\n    try:\n        response = requests.get(url, params=params, timeout=10)\n        response.raise_for_status()\n\n        # å¤„ç†å“åº”æ•°æ®\n        data = response.json()\n        df = process_weather_data(data)\n\n        return df\n\n    except requests.RequestException as e:\n        st.error(f\"API è¯·æ±‚å¤±è´¥: {e}\")\n        return None\n\ndef process_weather_data(data):\n    \"\"\"å°† API å“åº”è½¬æ¢ä¸ºç»“æ„åŒ– DataFrame\"\"\"\n    daily_data = data['daily']\n\n    # åˆ›å»ºæ—¥æœŸèŒƒå›´ï¼ˆå†å² + æœªæ¥ï¼‰\n    dates = pd.date_range(\n        start=pd.to_datetime(daily_data['time'][0]),\n        periods=len(daily_data['time']),\n        freq='D'\n    )\n\n    # æ„å»º DataFrame\n    df = pd.DataFrame({\n        'date': dates,\n        'temperature_max': daily_data['temperature_2m_max'],\n        'temperature_min': daily_data['temperature_2m_min'],\n        'temperature_mean': daily_data['temperature_2m_mean'],\n        'weather_code': daily_data['weathercode'],\n        'wind_speed_max': daily_data['windspeed_10m_max'],\n        'rain_probability': daily_data['precipitation_probability_max'],\n        'pm2_5': daily_data.get('pm2_5', [0] * len(dates))\n    })\n\n    # æ·»åŠ è¡ç”Ÿåˆ—\n    df['is_today'] = df['date'].dt.date == pd.Timestamp.now().date()\n    df['is_future'] = df['date'] &gt; pd.Timestamp.now()\n\n    return df\n\n\næ•°æ®å¤„ç†ç‰¹æ€§ï¼š - å†å² + é¢„æŠ¥ï¼š7 å¤©è¿‡å» + 5 å¤©æœªæ¥ - ç©ºæ°”è´¨é‡é›†æˆï¼šPM2.5 å’Œ PM10 æ•°æ® - æŒ‡æ ‡è¡ç”Ÿï¼šä»Šæ—¥æ£€æµ‹å’Œæœªæ¥è¶‹åŠ¿åˆ†æ - é”™è¯¯ç®¡ç†ï¼šå¥å£®çš„ API é”™è¯¯å¤„ç†æœºåˆ¶\n\n\n\næ¸©åº¦è¶‹åŠ¿å›¾ï¼Œæ¸…æ™°åœ°åŒºåˆ†äº†å†å²æ•°æ®å’Œé¢„æŠ¥æ•°æ®ï¼š\n\n\nCode\nimport altair as alt\n\ndef create_temperature_chart(weather_df):\n    \"\"\"åˆ›å»ºäº¤äº’å¼æ¸©åº¦è¶‹åŠ¿å›¾\"\"\"\n\n    # åŒ…å«æ¸©åº¦çº¿çš„åŸºå‡†å›¾è¡¨\n    base_chart = alt.Chart(weather_df).mark_line(\n        point=True,\n        strokeWidth=3,\n        opacity=0.8\n    ).encode(\n        x=alt.X('date:T', title='æ—¥æœŸ'),\n        y=alt.Y('temperature_mean:Q', title='æ¸©åº¦ (Â°C)', scale=alt.Scale(domain=[weather_df['temperature_min'].min()-5, weather_df['temperature_max'].max()+5]))\n    ).properties(\n        width=800,\n        height=400,\n        title='æ¸©åº¦è¶‹åŠ¿å›¾'\n    )\n\n    # å†å²æ•°æ®ï¼ˆå®çº¿ï¼‰\n    historical_data = weather_df[weather_df['is_future'] == False]\n    historical_line = base_chart.transform_filter(\n        'datum.is_future == false'\n    ).encode(\n        color=alt.value('blue'),\n        strokeDash=alt.value([0])  # å®çº¿\n    )\n\n    # æœªæ¥é¢„æŠ¥ï¼ˆè™šçº¿ï¼‰\n    future_data = weather_df[weather_df['is_future'] == True]\n    future_line = base_chart.transform_filter(\n        'datum.is_future == true'\n    ).encode(\n        color=alt.value('red'),\n        strokeDash=alt.value([5, 5])  # è™šçº¿\n    )\n\n    # ä»Šæ—¥æŒ‡ç¤ºçº¿\n    today_line = alt.Chart(pd.DataFrame({'x': [pd.Timestamp.now()]})).mark_rule(\n        strokeDash=[2, 2],\n        stroke='green',\n        strokeWidth=2\n    ).encode(x='x:T')\n\n    return (historical_line + future_line + today_line).resolve_scale(color='independent')\n\n\nå¯è§†åŒ–ç‰¹æ€§ï¼š - çº¿æ¡æ ·å¼åŒºåˆ†ï¼šå®çº¿ï¼ˆå†å²ï¼‰å¯¹æ¯”è™šçº¿ï¼ˆé¢„æŠ¥ï¼‰ - ä»Šæ—¥æŒ‡ç¤ºå™¨ï¼šå¯¹å½“å‰æ—¥æœŸçš„è§†è§‰æ ‡è®° - é¢œè‰²ç¼–ç ï¼šè“è‰²ä»£è¡¨è¿‡å»ï¼Œçº¢è‰²ä»£è¡¨æœªæ¥ - äº¤äº’å¼æç¤ºï¼šæ‚¬åœæ—¶æ˜¾ç¤ºæ•°æ®ç‚¹ä¿¡æ¯\n\n\n\nç¬¦åˆ EPA æ ‡å‡†çš„ PM2.5 æ°´å¹³é¢œè‰²ç¼–ç ï¼š\n\n\nCode\ndef get_air_quality_level(pm25_value):\n    \"\"\"åŸºäºç¾å›½ EPA PM2.5 æ ‡å‡†è·å–ç©ºæ°”è´¨é‡ç­‰çº§\"\"\"\n\n    if pm25_value &lt;= 12:\n        return {\n            'level': 'ä¼˜',\n            'color': '#00e400',  # æ·±ç»¿\n            'text_color': 'white',\n            'icon': 'ğŸŸ¢'\n        }\n    elif pm25_value &lt;= 35.4:\n        return {\n            'level': 'è‰¯',\n            'color': '#ffff00',  # æµ…é»„\n            'text_color': 'black',\n            'icon': 'ğŸŸ¢'\n        }\n    elif pm25_value &lt;= 55.4:\n        return {\n            'level': 'è½»åº¦æ±¡æŸ“',\n            'color': '#ff7e00',  # æ©™é»„\n            'text_color': 'black',\n            'icon': 'ğŸŸ¡'\n        }\n    elif pm25_value &lt;= 150.4:\n        return {\n            'level': 'ä¸­åº¦æ±¡æŸ“',\n            'color': '#ff0000',  # çº¢è‰²\n            'text_color': 'white',\n            'icon': 'ğŸŸ '\n        }\n    elif pm25_value &lt;= 250.4:\n        return {\n            'level': 'é‡åº¦æ±¡æŸ“',\n            'color': '#8f3f97',  # ç´«è‰²\n            'text_color': 'white',\n            'icon': 'ğŸ”´'\n        }\n    else:\n        return {\n            'level': 'ä¸¥é‡æ±¡æŸ“',\n            'color': '#7e0023',  # æ·±è¤\n            'text_color': 'white',\n            'icon': 'âš«'\n        }\n\ndef display_air_quality_badge(pm25_value):\n    \"\"\"æ˜¾ç¤ºå¸¦è§†è§‰æŒ‡ç¤ºçš„ç©ºæ°”è´¨é‡å¾½ç« \"\"\"\n    aq_info = get_air_quality_level(pm25_value)\n\n    st.markdown(f\"\"\"\n    &lt;div style=\"background-color: {aq_info['color']}; color: {aq_info['text_color']};\n                padding: 10px; border-radius: 5px; text-align: center; margin: 5px 0;\"&gt;\n        &lt;strong&gt;{aq_info['icon']} PM2.5: {pm25_value} Î¼g/mÂ³&lt;/strong&gt;&lt;br&gt;\n        &lt;small&gt;{aq_info['level']}&lt;/small&gt;\n    &lt;/div&gt;\n    \"\"\", unsafe_allow_html=True)\n\n\nç©ºæ°”è´¨é‡åŠŸèƒ½ç‰¹æ€§ï¼š - EPA æ ‡å‡†ï¼šåŸºäºç¾å›½ç¯å¢ƒä¿æŠ¤ç½²çš„æ ‡å‡† - è§†è§‰æŒ‡ç¤ºå™¨ï¼šå¸¦å›¾æ ‡çš„é¢œè‰²ç¼–ç å¾½ç«  - å¯è®¿é—®æ€§ï¼šé«˜å¯¹æ¯”åº¦è‰²å€¼ç¡®ä¿å¯è¯»æ€§ - ç§‘æ™®æ€§ï¼šé€šè¿‡ç­‰çº§è¯´æ˜å¸®åŠ©ç”¨æˆ·ç†è§£\n\n\n\n\n\n\næœ¬é¡¹ç›®æœ€å…·åˆ›æ–°æ€§çš„åŠŸèƒ½æ˜¯ä½¿ç”¨ ModelScope å¹³å°ä¸Šçš„ DeepSeek-V3.2 æ¨¡å‹æä¾› AI å¤©æ°”åˆ†æï¼š\n\n\n\nAI å¤©æ°”åˆ†æå»ºè®®\n\n\n\n\nCode\nfrom openai import OpenAI\nimport os\n\n# åˆå§‹åŒ– ModelScope çš„ AI å®¢æˆ·ç«¯\ndef init_ai_client():\n    \"\"\"åˆå§‹åŒ–ç”¨äº ModelScope API çš„ OpenAI å®¢æˆ·ç«¯\"\"\"\n    return OpenAI(\n        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n        api_key=os.getenv(\"modelscope\"),\n    )\n\ndef generate_weather_insights(weather_df, location_name, language=\"en\"):\n    \"\"\"ç”Ÿæˆ AI é©±åŠ¨çš„å¤©æ°”åˆ†æå»ºè®®\"\"\"\n\n    # å‡†å¤‡ç”¨äº AI åˆ†æçš„å¤©æ°”æ•°æ®\n    today_index = weather_df[weather_df['is_today']].index[0] if any(weather_df['is_today']) else 0\n    historical_data = weather_df.iloc[:today_index+1]  # æˆªè‡³ä»Šæ—¥\n    future_data = weather_df.iloc[today_index:]  # ä»Šæ—¥èµ·\n\n    # ä¸º AI åˆ›å»ºå¤©æ°”æ‘˜è¦\n    weather_summary = f\"\"\"\n    åœ°ç‚¹: {location_name}\n\n    å†å²å¤©æ°” (è¿‡å» {len(historical_data)} å¤©):\n    - æ¸©åº¦èŒƒå›´: {historical_data['temperature_min'].min():.1f}Â°C åˆ° {historical_data['temperature_max'].max():.1f}Â°C\n    - å¹³å‡æ¸©åº¦: {historical_data['temperature_mean'].mean():.1f}Â°C\n    - ç©ºæ°”è´¨é‡èŒƒå›´: {historical_data['pm2_5'].min():.1f} åˆ° {historical_data['pm2_5'].max():.1f} PM2.5\n\n    å¤©æ°”é¢„æŠ¥ (æœªæ¥ {len(future_data)} å¤©):\n    - æ¸©åº¦èŒƒå›´: {future_data['temperature_min'].min():.1f}Â°C åˆ° {future_data['temperature_max'].max():.1f}Â°C\n    - å¹³å‡é™é›¨æ¦‚ç‡: {future_data['rain_probability'].mean():.0f}%\n    \"\"\"\n\n    # æ ¹æ®è¯­è¨€ç”Ÿæˆæç¤ºè¯\n    if language == \"zh\":\n        prompt = f\"\"\"\n        åŸºäºä»¥ä¸‹å¤©æ°”æ•°æ®ï¼Œè¯·æä¾›ç®€æ´å®ç”¨çš„å¤©æ°”å»ºè®®ï¼ˆ100-200å­—ï¼‰ï¼š\n\n        {weather_summary}\n\n        è¯·åŒ…æ‹¬ï¼š\n        1. å¤©æ°”æ¨¡å¼åˆ†æ\n        2. ç©¿è¡£å»ºè®®\n        3. æˆ·å¤–æ´»åŠ¨å»ºè®®\n        4. å¥åº·æ³¨æ„äº‹é¡¹ï¼ˆå¦‚ç©ºæ°”è´¨é‡ç›¸å…³ï¼‰\n\n        è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œè¯­æ°”å‹å¥½å®ç”¨ã€‚\n        \"\"\"\n    else:\n        prompt = f\"\"\"\n        Based on the following weather data, please provide concise and practical weather advice (100-200 words):\n\n        {weather_summary}\n\n        Please include:\n        1. Weather pattern analysis\n        2. Clothing recommendations\n        3. Outdoor activity suggestions\n        4. Health considerations (related to air quality if applicable)\n\n        Please respond in {language} with a friendly and practical tone.\n        \"\"\"\n\n    try:\n        client = init_ai_client()\n        response = client.chat.completions.create(\n            model=\"deepseek-ai/DeepSeek-V3\",\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            max_tokens=300,\n            temperature=0.7\n        )\n\n        return response.choices[0].message.content\n\n    except Exception as e:\n        return f\"AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚é”™è¯¯ä¿¡æ¯: {str(e)}\"\n\n# åœ¨ Streamlit åº”ç”¨ä¸­\nif st.button(get_text(\"ai_button\", language)):\n    with st.spinner(\"æ­£åœ¨è·å– AI å¤©æ°”å»ºè®®...\"):\n        if 'weather_df' in st.session_state and 'location_name' in st.session_state:\n            ai_insights = generate_weather_insights(\n                st.session_state.weather_df,\n                st.session_state.location_name,\n                language\n            )\n            st.markdown(\"### ğŸ¤– AI å¤©æ°”åˆ†æ\")\n            st.write(ai_insights)\n        else:\n            st.warning(\"è¯·å…ˆè·å–å¤©æ°”æ•°æ®ã€‚\")\n\n\nAI ç‰¹æ€§ï¼š - ä¸Šä¸‹æ–‡æ„ŸçŸ¥åˆ†æï¼šåŒæ—¶å¤„ç†å†å²å’Œé¢„æŠ¥æ•°æ® - å¤šè¯­è¨€æ”¯æŒï¼šAI æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„è¯­è¨€å›å¤ - å®ç”¨å»ºè®®ï¼šæä¾›ç©¿è¡£ã€æ´»åŠ¨å’Œå¥åº·æ–¹é¢çš„è§è§£ - å®¹é”™å¤„ç†ï¼šåœ¨ AI æœåŠ¡ä¸å¯ç”¨æ—¶ä¼˜é›…åœ°æç¤º\n\n\n\nAI ç³»ç»Ÿé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºè¯ç”Ÿæˆæœ‰ä»·å€¼çš„è§è§£ï¼š\næç¤ºè¯ç»“æ„ï¼š 1. æ•°æ®ä¸Šä¸‹æ–‡ï¼šå…¨é¢çš„å¤©æ°”ç»Ÿè®¡ä¿¡æ¯ 2. ä»»åŠ¡å®šä¹‰ï¼šæ˜ç¡®çš„åˆ†æè¦æ±‚ 3. è¾“å‡ºæ ¼å¼ï¼šç»“æ„åŒ–çš„å›å¤ç±»åˆ« 4. è¯­è¨€é€‚é…ï¼šä¸ UI è¯­è¨€ä¿æŒä¸€è‡´\nå»ºè®®ç±»åˆ«ï¼š - å¤©æ°”æ¨¡å¼åˆ†æï¼šè¶‹åŠ¿å’Œå¼‚å¸¸åˆ†æ - ç©¿è¡£å»ºè®®ï¼šå®ç”¨çš„ç©¿ç€æŒ‡å¯¼ - æ´»åŠ¨å»ºè®®ï¼šæˆ·å¤–è®¡åˆ’çš„æ¨è - å¥åº·æ³¨æ„äº‹é¡¹ï¼šç©ºæ°”è´¨é‡åŠå¤©æ°”å½±å“\n\n\n\n\n\n\nåº”ç”¨å®ç°äº†ä¸€ä¸ªå…¨é¢çš„åŒè¯­ç³»ç»Ÿï¼š\n\n\nCode\n# language.py - ç¿»è¯‘ç®¡ç†\nTRANSLATIONS = {\n    \"en\": {\n        \"app_title\": \"Weather Forecast App\",\n        \"sidebar_header\": \"Weather Query\",\n        \"city_input_placeholder\": \"Enter a city name\",\n        \"get_weather_button\": \"Get Weather\",\n        \"weather_trends_title\": \"Weather Trends for\",\n        \"ai_button\": \"AI Weather Advice\",\n        # ... æ›´å¤šç¿»è¯‘\n    },\n    \"zh\": {\n        \"app_title\": \"å¤©æ°”é¢„æŠ¥åº”ç”¨\",\n        \"sidebar_header\": \"å¤©æ°”æŸ¥è¯¢\",\n        \"city_input_placeholder\": \"è¾“å…¥åŸå¸‚åç§°\",\n        \"get_weather_button\": \"è·å–å¤©æ°”\",\n        \"weather_trends_title\": \"å¤©æ°”è¶‹åŠ¿\",\n        \"ai_button\": \"AIå¤©æ°”å»ºè®®\",\n        # ... æ›´å¤šç¿»è¯‘\n    }\n}\n\ndef get_text(key, language=\"en\"):\n    \"\"\"è·å–æŒ‡å®šé”®å’Œè¯­è¨€çš„ç¿»è¯‘æ–‡æœ¬\"\"\"\n    return TRANSLATIONS.get(language, {}).get(key, key)\n\ndef get_available_languages():\n    \"\"\"è·å–å¯ç”¨çš„è¯­è¨€é€‰é¡¹\"\"\"\n    return {\"en\": \"English\", \"zh\": \"ä¸­æ–‡\"}\n\n# åœ¨ä¸»ç¨‹åº (app.py) ä¸­\ndef main():\n    # è¯­è¨€çŠ¶æ€ç®¡ç†\n    if 'language' not in st.session_state:\n        st.session_state.language = \"en\"\n\n    # è¯­è¨€åˆ‡æ¢æŒ‰é’®\n    current_lang = st.session_state.language\n    available_langs = get_available_languages()\n\n    col1, col2, col3 = st.columns([1,1,6])\n    with col1:\n        if st.button(\"EN\", disabled=current_lang==\"en\"):\n            st.session_state.language = \"en\"\n            st.rerun()\n\n    with col2:\n        if st.button(\"ä¸­æ–‡\", disabled=current_lang==\"zh\"):\n            st.session_state.language = \"zh\"\n            st.rerun()\n\n    # åœ¨æ‰€æœ‰ UI å…ƒç´ ä¸­ä½¿ç”¨å½“å‰è¯­è¨€\n    language = st.session_state.language\n    st.title(get_text(\"app_title\", language))\n    st.sidebar.header(get_text(\"sidebar_header\", language))\n\n\nå›½é™…åŒ–ç‰¹æ€§ï¼š - å®Œæ•´çš„ UI ç¿»è¯‘ï¼šæœ¬åœ°åŒ–æ‰€æœ‰ç•Œé¢å…ƒç´  - åŠ¨æ€è¯­è¨€åˆ‡æ¢ï¼šè¯­è¨€æ›´æ”¹æ—¶å³æ—¶æ›´æ–° UI - ä¸­æ–‡å­—ç¬¦æ”¯æŒï¼šå®Œæ•´çš„ Unicode å’Œ CJK æ”¯æŒ - è¯­å¢ƒä¸€è‡´ï¼šAI å›å¤ä¸ UI è¯­è¨€ç›¸åŒ¹é…\n\n\n\n\n\n\nå¤©æ°”è¡¨ç»“åˆäº†æ•°æ®ä¸è§†è§‰å…ƒç´ ï¼Œæ–¹ä¾¿ç”¨æˆ·å¿«é€Ÿç†è§£ï¼š\n\n\nCode\ndef create_weather_table(weather_df, language=\"en\"):\n    \"\"\"åˆ›å»ºå¢å¼ºçš„å¤©æ°”è¡¨ï¼ŒåŒ…å«å›¾æ ‡å’Œé¢œè‰²æ˜¾ç¤º\"\"\"\n\n    # å¤©æ°”ä»£ç åˆ° Emoji çš„æ˜ å°„\n    WEATHER_ICONS = {\n        0: \"â˜€ï¸\",   # æ™´\n        1: \"â›…\",   # æ™´é—´å¤šäº‘\n        2: \"â˜ï¸\",   # å¤šäº‘\n        3: \"â˜ï¸\",   # é˜´\n        45: \"ğŸŒ«ï¸\",  # é›¾\n        48: \"ğŸŒ¦ï¸\",  # é˜µé›¨\n        51: \"ğŸŒ§ï¸\",  # é›¨\n        53: \"â„ï¸\",  # é›ª\n        95: \"â›ˆï¸\",  # é›·é˜µé›¨\n    }\n\n    def format_weather_row(row):\n        \"\"\"æ ¼å¼åŒ–å•è¡Œå¤©æ°”æƒ…å†µå¹¶æ·»åŠ æ ·å¼\"\"\"\n        date_str = row['date'].strftime('%Y-%m-%d')\n        temp_range = f\"{row['temperature_min']:.1f}Â° ~ {row['temperature_max']:.1f}Â°\"\n        weather_icon = WEATHER_ICONS.get(row['weather_code'], \"ğŸŒ¡ï¸\")\n\n        # ç©ºæ°”è´¨é‡å¾½ç« \n        aq_info = get_air_quality_level(row['pm2_5'])\n        aq_badge = f'&lt;span style=\"background-color: {aq_info[\"color\"]}; color: {aq_info[\"text_color\"]}; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;\"&gt;{aq_info[\"icon\"]} {row[\"pm2_5\"]:.0f}&lt;/span&gt;'\n\n        # é™é›¨æ¦‚ç‡æŒ‡ç¤º\n        rain_color = 'red' if row['rain_probability'] &gt;= 80 else 'orange' if row['rain_probability'] &gt;= 50 else 'gray'\n        rain_indicator = f'&lt;span style=\"color: {rain_color};\"&gt;ğŸ”´ {row[\"rain_probability\"]:.0f}%&lt;/span&gt;' if row['rain_probability'] &gt;= 50 else f'&lt;span style=\"color: {rain_color};\"&gt;ğŸŸ¢ {row[\"rain_probability\"]:.0f}%&lt;/span&gt;'\n\n        # â€œä»Šæ—¥â€è¡Œé«˜äº®æ˜¾ç¤º\n        row_style = 'font-size: 1.2em; font-weight: bold;' if row['is_today'] else ''\n\n        return {\n            'æ—¥æœŸ': f'&lt;span style=\"{row_style}\"&gt;{date_str}&lt;/span&gt;',\n            'å¤©æ°”': f'&lt;span style=\"{row_style}\"&gt;{weather_icon}&lt;/span&gt;',\n            'æ¸©åº¦': f'&lt;span style=\"{row_style}\"&gt;{temp_range}&lt;/span&gt;',\n            'é£é€Ÿ': f'&lt;span style=\"{row_style}\"&gt;ğŸ’¨ {row[\"wind_speed_max\"]:.1f} km/h&lt;/span&gt;',\n            'é™é›¨': rain_indicator,\n            'ç©ºæ°”è´¨é‡': aq_badge\n        }\n\n    # å¯¹æ‰€æœ‰è¡Œåº”ç”¨æ ¼å¼åŒ–\n    formatted_rows = [format_weather_row(row) for _, row in weather_df.iterrows()]\n\n    return pd.DataFrame(formatted_rows)\n\n# åœ¨ Streamlit ä¸­æ˜¾ç¤º\nst.markdown(\"### ğŸ“Š å¤©æ°”è¯¦æƒ…\")\nst.dataframe(\n    create_weather_table(weather_df, language),\n    width=1200,\n    hide_index=True,\n    unsafe_allow_html=True\n)\n\n\nè¡¨æ ¼ç‰¹æ€§ï¼š - å¤©æ°”å›¾æ ‡ï¼šEmoji è¡¨è¾¾æ–¹å¼ï¼Œç›´è§‚æ˜“æ‡‚ - ä»Šæ—¥é«˜äº®ï¼šå¯¹å½“å¤©æ—¥æœŸä½¿ç”¨æ›´å¤§ã€åŠ ç²—çš„æ–‡å­— - ç©ºæ°”è´¨é‡å¾½ç« ï¼šé¢œè‰²ç¼–ç çš„ PM2.5 æŒ‡æ ‡ - é™é›¨æ¦‚ç‡ï¼šåŸºäº Material Design è‰²ç³»çš„è§†è§‰æŒ‡ç¤º - å“åº”å¼å¸ƒå±€ï¼šé€‚åº”å„ç§å±å¹•å®½åº¦\n\n\n\n\n\n\nåœ¨ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æ—¶ï¼Œè¯·é…ç½®ç¯å¢ƒå˜é‡ï¼š\n# .env æ–‡ä»¶\nmodelscope=æ‚¨çš„ API å¯†é’¥\n\n# å…¶ä»–ç”Ÿäº§ç¯å¢ƒè®¾ç½®\n# è€ƒè™‘é¢‘ç‡é™åˆ¶ã€ç¼“å­˜æœºåˆ¶å’Œç›‘æ§\n\n\n\n# 1. å®‰è£… Streamlit CLI\npip install streamlit\n\n# 2. ç™»å½• Streamlit\nstreamlit login\n\n# 3. éƒ¨ç½²åˆ° Streamlit Cloud\nstreamlit run app.py  # é¦–å…ˆåœ¨æœ¬åœ°æµ‹è¯•\n# ç„¶åé€šè¿‡ cloud.streamlit.io æˆ– CLI è¿›è¡Œéƒ¨ç½²\n\n\n\nFROM python:3.9-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCOPY . .\n\nEXPOSE 8501\n\nCMD [\"streamlit\", \"run\", \"app.py\", \"--server.address\", \"0.0.0.0\"]\n\n\n\n\n\n\n@st.cache_data(ttl=3600)  # ç¼“å­˜ 1 å°æ—¶\ndef get_weather_data_cached(lat, lon):\n    \"\"\"ç¼“å­˜å¤©æ°”æ•°æ®è·å–æ“ä½œ\"\"\"\n    return get_weather_data(lat, lon)\n\n@st.cache_resource\ndef get_ai_client():\n    \"\"\"ç¼“å­˜ AI å®¢æˆ·ç«¯åˆå§‹åŒ–\"\"\"\n    return init_ai_client()\n\n# ç¼“å­˜åœ°å›¾ç”Ÿæˆ\n@st.cache_data(ttl=3600)\ndef create_map_cached(lat, lon):\n    \"\"\"ç¼“å­˜åœ°å›¾åˆ›å»ºæ“ä½œ\"\"\"\n    return create_interactive_map(lat, lon)\n\n\n\n\n\nCode\ndef robust_api_call(func, *args, max_retries=3, **kwargs):\n    \"\"\"å¸¦é‡è¯•é€»è¾‘çš„é«˜å¯ç”¨ API è°ƒç”¨\"\"\"\n    for attempt in range(max_retries):\n        try:\n            return func(*args, **kwargs)\n        except requests.exceptions.Timeout:\n            if attempt == max_retries - 1:\n                st.error(\"å¤©æ°”æœåŠ¡æš‚æ—¶ä¸å¯ç”¨\")\n                return None\n            time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿é‡è¯•\n        except requests.exceptions.RequestException as e:\n            st.error(f\"API é”™è¯¯: {e}\")\n            return None\n\n\n\næ•°æ®å¯è§†åŒ–ï¼šä¸“ä¸šå›¾è¡¨ä¸äº¤äº’å¼åœ°å›¾ã€‚\nAI é›†æˆï¼šå°†è¯­è¨€æ¨¡å‹å®é™…åº”ç”¨äºæ•°æ®åˆ†æã€‚\nå›½é™…åŒ–ï¼šå®Œæ•´çš„åŒè¯­æ”¯æŒã€‚\nç”Ÿäº§å°±ç»ªï¼šåŒ…å«é”™è¯¯å¤„ç†ã€ç¼“å­˜å’Œæ€§èƒ½ä¼˜åŒ–ã€‚\n\næ— è®ºæ‚¨æ˜¯åœ¨æ„å»ºå¤©æ°”åº”ç”¨ã€æ•°æ®çœ‹æ¿è¿˜æ˜¯ AI é©±åŠ¨çš„å·¥å…·ï¼Œè¯¥é¡¹ç›®éƒ½ä¸ºåˆ›å»ºå¤æ‚ä¸”ç”¨æˆ·å‹å¥½çš„åº”ç”¨ç¨‹åºæä¾›äº†åšå®çš„åŸºç¡€ã€‚"
  },
  {
    "objectID": "posts/weather-trend/index.html#æŠ€æœ¯æ¶æ„",
    "href": "posts/weather-trend/index.html#æŠ€æœ¯æ¶æ„",
    "title": "ç»“åˆ AI é¢„æµ‹çš„ Streamlit å¤©æ°”é¢„æŠ¥åº”ç”¨",
    "section": "",
    "text": "flowchart TD\n    A[ç”¨æˆ·ç•Œé¢&lt;br/&gt;Streamlit Web åº”ç”¨] --&gt; B[ä½ç½®æœåŠ¡]\n    A --&gt; C[å¤©æ°”æ•°æ® API]\n    A --&gt; D[AI é›†æˆå±‚]\n    A --&gt; E[å¯è§†åŒ–å¼•æ“]\n\n    B --&gt; F[äº¤äº’å¼åœ°å›¾&lt;br/&gt;Folium + OpenStreetMap]\n    B --&gt; G[åŸå¸‚æœç´¢&lt;br/&gt;Nominatim åœ°ç†ç¼–ç ]\n\n    C --&gt; H[Open-Meteo API&lt;br/&gt;å¤©æ°” + ç©ºæ°”è´¨é‡]\n    C --&gt; I[æ•°æ®å¤„ç†&lt;br/&gt;Pandas DataFrame]\n\n    D --&gt; J[ModelScope API&lt;br/&gt;DeepSeek-V3.2 AI]\n    D --&gt; K[æ™ºèƒ½åˆ†æ&lt;br/&gt;å¤©æ°”å»ºè®®]\n\n    E --&gt; L[Altair å›¾è¡¨&lt;br/&gt;æ¸©åº¦è¶‹åŠ¿]\n    E --&gt; M[æ•°æ®è¡¨æ ¼&lt;br/&gt;å¤©æ°”è¯¦æƒ…]\n\n    F --&gt; A\n    G --&gt; A\n    I --&gt; E\n    K --&gt; A\n\n\n å¤©æ°”åº”ç”¨æ¶æ„ \n\n\n\n\n\n\nå‰ç«¯æ¡†æ¶ï¼šStreamlitï¼Œç”¨äºå¿«é€Ÿå¼€å‘ Web åº”ç”¨ç¨‹åº\nåœ°å›¾ï¼šFolium é…åˆ OpenStreetMap å›¾å±‚ï¼Œå®ç°äº¤äº’å¼ä½ç½®é€‰æ‹©\næ•°æ®å¯è§†åŒ–ï¼šAltairï¼Œç”¨äºä¸“ä¸šçš„å›¾è¡¨å’Œå›¾å½¢\nAPI é›†æˆï¼šOpen-Meteoï¼Œè·å–å¤©æ°”å’Œç©ºæ°”è´¨é‡æ•°æ®\nAI æœåŠ¡ï¼šé€šè¿‡ ModelScope API ä½¿ç”¨ DeepSeek-V3.2 è¿›è¡Œæ™ºèƒ½åˆ†æ\nåœ°ç†ç¼–ç ï¼šNominatimï¼Œç”¨äºåœ°å€ä¸åæ ‡çš„è½¬æ¢\nå›½é™…åŒ–ï¼šè‡ªå®šä¹‰è¯­è¨€ç³»ç»Ÿï¼Œæ”¯æŒä¸­è‹±æ–‡åˆ‡æ¢"
  },
  {
    "objectID": "posts/weather-trend/index.html#å¿«é€Ÿä¸Šæ‰‹",
    "href": "posts/weather-trend/index.html#å¿«é€Ÿä¸Šæ‰‹",
    "title": "ç»“åˆ AI é¢„æµ‹çš„ Streamlit å¤©æ°”é¢„æŠ¥åº”ç”¨",
    "section": "",
    "text": "åœ¨æ·±å…¥ä»£ç ä¹‹å‰ï¼Œè®©æˆ‘ä»¬å…ˆæ­å»ºå¥½å¼€å‘ç¯å¢ƒï¼š\n# 1. å…‹éš†ä»“åº“\ngit clone &lt;your-repo-url&gt;\ncd weather_trend\n\n# 2. å®‰è£…æ‰€éœ€è½¯ä»¶åŒ…\npip install streamlit pandas requests altair folium streamlit-folium geopy python-dotenv openai\n\n# 3. ä¸º AI åŠŸèƒ½è®¾ç½®ç¯å¢ƒå˜é‡\necho \"modelscope=æ‚¨çš„ API å¯†é’¥\" &gt; .env\n\n\n\n\nstreamlitï¼šå…·å¤‡å“åº”å¼ UI ç»„ä»¶çš„ Web åº”ç”¨æ¡†æ¶\npandasï¼šç”¨äºå¤©æ°”æ•°æ®é›†çš„æ•°æ®æ“ä½œå’Œåˆ†æ\nrequestsï¼šç”¨äº API é€šä¿¡çš„ HTTP å®¢æˆ·ç«¯\naltairï¼šå£°æ˜å¼ç»Ÿè®¡å¯è§†åŒ–åº“\nfolium + streamlit-foliumï¼šäº¤äº’å¼åœ°å›¾é›†æˆ\ngeopyï¼šç”¨äºä½ç½®æŸ¥æ‰¾çš„åœ°ç†ç¼–ç æœåŠ¡\npython-dotenvï¼šç¯å¢ƒå˜é‡ç®¡ç†\nopenaiï¼šAI æ¨¡å‹é›†æˆï¼ˆä¸ ModelScope å…¼å®¹ï¼‰"
  },
  {
    "objectID": "posts/weather-trend/index.html#æ ¸å¿ƒåŠŸèƒ½å®ç°",
    "href": "posts/weather-trend/index.html#æ ¸å¿ƒåŠŸèƒ½å®ç°",
    "title": "ç»“åˆ AI é¢„æµ‹çš„ Streamlit å¤©æ°”é¢„æŠ¥åº”ç”¨",
    "section": "",
    "text": "åœ°å›¾åŠŸèƒ½å…è®¸ç”¨æˆ·ç‚¹å‡»ä»»æ„ä½ç½®å¹¶è·å–è¯¥åœ°ç‚¹çš„å®æ—¶å¤©æ°”æ•°æ®ï¼š\n\n\nCode\nimport folium\nfrom streamlit_folium import st_folium\n\n# åˆ›å»ºä»¥é»˜è®¤ä½ç½®ä¸ºä¸­å¿ƒçš„äº¤äº’å¼åœ°å›¾\ndef create_interactive_map(lat=40.7128, lon=-74.0060, zoom=10):\n    \"\"\"åˆ›å»ºäº¤äº’å¼ Folium åœ°å›¾\"\"\"\n    m = folium.Map(\n        location=[lat, lon],\n        zoom_start=zoom,\n        tiles=\"OpenStreetMap\"\n    )\n\n    # æ·»åŠ ç‚¹å‡»äº‹ä»¶å¤„ç†å™¨ä»¥æ•è·åæ ‡\n    m.add_child(folium.LatLngPopup())\n\n    return m\n\n# åœ¨ Streamlit ä¸­æ˜¾ç¤ºåœ°å›¾\nif 'map_data' not in st.session_state:\n    st.session_state.map_data = None\n\nmap_object = create_interactive_map()\nst_data = st_folium(map_object, width=700, height=500)\n\n# æ•è·ç‚¹å‡»å¤„çš„åæ ‡\nif st_data['last_clicked']:\n    lat = st_data['last_clicked']['lat']\n    lon = st_data['last_clicked']['lng']\n    st.session_state.clicked_location = (lat, lon)\n    get_weather_for_coordinates(lat, lon)\n\n\nå…³é”®ç‰¹æ€§ï¼š - ç‚¹å‡»é€‰æ‹©ï¼šç”¨æˆ·å¯ä»¥ç‚¹å‡»åœ°å›¾ä¸Šçš„ä»»ä½•åœ°æ–¹ - ç¼©æ”¾æ§åˆ¶ï¼šæ ‡å‡†çš„åœ°å›¾å¯¼èˆªåŠŸèƒ½ - å“åº”å¼è®¾è®¡ï¼šé€‚åº”ä¸åŒçš„å±å¹•å°ºå¯¸ - åæ ‡æ•è·ï¼šè‡ªåŠ¨æå–æ‰€é€‰ä½ç½®çš„ä¿¡æ¯\n\n\n\næ­¤åº”ç”¨æ”¯æŒä¸­è‹±æ–‡åŸå¸‚åç§°ï¼Œå¹¶å…·å¤‡æ™ºèƒ½çš„å›é€€æœºåˆ¶ï¼š\n\n\nCode\nimport re\nfrom geopy.geocoders import Nominatim\n\n# æ‰©å±•çš„ä¸­æ–‡å­—ç¬¦æ£€æµ‹\ndef contains_chinese(text):\n    \"\"\"æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦ï¼ŒåŒ…æ‹¬ CJK ç»Ÿä¸€æ±‰å­—\"\"\"\n    chinese_pattern = re.compile(\n        r\"[\\u4e00-\\u9fff\\u3400-\\u4dbf\\U00020000-\\U0002a6df\\U0002a700-\\U0002b73f]\"\n    )\n    return bool(chinese_pattern.search(text))\n\n# ä¸­æ–‡åŸå¸‚æ˜ å°„ï¼Œä»¥è·å¾—æ›´å¥½çš„è§£ææ•ˆæœ\nCHINESE_CITY_MAPPING = {\n    \"çº½çº¦\": \"New York\",\n    \"ä¸œäº¬\": \"Tokyo\",\n    \"ä¼¦æ•¦\": \"London\",\n    \"å·´é»\": \"Paris\",\n    \"æ´›æ‰çŸ¶\": \"Los Angeles\",\n    # ... æ›´å¤šæ˜ å°„\n}\n\ndef get_coordinates_for_city(city_name):\n    \"\"\"è·å–åŸå¸‚åæ ‡ï¼Œæ”¯æŒå¤šè¯­è¨€\"\"\"\n    # æ£€æŸ¥ä¸­æ–‡åŸå¸‚åç§°æ˜ å°„\n    if contains_chinese(city_name) and city_name in CHINESE_CITY_MAPPING:\n        city_name = CHINESE_CITY_MAPPING[city_name]\n\n    # å¯¹åŸå¸‚è¿›è¡Œåœ°ç†ç¼–ç \n    geolocator = Nominatim(user_agent=\"weather_app\")\n    try:\n        location = geolocator.geocode(city_name)\n        return (location.latitude, location.longitude) if location else None\n    except:\n        return None\n\n\nåŒè¯­ç‰¹æ€§ï¼š - ä¸­æ–‡å­—ç¬¦æ£€æµ‹ï¼šé’ˆå¯¹ CJK å­—ç¬¦çš„é«˜çº§æ­£åˆ™æ¨¡å¼ - åŸå¸‚åç§°æ˜ å°„ï¼šä¸»è¦åŸå¸‚çš„ç¿»è¯‘æ•°æ®åº“ - é”™è¯¯å¤„ç†ï¼šå½“åœ°ç†ç¼–ç å¤±è´¥æ—¶ä¿æŒç³»ç»Ÿç¨³å®š - Unicode æ”¯æŒï¼šå®Œæ•´æ”¯æŒå›½é™…åŒ–å­—ç¬¦\n\n\n\nè¯¥åº”ç”¨ç¨‹åºä» Open-Meteo API è·å–å…¨é¢çš„å¤©æ°”æ•°æ®ï¼š\n\n\nCode\nimport requests\nimport pandas as pd\n\ndef get_weather_data(latitude, longitude):\n    \"\"\"è·å– 12 å¤©çš„å¤©æ°”æ•°æ®ï¼ˆ7 å¤©å†å² + 5 å¤©é¢„æŠ¥ï¼‰\"\"\"\n\n    # API ç«¯ç‚¹é…ç½®\n    url = \"https://api.open-meteo.com/v1/forecast\"\n    params = {\n        'latitude': latitude,\n        'longitude': longitude,\n        'daily': [\n            'temperature_2m_max', 'temperature_2m_min', 'temperature_2m_mean',\n            'weathercode', 'windspeed_10m_max', 'precipitation_probability_max',\n            'pm10', 'pm2_5'\n        ],\n        'timezone': 'auto',\n        'past_days': 7,  # è·å–å†å²æ•°æ®\n        'forecast_days': 5  # è·å–æœªæ¥é¢„æŠ¥\n    }\n\n    try:\n        response = requests.get(url, params=params, timeout=10)\n        response.raise_for_status()\n\n        # å¤„ç†å“åº”æ•°æ®\n        data = response.json()\n        df = process_weather_data(data)\n\n        return df\n\n    except requests.RequestException as e:\n        st.error(f\"API è¯·æ±‚å¤±è´¥: {e}\")\n        return None\n\ndef process_weather_data(data):\n    \"\"\"å°† API å“åº”è½¬æ¢ä¸ºç»“æ„åŒ– DataFrame\"\"\"\n    daily_data = data['daily']\n\n    # åˆ›å»ºæ—¥æœŸèŒƒå›´ï¼ˆå†å² + æœªæ¥ï¼‰\n    dates = pd.date_range(\n        start=pd.to_datetime(daily_data['time'][0]),\n        periods=len(daily_data['time']),\n        freq='D'\n    )\n\n    # æ„å»º DataFrame\n    df = pd.DataFrame({\n        'date': dates,\n        'temperature_max': daily_data['temperature_2m_max'],\n        'temperature_min': daily_data['temperature_2m_min'],\n        'temperature_mean': daily_data['temperature_2m_mean'],\n        'weather_code': daily_data['weathercode'],\n        'wind_speed_max': daily_data['windspeed_10m_max'],\n        'rain_probability': daily_data['precipitation_probability_max'],\n        'pm2_5': daily_data.get('pm2_5', [0] * len(dates))\n    })\n\n    # æ·»åŠ è¡ç”Ÿåˆ—\n    df['is_today'] = df['date'].dt.date == pd.Timestamp.now().date()\n    df['is_future'] = df['date'] &gt; pd.Timestamp.now()\n\n    return df\n\n\næ•°æ®å¤„ç†ç‰¹æ€§ï¼š - å†å² + é¢„æŠ¥ï¼š7 å¤©è¿‡å» + 5 å¤©æœªæ¥ - ç©ºæ°”è´¨é‡é›†æˆï¼šPM2.5 å’Œ PM10 æ•°æ® - æŒ‡æ ‡è¡ç”Ÿï¼šä»Šæ—¥æ£€æµ‹å’Œæœªæ¥è¶‹åŠ¿åˆ†æ - é”™è¯¯ç®¡ç†ï¼šå¥å£®çš„ API é”™è¯¯å¤„ç†æœºåˆ¶\n\n\n\næ¸©åº¦è¶‹åŠ¿å›¾ï¼Œæ¸…æ™°åœ°åŒºåˆ†äº†å†å²æ•°æ®å’Œé¢„æŠ¥æ•°æ®ï¼š\n\n\nCode\nimport altair as alt\n\ndef create_temperature_chart(weather_df):\n    \"\"\"åˆ›å»ºäº¤äº’å¼æ¸©åº¦è¶‹åŠ¿å›¾\"\"\"\n\n    # åŒ…å«æ¸©åº¦çº¿çš„åŸºå‡†å›¾è¡¨\n    base_chart = alt.Chart(weather_df).mark_line(\n        point=True,\n        strokeWidth=3,\n        opacity=0.8\n    ).encode(\n        x=alt.X('date:T', title='æ—¥æœŸ'),\n        y=alt.Y('temperature_mean:Q', title='æ¸©åº¦ (Â°C)', scale=alt.Scale(domain=[weather_df['temperature_min'].min()-5, weather_df['temperature_max'].max()+5]))\n    ).properties(\n        width=800,\n        height=400,\n        title='æ¸©åº¦è¶‹åŠ¿å›¾'\n    )\n\n    # å†å²æ•°æ®ï¼ˆå®çº¿ï¼‰\n    historical_data = weather_df[weather_df['is_future'] == False]\n    historical_line = base_chart.transform_filter(\n        'datum.is_future == false'\n    ).encode(\n        color=alt.value('blue'),\n        strokeDash=alt.value([0])  # å®çº¿\n    )\n\n    # æœªæ¥é¢„æŠ¥ï¼ˆè™šçº¿ï¼‰\n    future_data = weather_df[weather_df['is_future'] == True]\n    future_line = base_chart.transform_filter(\n        'datum.is_future == true'\n    ).encode(\n        color=alt.value('red'),\n        strokeDash=alt.value([5, 5])  # è™šçº¿\n    )\n\n    # ä»Šæ—¥æŒ‡ç¤ºçº¿\n    today_line = alt.Chart(pd.DataFrame({'x': [pd.Timestamp.now()]})).mark_rule(\n        strokeDash=[2, 2],\n        stroke='green',\n        strokeWidth=2\n    ).encode(x='x:T')\n\n    return (historical_line + future_line + today_line).resolve_scale(color='independent')\n\n\nå¯è§†åŒ–ç‰¹æ€§ï¼š - çº¿æ¡æ ·å¼åŒºåˆ†ï¼šå®çº¿ï¼ˆå†å²ï¼‰å¯¹æ¯”è™šçº¿ï¼ˆé¢„æŠ¥ï¼‰ - ä»Šæ—¥æŒ‡ç¤ºå™¨ï¼šå¯¹å½“å‰æ—¥æœŸçš„è§†è§‰æ ‡è®° - é¢œè‰²ç¼–ç ï¼šè“è‰²ä»£è¡¨è¿‡å»ï¼Œçº¢è‰²ä»£è¡¨æœªæ¥ - äº¤äº’å¼æç¤ºï¼šæ‚¬åœæ—¶æ˜¾ç¤ºæ•°æ®ç‚¹ä¿¡æ¯\n\n\n\nç¬¦åˆ EPA æ ‡å‡†çš„ PM2.5 æ°´å¹³é¢œè‰²ç¼–ç ï¼š\n\n\nCode\ndef get_air_quality_level(pm25_value):\n    \"\"\"åŸºäºç¾å›½ EPA PM2.5 æ ‡å‡†è·å–ç©ºæ°”è´¨é‡ç­‰çº§\"\"\"\n\n    if pm25_value &lt;= 12:\n        return {\n            'level': 'ä¼˜',\n            'color': '#00e400',  # æ·±ç»¿\n            'text_color': 'white',\n            'icon': 'ğŸŸ¢'\n        }\n    elif pm25_value &lt;= 35.4:\n        return {\n            'level': 'è‰¯',\n            'color': '#ffff00',  # æµ…é»„\n            'text_color': 'black',\n            'icon': 'ğŸŸ¢'\n        }\n    elif pm25_value &lt;= 55.4:\n        return {\n            'level': 'è½»åº¦æ±¡æŸ“',\n            'color': '#ff7e00',  # æ©™é»„\n            'text_color': 'black',\n            'icon': 'ğŸŸ¡'\n        }\n    elif pm25_value &lt;= 150.4:\n        return {\n            'level': 'ä¸­åº¦æ±¡æŸ“',\n            'color': '#ff0000',  # çº¢è‰²\n            'text_color': 'white',\n            'icon': 'ğŸŸ '\n        }\n    elif pm25_value &lt;= 250.4:\n        return {\n            'level': 'é‡åº¦æ±¡æŸ“',\n            'color': '#8f3f97',  # ç´«è‰²\n            'text_color': 'white',\n            'icon': 'ğŸ”´'\n        }\n    else:\n        return {\n            'level': 'ä¸¥é‡æ±¡æŸ“',\n            'color': '#7e0023',  # æ·±è¤\n            'text_color': 'white',\n            'icon': 'âš«'\n        }\n\ndef display_air_quality_badge(pm25_value):\n    \"\"\"æ˜¾ç¤ºå¸¦è§†è§‰æŒ‡ç¤ºçš„ç©ºæ°”è´¨é‡å¾½ç« \"\"\"\n    aq_info = get_air_quality_level(pm25_value)\n\n    st.markdown(f\"\"\"\n    &lt;div style=\"background-color: {aq_info['color']}; color: {aq_info['text_color']};\n                padding: 10px; border-radius: 5px; text-align: center; margin: 5px 0;\"&gt;\n        &lt;strong&gt;{aq_info['icon']} PM2.5: {pm25_value} Î¼g/mÂ³&lt;/strong&gt;&lt;br&gt;\n        &lt;small&gt;{aq_info['level']}&lt;/small&gt;\n    &lt;/div&gt;\n    \"\"\", unsafe_allow_html=True)\n\n\nç©ºæ°”è´¨é‡åŠŸèƒ½ç‰¹æ€§ï¼š - EPA æ ‡å‡†ï¼šåŸºäºç¾å›½ç¯å¢ƒä¿æŠ¤ç½²çš„æ ‡å‡† - è§†è§‰æŒ‡ç¤ºå™¨ï¼šå¸¦å›¾æ ‡çš„é¢œè‰²ç¼–ç å¾½ç«  - å¯è®¿é—®æ€§ï¼šé«˜å¯¹æ¯”åº¦è‰²å€¼ç¡®ä¿å¯è¯»æ€§ - ç§‘æ™®æ€§ï¼šé€šè¿‡ç­‰çº§è¯´æ˜å¸®åŠ©ç”¨æˆ·ç†è§£"
  },
  {
    "objectID": "posts/weather-trend/index.html#ai-é©±åŠ¨çš„å¤©æ°”æ™ºèƒ½",
    "href": "posts/weather-trend/index.html#ai-é©±åŠ¨çš„å¤©æ°”æ™ºèƒ½",
    "title": "ç»“åˆ AI é¢„æµ‹çš„ Streamlit å¤©æ°”é¢„æŠ¥åº”ç”¨",
    "section": "",
    "text": "æœ¬é¡¹ç›®æœ€å…·åˆ›æ–°æ€§çš„åŠŸèƒ½æ˜¯ä½¿ç”¨ ModelScope å¹³å°ä¸Šçš„ DeepSeek-V3.2 æ¨¡å‹æä¾› AI å¤©æ°”åˆ†æï¼š\n\n\n\nAI å¤©æ°”åˆ†æå»ºè®®\n\n\n\n\nCode\nfrom openai import OpenAI\nimport os\n\n# åˆå§‹åŒ– ModelScope çš„ AI å®¢æˆ·ç«¯\ndef init_ai_client():\n    \"\"\"åˆå§‹åŒ–ç”¨äº ModelScope API çš„ OpenAI å®¢æˆ·ç«¯\"\"\"\n    return OpenAI(\n        base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\",\n        api_key=os.getenv(\"modelscope\"),\n    )\n\ndef generate_weather_insights(weather_df, location_name, language=\"en\"):\n    \"\"\"ç”Ÿæˆ AI é©±åŠ¨çš„å¤©æ°”åˆ†æå»ºè®®\"\"\"\n\n    # å‡†å¤‡ç”¨äº AI åˆ†æçš„å¤©æ°”æ•°æ®\n    today_index = weather_df[weather_df['is_today']].index[0] if any(weather_df['is_today']) else 0\n    historical_data = weather_df.iloc[:today_index+1]  # æˆªè‡³ä»Šæ—¥\n    future_data = weather_df.iloc[today_index:]  # ä»Šæ—¥èµ·\n\n    # ä¸º AI åˆ›å»ºå¤©æ°”æ‘˜è¦\n    weather_summary = f\"\"\"\n    åœ°ç‚¹: {location_name}\n\n    å†å²å¤©æ°” (è¿‡å» {len(historical_data)} å¤©):\n    - æ¸©åº¦èŒƒå›´: {historical_data['temperature_min'].min():.1f}Â°C åˆ° {historical_data['temperature_max'].max():.1f}Â°C\n    - å¹³å‡æ¸©åº¦: {historical_data['temperature_mean'].mean():.1f}Â°C\n    - ç©ºæ°”è´¨é‡èŒƒå›´: {historical_data['pm2_5'].min():.1f} åˆ° {historical_data['pm2_5'].max():.1f} PM2.5\n\n    å¤©æ°”é¢„æŠ¥ (æœªæ¥ {len(future_data)} å¤©):\n    - æ¸©åº¦èŒƒå›´: {future_data['temperature_min'].min():.1f}Â°C åˆ° {future_data['temperature_max'].max():.1f}Â°C\n    - å¹³å‡é™é›¨æ¦‚ç‡: {future_data['rain_probability'].mean():.0f}%\n    \"\"\"\n\n    # æ ¹æ®è¯­è¨€ç”Ÿæˆæç¤ºè¯\n    if language == \"zh\":\n        prompt = f\"\"\"\n        åŸºäºä»¥ä¸‹å¤©æ°”æ•°æ®ï¼Œè¯·æä¾›ç®€æ´å®ç”¨çš„å¤©æ°”å»ºè®®ï¼ˆ100-200å­—ï¼‰ï¼š\n\n        {weather_summary}\n\n        è¯·åŒ…æ‹¬ï¼š\n        1. å¤©æ°”æ¨¡å¼åˆ†æ\n        2. ç©¿è¡£å»ºè®®\n        3. æˆ·å¤–æ´»åŠ¨å»ºè®®\n        4. å¥åº·æ³¨æ„äº‹é¡¹ï¼ˆå¦‚ç©ºæ°”è´¨é‡ç›¸å…³ï¼‰\n\n        è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œè¯­æ°”å‹å¥½å®ç”¨ã€‚\n        \"\"\"\n    else:\n        prompt = f\"\"\"\n        Based on the following weather data, please provide concise and practical weather advice (100-200 words):\n\n        {weather_summary}\n\n        Please include:\n        1. Weather pattern analysis\n        2. Clothing recommendations\n        3. Outdoor activity suggestions\n        4. Health considerations (related to air quality if applicable)\n\n        Please respond in {language} with a friendly and practical tone.\n        \"\"\"\n\n    try:\n        client = init_ai_client()\n        response = client.chat.completions.create(\n            model=\"deepseek-ai/DeepSeek-V3\",\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            max_tokens=300,\n            temperature=0.7\n        )\n\n        return response.choices[0].message.content\n\n    except Exception as e:\n        return f\"AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚é”™è¯¯ä¿¡æ¯: {str(e)}\"\n\n# åœ¨ Streamlit åº”ç”¨ä¸­\nif st.button(get_text(\"ai_button\", language)):\n    with st.spinner(\"æ­£åœ¨è·å– AI å¤©æ°”å»ºè®®...\"):\n        if 'weather_df' in st.session_state and 'location_name' in st.session_state:\n            ai_insights = generate_weather_insights(\n                st.session_state.weather_df,\n                st.session_state.location_name,\n                language\n            )\n            st.markdown(\"### ğŸ¤– AI å¤©æ°”åˆ†æ\")\n            st.write(ai_insights)\n        else:\n            st.warning(\"è¯·å…ˆè·å–å¤©æ°”æ•°æ®ã€‚\")\n\n\nAI ç‰¹æ€§ï¼š - ä¸Šä¸‹æ–‡æ„ŸçŸ¥åˆ†æï¼šåŒæ—¶å¤„ç†å†å²å’Œé¢„æŠ¥æ•°æ® - å¤šè¯­è¨€æ”¯æŒï¼šAI æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„è¯­è¨€å›å¤ - å®ç”¨å»ºè®®ï¼šæä¾›ç©¿è¡£ã€æ´»åŠ¨å’Œå¥åº·æ–¹é¢çš„è§è§£ - å®¹é”™å¤„ç†ï¼šåœ¨ AI æœåŠ¡ä¸å¯ç”¨æ—¶ä¼˜é›…åœ°æç¤º\n\n\n\nAI ç³»ç»Ÿé€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤ºè¯ç”Ÿæˆæœ‰ä»·å€¼çš„è§è§£ï¼š\næç¤ºè¯ç»“æ„ï¼š 1. æ•°æ®ä¸Šä¸‹æ–‡ï¼šå…¨é¢çš„å¤©æ°”ç»Ÿè®¡ä¿¡æ¯ 2. ä»»åŠ¡å®šä¹‰ï¼šæ˜ç¡®çš„åˆ†æè¦æ±‚ 3. è¾“å‡ºæ ¼å¼ï¼šç»“æ„åŒ–çš„å›å¤ç±»åˆ« 4. è¯­è¨€é€‚é…ï¼šä¸ UI è¯­è¨€ä¿æŒä¸€è‡´\nå»ºè®®ç±»åˆ«ï¼š - å¤©æ°”æ¨¡å¼åˆ†æï¼šè¶‹åŠ¿å’Œå¼‚å¸¸åˆ†æ - ç©¿è¡£å»ºè®®ï¼šå®ç”¨çš„ç©¿ç€æŒ‡å¯¼ - æ´»åŠ¨å»ºè®®ï¼šæˆ·å¤–è®¡åˆ’çš„æ¨è - å¥åº·æ³¨æ„äº‹é¡¹ï¼šç©ºæ°”è´¨é‡åŠå¤©æ°”å½±å“"
  },
  {
    "objectID": "posts/weather-trend/index.html#å›½é™…åŒ–ç³»ç»Ÿ",
    "href": "posts/weather-trend/index.html#å›½é™…åŒ–ç³»ç»Ÿ",
    "title": "ç»“åˆ AI é¢„æµ‹çš„ Streamlit å¤©æ°”é¢„æŠ¥åº”ç”¨",
    "section": "",
    "text": "åº”ç”¨å®ç°äº†ä¸€ä¸ªå…¨é¢çš„åŒè¯­ç³»ç»Ÿï¼š\n\n\nCode\n# language.py - ç¿»è¯‘ç®¡ç†\nTRANSLATIONS = {\n    \"en\": {\n        \"app_title\": \"Weather Forecast App\",\n        \"sidebar_header\": \"Weather Query\",\n        \"city_input_placeholder\": \"Enter a city name\",\n        \"get_weather_button\": \"Get Weather\",\n        \"weather_trends_title\": \"Weather Trends for\",\n        \"ai_button\": \"AI Weather Advice\",\n        # ... æ›´å¤šç¿»è¯‘\n    },\n    \"zh\": {\n        \"app_title\": \"å¤©æ°”é¢„æŠ¥åº”ç”¨\",\n        \"sidebar_header\": \"å¤©æ°”æŸ¥è¯¢\",\n        \"city_input_placeholder\": \"è¾“å…¥åŸå¸‚åç§°\",\n        \"get_weather_button\": \"è·å–å¤©æ°”\",\n        \"weather_trends_title\": \"å¤©æ°”è¶‹åŠ¿\",\n        \"ai_button\": \"AIå¤©æ°”å»ºè®®\",\n        # ... æ›´å¤šç¿»è¯‘\n    }\n}\n\ndef get_text(key, language=\"en\"):\n    \"\"\"è·å–æŒ‡å®šé”®å’Œè¯­è¨€çš„ç¿»è¯‘æ–‡æœ¬\"\"\"\n    return TRANSLATIONS.get(language, {}).get(key, key)\n\ndef get_available_languages():\n    \"\"\"è·å–å¯ç”¨çš„è¯­è¨€é€‰é¡¹\"\"\"\n    return {\"en\": \"English\", \"zh\": \"ä¸­æ–‡\"}\n\n# åœ¨ä¸»ç¨‹åº (app.py) ä¸­\ndef main():\n    # è¯­è¨€çŠ¶æ€ç®¡ç†\n    if 'language' not in st.session_state:\n        st.session_state.language = \"en\"\n\n    # è¯­è¨€åˆ‡æ¢æŒ‰é’®\n    current_lang = st.session_state.language\n    available_langs = get_available_languages()\n\n    col1, col2, col3 = st.columns([1,1,6])\n    with col1:\n        if st.button(\"EN\", disabled=current_lang==\"en\"):\n            st.session_state.language = \"en\"\n            st.rerun()\n\n    with col2:\n        if st.button(\"ä¸­æ–‡\", disabled=current_lang==\"zh\"):\n            st.session_state.language = \"zh\"\n            st.rerun()\n\n    # åœ¨æ‰€æœ‰ UI å…ƒç´ ä¸­ä½¿ç”¨å½“å‰è¯­è¨€\n    language = st.session_state.language\n    st.title(get_text(\"app_title\", language))\n    st.sidebar.header(get_text(\"sidebar_header\", language))\n\n\nå›½é™…åŒ–ç‰¹æ€§ï¼š - å®Œæ•´çš„ UI ç¿»è¯‘ï¼šæœ¬åœ°åŒ–æ‰€æœ‰ç•Œé¢å…ƒç´  - åŠ¨æ€è¯­è¨€åˆ‡æ¢ï¼šè¯­è¨€æ›´æ”¹æ—¶å³æ—¶æ›´æ–° UI - ä¸­æ–‡å­—ç¬¦æ”¯æŒï¼šå®Œæ•´çš„ Unicode å’Œ CJK æ”¯æŒ - è¯­å¢ƒä¸€è‡´ï¼šAI å›å¤ä¸ UI è¯­è¨€ç›¸åŒ¹é…"
  },
  {
    "objectID": "posts/weather-trend/index.html#é«˜çº§-ui-ç»„ä»¶",
    "href": "posts/weather-trend/index.html#é«˜çº§-ui-ç»„ä»¶",
    "title": "ç»“åˆ AI é¢„æµ‹çš„ Streamlit å¤©æ°”é¢„æŠ¥åº”ç”¨",
    "section": "",
    "text": "å¤©æ°”è¡¨ç»“åˆäº†æ•°æ®ä¸è§†è§‰å…ƒç´ ï¼Œæ–¹ä¾¿ç”¨æˆ·å¿«é€Ÿç†è§£ï¼š\n\n\nCode\ndef create_weather_table(weather_df, language=\"en\"):\n    \"\"\"åˆ›å»ºå¢å¼ºçš„å¤©æ°”è¡¨ï¼ŒåŒ…å«å›¾æ ‡å’Œé¢œè‰²æ˜¾ç¤º\"\"\"\n\n    # å¤©æ°”ä»£ç åˆ° Emoji çš„æ˜ å°„\n    WEATHER_ICONS = {\n        0: \"â˜€ï¸\",   # æ™´\n        1: \"â›…\",   # æ™´é—´å¤šäº‘\n        2: \"â˜ï¸\",   # å¤šäº‘\n        3: \"â˜ï¸\",   # é˜´\n        45: \"ğŸŒ«ï¸\",  # é›¾\n        48: \"ğŸŒ¦ï¸\",  # é˜µé›¨\n        51: \"ğŸŒ§ï¸\",  # é›¨\n        53: \"â„ï¸\",  # é›ª\n        95: \"â›ˆï¸\",  # é›·é˜µé›¨\n    }\n\n    def format_weather_row(row):\n        \"\"\"æ ¼å¼åŒ–å•è¡Œå¤©æ°”æƒ…å†µå¹¶æ·»åŠ æ ·å¼\"\"\"\n        date_str = row['date'].strftime('%Y-%m-%d')\n        temp_range = f\"{row['temperature_min']:.1f}Â° ~ {row['temperature_max']:.1f}Â°\"\n        weather_icon = WEATHER_ICONS.get(row['weather_code'], \"ğŸŒ¡ï¸\")\n\n        # ç©ºæ°”è´¨é‡å¾½ç« \n        aq_info = get_air_quality_level(row['pm2_5'])\n        aq_badge = f'&lt;span style=\"background-color: {aq_info[\"color\"]}; color: {aq_info[\"text_color\"]}; padding: 2px 6px; border-radius: 3px; font-size: 0.8em;\"&gt;{aq_info[\"icon\"]} {row[\"pm2_5\"]:.0f}&lt;/span&gt;'\n\n        # é™é›¨æ¦‚ç‡æŒ‡ç¤º\n        rain_color = 'red' if row['rain_probability'] &gt;= 80 else 'orange' if row['rain_probability'] &gt;= 50 else 'gray'\n        rain_indicator = f'&lt;span style=\"color: {rain_color};\"&gt;ğŸ”´ {row[\"rain_probability\"]:.0f}%&lt;/span&gt;' if row['rain_probability'] &gt;= 50 else f'&lt;span style=\"color: {rain_color};\"&gt;ğŸŸ¢ {row[\"rain_probability\"]:.0f}%&lt;/span&gt;'\n\n        # â€œä»Šæ—¥â€è¡Œé«˜äº®æ˜¾ç¤º\n        row_style = 'font-size: 1.2em; font-weight: bold;' if row['is_today'] else ''\n\n        return {\n            'æ—¥æœŸ': f'&lt;span style=\"{row_style}\"&gt;{date_str}&lt;/span&gt;',\n            'å¤©æ°”': f'&lt;span style=\"{row_style}\"&gt;{weather_icon}&lt;/span&gt;',\n            'æ¸©åº¦': f'&lt;span style=\"{row_style}\"&gt;{temp_range}&lt;/span&gt;',\n            'é£é€Ÿ': f'&lt;span style=\"{row_style}\"&gt;ğŸ’¨ {row[\"wind_speed_max\"]:.1f} km/h&lt;/span&gt;',\n            'é™é›¨': rain_indicator,\n            'ç©ºæ°”è´¨é‡': aq_badge\n        }\n\n    # å¯¹æ‰€æœ‰è¡Œåº”ç”¨æ ¼å¼åŒ–\n    formatted_rows = [format_weather_row(row) for _, row in weather_df.iterrows()]\n\n    return pd.DataFrame(formatted_rows)\n\n# åœ¨ Streamlit ä¸­æ˜¾ç¤º\nst.markdown(\"### ğŸ“Š å¤©æ°”è¯¦æƒ…\")\nst.dataframe(\n    create_weather_table(weather_df, language),\n    width=1200,\n    hide_index=True,\n    unsafe_allow_html=True\n)\n\n\nè¡¨æ ¼ç‰¹æ€§ï¼š - å¤©æ°”å›¾æ ‡ï¼šEmoji è¡¨è¾¾æ–¹å¼ï¼Œç›´è§‚æ˜“æ‡‚ - ä»Šæ—¥é«˜äº®ï¼šå¯¹å½“å¤©æ—¥æœŸä½¿ç”¨æ›´å¤§ã€åŠ ç²—çš„æ–‡å­— - ç©ºæ°”è´¨é‡å¾½ç« ï¼šé¢œè‰²ç¼–ç çš„ PM2.5 æŒ‡æ ‡ - é™é›¨æ¦‚ç‡ï¼šåŸºäº Material Design è‰²ç³»çš„è§†è§‰æŒ‡ç¤º - å“åº”å¼å¸ƒå±€ï¼šé€‚åº”å„ç§å±å¹•å®½åº¦"
  },
  {
    "objectID": "posts/weather-trend/index.html#éƒ¨ç½²ä¸ç”Ÿäº§",
    "href": "posts/weather-trend/index.html#éƒ¨ç½²ä¸ç”Ÿäº§",
    "title": "ç»“åˆ AI é¢„æµ‹çš„ Streamlit å¤©æ°”é¢„æŠ¥åº”ç”¨",
    "section": "",
    "text": "åœ¨ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²æ—¶ï¼Œè¯·é…ç½®ç¯å¢ƒå˜é‡ï¼š\n# .env æ–‡ä»¶\nmodelscope=æ‚¨çš„ API å¯†é’¥\n\n# å…¶ä»–ç”Ÿäº§ç¯å¢ƒè®¾ç½®\n# è€ƒè™‘é¢‘ç‡é™åˆ¶ã€ç¼“å­˜æœºåˆ¶å’Œç›‘æ§\n\n\n\n# 1. å®‰è£… Streamlit CLI\npip install streamlit\n\n# 2. ç™»å½• Streamlit\nstreamlit login\n\n# 3. éƒ¨ç½²åˆ° Streamlit Cloud\nstreamlit run app.py  # é¦–å…ˆåœ¨æœ¬åœ°æµ‹è¯•\n# ç„¶åé€šè¿‡ cloud.streamlit.io æˆ– CLI è¿›è¡Œéƒ¨ç½²\n\n\n\nFROM python:3.9-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCOPY . .\n\nEXPOSE 8501\n\nCMD [\"streamlit\", \"run\", \"app.py\", \"--server.address\", \"0.0.0.0\"]"
  },
  {
    "objectID": "posts/weather-trend/index.html#æ€§èƒ½ä¼˜åŒ–",
    "href": "posts/weather-trend/index.html#æ€§èƒ½ä¼˜åŒ–",
    "title": "ç»“åˆ AI é¢„æµ‹çš„ Streamlit å¤©æ°”é¢„æŠ¥åº”ç”¨",
    "section": "",
    "text": "@st.cache_data(ttl=3600)  # ç¼“å­˜ 1 å°æ—¶\ndef get_weather_data_cached(lat, lon):\n    \"\"\"ç¼“å­˜å¤©æ°”æ•°æ®è·å–æ“ä½œ\"\"\"\n    return get_weather_data(lat, lon)\n\n@st.cache_resource\ndef get_ai_client():\n    \"\"\"ç¼“å­˜ AI å®¢æˆ·ç«¯åˆå§‹åŒ–\"\"\"\n    return init_ai_client()\n\n# ç¼“å­˜åœ°å›¾ç”Ÿæˆ\n@st.cache_data(ttl=3600)\ndef create_map_cached(lat, lon):\n    \"\"\"ç¼“å­˜åœ°å›¾åˆ›å»ºæ“ä½œ\"\"\"\n    return create_interactive_map(lat, lon)\n\n\n\n\n\nCode\ndef robust_api_call(func, *args, max_retries=3, **kwargs):\n    \"\"\"å¸¦é‡è¯•é€»è¾‘çš„é«˜å¯ç”¨ API è°ƒç”¨\"\"\"\n    for attempt in range(max_retries):\n        try:\n            return func(*args, **kwargs)\n        except requests.exceptions.Timeout:\n            if attempt == max_retries - 1:\n                st.error(\"å¤©æ°”æœåŠ¡æš‚æ—¶ä¸å¯ç”¨\")\n                return None\n            time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿é‡è¯•\n        except requests.exceptions.RequestException as e:\n            st.error(f\"API é”™è¯¯: {e}\")\n            return None\n\n\n\næ•°æ®å¯è§†åŒ–ï¼šä¸“ä¸šå›¾è¡¨ä¸äº¤äº’å¼åœ°å›¾ã€‚\nAI é›†æˆï¼šå°†è¯­è¨€æ¨¡å‹å®é™…åº”ç”¨äºæ•°æ®åˆ†æã€‚\nå›½é™…åŒ–ï¼šå®Œæ•´çš„åŒè¯­æ”¯æŒã€‚\nç”Ÿäº§å°±ç»ªï¼šåŒ…å«é”™è¯¯å¤„ç†ã€ç¼“å­˜å’Œæ€§èƒ½ä¼˜åŒ–ã€‚\n\næ— è®ºæ‚¨æ˜¯åœ¨æ„å»ºå¤©æ°”åº”ç”¨ã€æ•°æ®çœ‹æ¿è¿˜æ˜¯ AI é©±åŠ¨çš„å·¥å…·ï¼Œè¯¥é¡¹ç›®éƒ½ä¸ºåˆ›å»ºå¤æ‚ä¸”ç”¨æˆ·å‹å¥½çš„åº”ç”¨ç¨‹åºæä¾›äº†åšå®çš„åŸºç¡€ã€‚"
  },
  {
    "objectID": "posts/whisky-tasting/index.html",
    "href": "posts/whisky-tasting/index.html",
    "title": "åŸºäº RAG çš„å¨å£«å¿Œå“é‰´ç¬”è®°",
    "section": "",
    "text": "å¨å£«å¿Œå“é‰´åº”ç”¨æ˜¯ä¸€æ¬¾å…ˆè¿›çš„ AI é©±åŠ¨ Web åº”ç”¨ç¨‹åºï¼Œå¯ç”Ÿæˆè¯¦ç»†ã€ä¸“ä¸šçš„å¨å£«å¿Œå“é‰´ç¬”è®°å’Œå»ºè®®ã€‚è¯¥ç³»ç»Ÿçš„ç‰¹åˆ«ä¹‹å¤„åœ¨äºå…¶é‡‡ç”¨äº†å¤š Agent æ¶æ„ï¼Œå¹¶é…å¤‡äº†ä¸“é—¨çš„ AI äººæ ¼ï¼Œæ¯ä¸ªäººæ ¼éƒ½ç»è¿‡äº†ä¸åŒå¨å£«å¿Œè¯„è®ºæºå’Œè¯­è¨€é£æ ¼çš„è®­ç»ƒã€‚\nåœ¨çº¿æ¼”ç¤º (Modelscope): https://modelscope.cn/studios/ttflying/whisky_AI_tasting\nåœ¨çº¿æ¼”ç¤º (Shinyapp): https://jcflyingco.shinyapps.io/ai-whisky-tasting/\nGithub: https://github.com/JCwinning/whisky_tasting\n\nAI å“é‰´è¯AI æ¨è\n\n\n\n\n\n\n\n\n\n\n\n\n\nè¯¥åº”ç”¨åŒ…å«ä¸‰ä¸ªä¸“é—¨çš„ AI Agentï¼Œæ¯ä¸ª Agent éƒ½æœ‰ç‹¬ç‰¹çš„ç‰¹å¾å’Œæ•°æ®æºï¼š\n\nDrunkTony (dt) - ä¸­æ–‡ Agentï¼Œä¸“æ³¨äºä¸­æ–‡å¨å£«å¿Œè¯„è®ºã€‚\nWhiskyFunny (wf) - è‹±æ–‡ Agentï¼Œæ•°æ®æºè‡ª whiskyfun.comã€‚\nWhiskyNotebook (wn) - è‹±æ–‡ Agentï¼Œæ•°æ®æºè‡ª whiskynotes.beã€‚\n\n\n\n\n\nä¸»è¦è¯­è¨€: Python 3.13+\nWeb æ¡†æ¶: Streamlit (ä¸»é€‰) + Shiny for Python (å¤‡é€‰)\næ•°æ®åº“: DuckDB (376MBï¼Œé’ˆå¯¹å‘é‡æ“ä½œè¿›è¡Œäº†ä¼˜åŒ–)\nAI/ML: OpenAI API, å‘é‡åµŒå…¥ (Vector embeddings), RAG ç³»ç»Ÿ\næ•°æ®æº: ä½¿ç”¨ BeautifulSoup4 è¿›è¡Œç½‘é¡µæŠ“å–\n\n\n\n\n\n\n\nç³»ç»Ÿä½¿ç”¨ DuckDB ä½œä¸ºä¸»æ•°æ®åº“ï¼Œå› å…¶åœ¨å‘é‡æ“ä½œæ–¹é¢è¡¨ç°å“è¶Šï¼š\n-- æ•°æ®åº“ç»“æ„\nCREATE TABLE drinktony_embed (\n    full TEXT,\n    bottle_embedding FLOAT[1024]  -- 1024 ç»´å‘é‡\n);\n\nCREATE TABLE whiskyfun_embed (\n    full TEXT,\n    bottle_embedding FLOAT[1024]\n);\n\nCREATE TABLE whiskynote_embed (\n    full TEXT,\n    bottle_embedding FLOAT[1024]\n);\n\n\n\n\n\nCode\n# get_data_dt.py ä¸­çš„ç½‘é¡µæŠ“å–ç¤ºä¾‹\ndef scrape_drinktony_reviews():\n    \"\"\"ä» drinktony.netlify.app æŠ“å–ä¸­æ–‡å¨å£«å¿Œè¯„è®º\"\"\"\n    url = \"https://drinktony.netlify.app/\"\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, \"html.parser\")\n\n    # æŸ¥æ‰¾æ‰€æœ‰è¯„è®ºé“¾æ¥\n    post_links = [urljoin(url, a.get(\"href\"))\n                 for a in soup.select(\"a.quarto-grid-link\")]\n\n    all_reviews = []\n    for post_url in post_links:\n        response = requests.get(post_url)\n        soup = BeautifulSoup(response.content, \"html.parser\")\n\n        # æå–è¯„è®ºç« èŠ‚\n        review_sections = soup.select(\"section.level1\")\n        for section in review_sections:\n            # è§£æå¨å£«å¿Œåç§°å’Œè¯„è®ºå†…å®¹\n            whisky_name = extract_whisky_name(section)\n            review_text = extract_review_text(section)\n            all_reviews.append({\n                'whisky': whisky_name,\n                'review': review_text\n            })\n\n    return all_reviews\n\n\n\n\n\n\n\n\nåº”ç”¨ä½¿ç”¨å°–ç«¯çš„åµŒå…¥æŠ€æœ¯å°†æ–‡æœ¬è½¬æ¢ä¸ºé«˜ç»´å‘é‡ï¼Œä»¥ä¾¿è¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢ã€‚\n\n\næ¨¡å‹: BAAI/bge-large-zh-v1.5 - ç»´åº¦: 1024 - æœåŠ¡å•†: SiliconFlow API - ç”¨é€”: è·¨è¯­è¨€æ–‡æœ¬ç†è§£ï¼ˆåœ¨ä¸­è‹±æ–‡æ–¹é¢è¡¨ç°å‡å¾ˆå‡ºè‰²ï¼‰\n\n\n\n\nè·¨è¯­è¨€èƒ½åŠ›: åœ¨ç†è§£ä¸­è‹±æ–‡å¨å£«å¿Œä¸“ä¸šæœ¯è¯­æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚\né«˜æ€§èƒ½: ä¸é€šç”¨åµŒå…¥æ¨¡å‹ç›¸æ¯”ï¼Œå…·å¤‡æ›´å‡ºè‰²çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ã€‚\né«˜æ•ˆå°ºå¯¸: 1024 ç»´åº¦åœ¨æ€§èƒ½å’Œå­˜å‚¨æ•ˆç‡ä¹‹é—´è¾¾åˆ°äº†å¹³è¡¡ã€‚\nAPI è®¿é—®: é€šè¿‡ SiliconFlow æä¾›ç¨³å®šçš„æœåŠ¡ã€‚\n\n\n\n\nè¯¥åº”ç”¨ä½¿ç”¨ BGE-Large-ZH-v1.5 æ¨¡å‹ç”ŸæˆåµŒå…¥å‘é‡ï¼š\n\n\nCode\ndef get_embedding(text: str, api_key: str):\n    \"\"\"ä½¿ç”¨ SiliconFlow API ç”Ÿæˆæ–‡æœ¬åµŒå…¥\"\"\"\n    client = OpenAI(\n        api_key=api_key,\n        base_url=\"https://api.siliconflow.cn/v1\"\n    )\n    response = client.embeddings.create(\n        model=\"BAAI/bge-large-zh-v1.5\",\n        input=[text]\n    )\n    return np.array(response.data[0].embedding)\n\ndef cosine_similarity(v1, v2):\n    \"\"\"è®¡ç®—ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦\"\"\"\n    if v1 is None or v2 is None:\n        return 0\n    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n\n\n\n\n\n\næ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) ç³»ç»Ÿæ˜¯æ­¤åº”ç”¨çš„æ ¸å¿ƒåˆ›æ–°ã€‚è®©æˆ‘ä»¬è¯¦ç»†æ¢è®¨å…¶ç»„ä»¶ã€‚\n\n\n\næ£€ç´¢å¢å¼ºç”Ÿæˆè¿‡ç¨‹éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š\n%%| fig-cap: \"å¨å£«å¿Œå“é‰´çš„ RAG å·¥ä½œæµ\"\nflowchart TD\n    A[ç”¨æˆ·è¾“å…¥&lt;br/&gt;å¨å£«å¿Œåç§°] --&gt; B[ç”ŸæˆåµŒå…¥å‘é‡]\n    B --&gt; C[DuckDB ä¸­çš„&lt;br/&gt;å‘é‡ç›¸ä¼¼åº¦æœç´¢]\n    C --&gt; D[æ£€ç´¢å‰ 10 æ¡&lt;br/&gt;ç›¸ä¼¼è¯„è®º]\n    D --&gt; E[ä¸º LLM æ ¼å¼åŒ–ä¸Šä¸‹æ–‡]\n    E --&gt; F[ä¸» LLM&lt;br/&gt;ç”Ÿæˆå“é‰´ç¬”è®°]\n    F --&gt; G[å‰¯ LLM&lt;br/&gt;ç”Ÿæˆæ¨èå»ºè®®]\n    G --&gt; H[æ ¼å¼åŒ–å¹¶&lt;br/&gt;æ˜¾ç¤ºç»“æœ]\n\n    C --&gt; I[æ•°æ®åº“]\n    I --&gt; J[drinktony_embed&lt;br/&gt;1200 æ¡ä¸­æ–‡è¯„è®º]\n    I --&gt; K[whiskyfun_embed&lt;br/&gt;2 ä¸‡æ¡è‹±æ–‡è¯„è®º]\n    I --&gt; L[whiskynote_embed&lt;br/&gt;5000 æ¡è‹±æ–‡è¯„è®º]\n\n\n\n\n\nCode\ndef find_similar_chunks(\n    query_embedding,\n    db_path,\n    table_name,\n    text_col,\n    embedding_col,\n    top_n=10,\n):\n    \"\"\"ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦åœ¨æ•°æ®åº“ä¸­æŸ¥æ‰¾æœ€ç›¸ä¼¼çš„æ–‡æœ¬å—\"\"\"\n    try:\n        with duckdb.connect(database=db_path, read_only=True) as con:\n            df = con.execute(\n                f'SELECT \"{text_col}\", \"{embedding_col}\" FROM \"{table_name}\"'\n            ).fetchdf()\n\n            # è®¡ç®—ç›¸ä¼¼åº¦\n            similarities = []\n            for _, row in df.iterrows():\n                text = row[text_col]\n                embedding = np.array(row[embedding_col])\n                similarity = cosine_similarity(query_embedding, embedding)\n                similarities.append((text, similarity))\n\n            # æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶è¿”å›å‰ N æ¡\n            similarities.sort(key=lambda x: x[1], reverse=True)\n            return similarities[:top_n]\n\n    except Exception as e:\n        print(f\"æœç´¢ç›¸ä¼¼å—æ—¶å‡ºé”™: {e}\")\n        return []\n\n\n\n\n\n\n\n\n\n\nCode\ndef run_conversation(query, api_key, model):\n    \"\"\"ç”Ÿæˆä¸­æ–‡æ ¼å¼çš„å¨å£«å¿Œå“é‰´ç¬”è®°\"\"\"\n\n    # ç¬¬ 1 æ­¥ï¼šç”ŸæˆåµŒå…¥å¹¶æŸ¥æ‰¾ç›¸ä¼¼è¯„è®º\n    query_embedding = get_embedding(query, api_key)\n    similar_reviews = find_similar_chunks(\n        query_embedding=query_embedding,\n        db_path=\"data/whisky_database.duckdb\",\n        table_name=\"drinktony_embed\",\n        text_col=\"full\",\n        embedding_col=\"bottle_embedding\"\n    )\n\n    # ç¬¬ 2 æ­¥ï¼šä¸º LLM å‡†å¤‡ä¸Šä¸‹æ–‡\n    context = \"\\n---\\n\".join([review[0] for review in similar_reviews])\n\n    # ç¬¬ 3 æ­¥ï¼šç”Ÿæˆå“é‰´ç¬”è®°\n    prompt = f\"\"\"ä½œä¸ºå¨å£«å¿Œä¸“å®¶ï¼ŒåŸºäºä»¥ä¸‹å¨å£«å¿Œå“é‰´ç¬”è®°ï¼Œä¸º\"{query}\"ç”Ÿæˆä¸“ä¸šçš„å“é‰´æŠ¥å‘Šï¼š\n\nå‚è€ƒå“é‰´ç¬”è®°ï¼š\n{context}\n\nè¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š\n{query}\né—»é¦™: [è¯¦ç»†æè¿°]\nå“å‘³: [è¯¦ç»†æè¿°]\næ‰“åˆ†: [90-100åˆ†]\n\"\"\"\n\n    response = llm_client.chat.completions.create(\n        model=model,\n        messages=[\n            {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¨å£«å¿Œå“é‰´å¸ˆï¼Œæ“…é•¿ç”Ÿæˆè¯¦ç»†å‡†ç¡®çš„å“é‰´ç¬”è®°ã€‚\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        temperature=0.7,\n        max_tokens=1000\n    )\n\n    return response.choices[0].message.content\n\n\n\n\n\n\n\nCode\ndef run_conversation(query, api_key, model):\n    \"\"\"ç”Ÿæˆè‹±æ–‡æ ¼å¼çš„å¨å£«å¿Œå“é‰´ç¬”è®°\"\"\"\n\n    query_embedding = get_embedding(query, api_key)\n    similar_reviews = find_similar_chunks(\n        query_embedding=query_embedding,\n        db_path=\"data/whisky_database.duckdb\",\n        table_name=\"whiskyfun_embed\",\n        text_col=\"full\",\n        embedding_col=\"bottle_embedding\"\n    )\n\n    context = \"\\n---\\n\".join([review[0] for review in similar_reviews])\n\n    prompt = f\"\"\"As a whisky expert, generate professional tasting notes for \"{query}\" based on these reference reviews:\n\nReference reviews:\n{context}\n\nPlease output in this format:\nColour: [detailed description]\nNose: [detailed aroma description]\nMouth: [detailed taste description]\nFinish: [detailed finish description]\nComments: [overall impression]\nSGP: xxx - xx points\n\"\"\"\n\n    response = llm_client.chat.completions.create(\n        model=model,\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a professional whisky taster specializing in detailed sensory analysis.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        temperature=0.7,\n        max_tokens=1200\n    )\n\n    return response.choices[0].message.content\n\n\n\n\n\n\n\n\nåº”ç”¨ä½¿ç”¨ä¸€ä¸ªç‹¬ç«‹çš„ LLM æ¥ç”Ÿæˆå¨å£«å¿Œæ¨èå»ºè®®ï¼š\n\n\nCode\ndef recommend_whiskies_by_profile(tasting_notes, api_key, model):\n    \"\"\"åŸºäºå“é‰´ç‰¹å¾ç”Ÿæˆå¨å£«å¿Œæ¨è\"\"\"\n\n    prompt = f\"\"\"Based on these tasting notes, recommend 2 similar whiskies that the user might enjoy:\n\n{Tasting Notes:}\n{tasting_notes}\n\nPlease provide:\n1. Whisky name with brief description\n2. Why it matches the user's preference\n3. Price range and availability\n\nFormat each recommendation as:\n**Recommendation [1/2]:** [Whisky Name]\n**Why it matches:** [detailed reasoning]\n**Details:** [price, availability, tasting profile]\n\"\"\"\n\n    response = recommendation_client.chat.completions.create(\n        model=model,  # æ¨èä½¿ç”¨ä¸åŒçš„æ¨¡å‹\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a whisky recommendation expert with deep knowledge of global whisky brands and profiles.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        temperature=0.8,\n        max_tokens=800\n    )\n\n    return response.choices[0].message.content\n\n\n\n\n\n\n\n\n\n\nCode\n# ä¸»åº”ç”¨ç¨‹åºç•Œé¢\ndef main():\n    st.set_page_config(\n        page_title=\"AI å¨å£«å¿Œå“é‰´ç³»ç»Ÿ\",\n        page_icon=\"ğŸ¥ƒ\",\n        layout=\"wide\"\n    )\n\n    # ä¾§è¾¹æ  Agent é€‰æ‹©\n    with st.sidebar:\n        st.header(\"ğŸ¥ƒ å¨å£«å¿Œ AI å“é‰´\")\n\n        # Agent é€‰æ‹©\n        agent_type = st.selectbox(\n            \"é€‰æ‹©å“é‰´ Agent:\",\n            [\"DrunkTony (ä¸­æ–‡)\", \"WhiskyFunny (English)\", \"WhiskyNotebook (English)\"],\n            help=\"æ¯ä¸ª Agent éƒ½æœ‰ä¸åŒçš„æ€§æ ¼å’Œæ•°æ®æº\"\n        )\n\n        # æ¨¡å‹é€‰æ‹©\n        model_options = get_model_options(agent_type)\n        selected_model = st.selectbox(\"æ¨¡å‹:\", model_options)\n\n    # ä¸»å†…å®¹åŒºåŸŸ\n    st.header(\"ä¸“ä¸šçš„å¨å£«å¿Œå“é‰´ç¬”è®°ç”Ÿæˆå™¨\")\n\n    # è¾“å…¥éƒ¨åˆ†\n    col1, col2 = st.columns([2, 1])\n    with col1:\n        whisky_name = st.text_input(\n            \"è¾“å…¥å¨å£«å¿Œåç§°:\",\n            placeholder=\"ä¾‹å¦‚: Macallan 18 Year Old\",\n            help=\"è¾“å…¥å®Œæ•´çš„å¨å£«å¿Œåç§°ï¼ŒåŒ…æ‹¬å¹´ä»½å’Œæ¡¶å‹\"\n        )\n\n    with col2:\n        st.write(\"\")  # é—´è·\n        generate_btn = st.button(\"ğŸ· ç”Ÿæˆå“é‰´ç¬”è®°\", type=\"primary\")\n        recommend_btn = st.button(\"ğŸ¯ è·å–æ¨è\")\n\n    # è¾“å‡ºéƒ¨åˆ†\n    if generate_btn:\n        if not whisky_name:\n            st.error(\"è¯·è¾“å…¥å¨å£«å¿Œåç§°\")\n        else:\n            with st.spinner(\"æ­£åœ¨åˆ†æå¨å£«å¿Œ...\"):\n                tasting_notes = generate_tasting_notes(whisky_name, agent_type, selected_model)\n                st.markdown(\"### ğŸ¥ƒ å“é‰´ç¬”è®°\")\n                st.markdown(tasting_notes)\n\n    if recommend_btn:\n        with st.spinner(\"æ­£åœ¨æŸ¥æ‰¾æ¨è...\"):\n            recommendations = get_recommendations(tasting_notes, agent_type)\n            st.markdown(\"### ğŸ¯ ä¸ªæ€§åŒ–æ¨è\")\n            st.markdown(recommendations)\n\n\n\n\n\n\n\n\n\n\nCode\n# é¢‘ç‡é™åˆ¶å®ç°\nRATE_LIMIT_FILE = \"rate_limit.json\"\nMAX_RUNS_PER_DAY = 80\n\ndef get_rate_limit_data():\n    \"\"\"è·å–å½“å‰ä½¿ç”¨æ•°æ®\"\"\"\n    try:\n        with open(RATE_LIMIT_FILE, \"r\") as f:\n            data = json.load(f)\n            # ç¡®ä¿é”®å­˜åœ¨\n            if \"date\" not in data or \"count\" not in data:\n                return {\"date\": str(datetime.date.today()), \"count\": 0}\n            return data\n    except (FileNotFoundError, json.JSONDecodeError):\n        return {\"date\": str(datetime.date.today()), \"count\": 0}\n\ndef check_rate_limit():\n    \"\"\"æ£€æŸ¥ç”¨æˆ·æ˜¯å¦è¶…å‡ºäº†æ¯æ—¥é™åˆ¶\"\"\"\n    data = get_rate_limit_data()\n    today = str(datetime.date.today())\n\n    if data[\"date\"] != today:\n        # ä¸ºæ–°çš„ä¸€å¤©é‡ç½®è®¡æ•°å™¨\n        return {\"date\": today, \"count\": 0, \"can_run\": True}\n\n    if data[\"count\"] &gt;= MAX_RUNS_PER_DAY:\n        return {\"date\": today, \"count\": data[\"count\"], \"can_run\": False}\n\n    return {\"date\": today, \"count\": data[\"count\"], \"can_run\": True}\n\n\n\n\n\n\n\n\n\n\nCode\n# é’ˆå¯¹å¤§æ•°æ®çš„åˆ†æ‰¹ä¼˜åŒ–ç›¸ä¼¼åº¦æœç´¢\ndef batch_similarity_search(query_embedding, db_path, table_name, batch_size=1000):\n    \"\"\"é’ˆå¯¹å¤§å‹æ•°æ®é›†çš„åˆ†æ‰¹ç›¸ä¼¼åº¦æœç´¢ä¼˜åŒ–\"\"\"\n\n    with duckdb.connect(database=db_path, read_only=True) as con:\n        # è·å–æ€»è¡Œæ•°\n        total_rows = con.execute(f\"SELECT COUNT(*) FROM {table_name}\").fetchone()[0]\n\n        all_similarities = []\n\n        # åˆ†æ‰¹å¤„ç†ä»¥ç®¡ç†å†…å­˜\n        for offset in range(0, total_rows, batch_size):\n            batch_df = con.execute(\n                f'SELECT full, bottle_embedding FROM {table_name} LIMIT {batch_size} OFFSET {offset}'\n            ).fetchdf()\n\n            # è®¡ç®—è¯¥æ‰¹æ¬¡çš„ç›¸ä¼¼åº¦\n            for _, row in batch_df.iterrows():\n                embedding = np.array(row['bottle_embedding'])\n                similarity = cosine_similarity(query_embedding, embedding)\n                all_similarities.append((row['full'], similarity))\n\n        # æ’åºå¹¶è¿”å›å‰å‡ æ¡ç»“æœ\n        all_similarities.sort(key=lambda x: x[1], reverse=True)\n        return all_similarities[:10]\n\n\n\n\n\n\n\n\n# .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡\nSILICONFLOW_API_KEY=æ‚¨çš„ SiliconFlow å¯†é’¥\nMODELSCOPE_API_KEY=æ‚¨çš„ ModelScope å¯†é’¥\nGEMINI_API_KEY=æ‚¨çš„ Gemini å¯†é’¥  # å¯é€‰\n\n# æ•°æ®åº“åˆå§‹åŒ–\npython -c \"\nimport duckdb\nconn = duckdb.connect('data/whisky_database.duckdb')\n# åˆ›å»ºæ”¯æŒå‘é‡çš„è¡¨æ ¼\n\"\n\n\n\n\n\nCode\n# ä½¿ç”¨ Shiny å®ç°çš„å¤‡é€‰ UI\nfrom shiny import App, ui, render, reactive, req\n\napp_ui = ui.page_fluid(\n    ui.h2(\"ğŸ¥ƒ AI å¨å£«å¿Œå“é‰´ç³»ç»Ÿ\"),\n    ui.layout_sidebar(\n        ui.sidebar(\n            ui.input_select(\"agent\", \"é€‰æ‹© Agent:\", [\n                \"DrunkTony (ä¸­æ–‡)\", \"WhiskyFunny (English)\", \"WhiskyNotebook (English)\"\n            ]),\n            ui.input_text(\"whisky_name\", \"å¨å£«å¿Œåç§°:\", \"\"),\n            ui.input_action_button(\"generate\", \"ç”Ÿæˆå“é‰´ç¬”è®°\")\n        ),\n        ui.output_text_verbatim(\"tasting_notes\"),\n        ui.output_text_verbatim(\"recommendations\")\n    )\n)\n\ndef server(input, output, session):\n    @output\n    @render.text\n    def tasting_notes():\n        req(input.generate())\n        # ç”Ÿæˆå“é‰´ç¬”è®°é€»è¾‘\n        return generate_tasting_notes(input.whisky_name(), input.agent())\n\napp = App(app_ui, server)\n\n\n\n\n\n\n\n\n\nå¤š Agent æ¶æ„: æ‹¥æœ‰ä¸åŒçš„ AI äººæ ¼å’Œæ•°æ®æºã€‚\nRAG å®ç°: ä½¿ç”¨çœŸå®å¨å£«å¿Œè¯„è®ºè¿›è¡Œæ£€ç´¢å¢å¼ºç”Ÿæˆã€‚\nå‘é‡æ•°æ®åº“: ä½¿ç”¨ 376MB æ•°æ®åº“è¿›è¡Œé«˜æ•ˆç›¸ä¼¼åº¦æœç´¢ã€‚\nåŒè¯­æ”¯æŒ: æä¾›ä¸­æ–‡å’Œè‹±æ–‡ Agentã€‚\næˆæœ¬ç®¡ç†: å†…ç½®é¢‘ç‡é™åˆ¶å’Œ API ä¼˜åŒ–ã€‚\nä¸“ä¸šå“é‰´æ ¼å¼: ç¬¦åˆè¡Œä¸šæ ‡å‡†çš„ç¬”è®°ç»“æ„ã€‚\n\n\n\n\n\n\n\næŒ‡æ ‡\næ•°å€¼\n\n\n\n\næ•°æ®åº“å¤§å°\n376MB (26,000+ æ¡è¯„è®º)\n\n\nåµŒå…¥ç»´åº¦\n1024\n\n\næœç´¢å»¶è¿Ÿ\n&lt; 2 ç§’\n\n\næ¯æ—¥è¯·æ±‚é™åˆ¶\n80 æ¬¡è¯·æ±‚\n\n\næ”¯æŒè¯­è¨€\n2 (EN/ZH)\n\n\næ•°æ®æº\n3 (drinktony, whiskyfun, whiskynotes)\n\n\n\n\n\n\n\nä¸‹ä¸€ç‰ˆæœ¬çš„æ½œåœ¨æ”¹è¿›ç‚¹ï¼š\n\né«˜çº§ç›¸ä¼¼åº¦ç®—æ³•: å®ç°æ–‡æœ¬ + å…ƒæ•°æ®çš„æ··åˆæœç´¢ã€‚\nç”¨æˆ·ä¸ªæ€§åŒ–: éšç€æ—¶é—´æ¨ç§»å­¦ä¹ ç”¨æˆ·çš„åå¥½ã€‚\nç§»åŠ¨ç«¯åº”ç”¨: åŸç”Ÿçš„ iOS/Android åº”ç”¨ç¨‹åºã€‚\nå®æ—¶æ•°æ®æ›´æ–°: è‡ªåŠ¨åŒ–çš„ç½‘é¡µæŠ“å–æµæ°´çº¿ã€‚\nå£å‘³ç‰¹å¾åˆ†æ: æ ¹æ®ç”¨æˆ·åå¥½ç”Ÿæˆå…¶å£å‘³ç‰¹å¾å›¾è°±ã€‚\nç¤¾äº¤åŠŸèƒ½: ä¸ç¤¾åŒºåˆ†äº«å“é‰´ç¬”è®°å’Œæ¨èã€‚\n\n\n\n\nè¿™æ¬¾å¨å£«å¿Œå“é‰´åº”ç”¨å±•ç¤ºäº†å°† RAG æŠ€æœ¯ä¸ä¸“é—¨çš„ AI Agent ç›¸ç»“åˆï¼Œä»è€Œæ„å»ºå¤æ‚çš„é¢†åŸŸç‰¹å®šç³»ç»Ÿçš„å¼ºå¤§åŠ›é‡ã€‚æœ¬é¡¹ç›®å±•ç¤ºäº†ï¼š\n\nå…ˆè¿›çš„ AI æ¶æ„: å…·å¤‡ä¸åŒäººæ ¼çš„å¤š Agent ç³»ç»Ÿã€‚\næ•°æ®å·¥ç¨‹: å¤§è§„æ¨¡å‘é‡æ•°æ®åº“ç®¡ç†ã€‚\nä¸“ä¸šçŸ¥è¯†: è¡Œä¸šæ ‡å‡†çš„å“é‰´ç¬”è®°æ ¼å¼ã€‚\nç”¨æˆ·ä½“éªŒ: è·¨å¹³å°çš„ç®€æ´ã€ç›´è§‚ç•Œé¢ã€‚\næˆæœ¬æ•ˆç›Š: æ™ºèƒ½çš„é¢‘ç‡é™åˆ¶å’Œä¼˜åŒ–ã€‚\n\næ— è®ºæ‚¨æ˜¯å¨å£«å¿Œçˆ±å¥½è€…ã€AI å¼€å‘äººå‘˜è¿˜æ˜¯æ•°æ®ç§‘å­¦å®¶ï¼Œæœ¬é¡¹ç›®éƒ½ä¸ºæ‚¨æä¾›äº†ä¸€ä¸ªæä½³çš„èŒƒä¾‹ï¼Œå±•ç¤ºäº†å¦‚ä½•ç»“åˆçœŸå®ä¸–ç•Œæ•°æ®ä¸å…ˆè¿›æœºå™¨å­¦ä¹ æŠ€æœ¯æ¥æ„å»ºç”Ÿäº§çº§ AI åº”ç”¨ã€‚\n\næŠ€æœ¯æ ˆ: Python, Streamlit, DuckDB, OpenAI API, å‘é‡åµŒå…¥ (Vector Embeddings)\næ•°æ®åº“: æ¶µç›– 3 ä¸ªä¸“é—¨æ¥æºçš„ 26,000+ æ¡çœŸå®å¨å£«å¿Œè¯„è®ºã€‚"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#æ ¸å¿ƒæ¶æ„",
    "href": "posts/whisky-tasting/index.html#æ ¸å¿ƒæ¶æ„",
    "title": "åŸºäº RAG çš„å¨å£«å¿Œå“é‰´ç¬”è®°",
    "section": "",
    "text": "è¯¥åº”ç”¨åŒ…å«ä¸‰ä¸ªä¸“é—¨çš„ AI Agentï¼Œæ¯ä¸ª Agent éƒ½æœ‰ç‹¬ç‰¹çš„ç‰¹å¾å’Œæ•°æ®æºï¼š\n\nDrunkTony (dt) - ä¸­æ–‡ Agentï¼Œä¸“æ³¨äºä¸­æ–‡å¨å£«å¿Œè¯„è®ºã€‚\nWhiskyFunny (wf) - è‹±æ–‡ Agentï¼Œæ•°æ®æºè‡ª whiskyfun.comã€‚\nWhiskyNotebook (wn) - è‹±æ–‡ Agentï¼Œæ•°æ®æºè‡ª whiskynotes.beã€‚\n\n\n\n\n\nä¸»è¦è¯­è¨€: Python 3.13+\nWeb æ¡†æ¶: Streamlit (ä¸»é€‰) + Shiny for Python (å¤‡é€‰)\næ•°æ®åº“: DuckDB (376MBï¼Œé’ˆå¯¹å‘é‡æ“ä½œè¿›è¡Œäº†ä¼˜åŒ–)\nAI/ML: OpenAI API, å‘é‡åµŒå…¥ (Vector embeddings), RAG ç³»ç»Ÿ\næ•°æ®æº: ä½¿ç”¨ BeautifulSoup4 è¿›è¡Œç½‘é¡µæŠ“å–"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#æ•°æ®åº“æ¶æ„",
    "href": "posts/whisky-tasting/index.html#æ•°æ®åº“æ¶æ„",
    "title": "åŸºäº RAG çš„å¨å£«å¿Œå“é‰´ç¬”è®°",
    "section": "",
    "text": "ç³»ç»Ÿä½¿ç”¨ DuckDB ä½œä¸ºä¸»æ•°æ®åº“ï¼Œå› å…¶åœ¨å‘é‡æ“ä½œæ–¹é¢è¡¨ç°å“è¶Šï¼š\n-- æ•°æ®åº“ç»“æ„\nCREATE TABLE drinktony_embed (\n    full TEXT,\n    bottle_embedding FLOAT[1024]  -- 1024 ç»´å‘é‡\n);\n\nCREATE TABLE whiskyfun_embed (\n    full TEXT,\n    bottle_embedding FLOAT[1024]\n);\n\nCREATE TABLE whiskynote_embed (\n    full TEXT,\n    bottle_embedding FLOAT[1024]\n);\n\n\n\n\n\nCode\n# get_data_dt.py ä¸­çš„ç½‘é¡µæŠ“å–ç¤ºä¾‹\ndef scrape_drinktony_reviews():\n    \"\"\"ä» drinktony.netlify.app æŠ“å–ä¸­æ–‡å¨å£«å¿Œè¯„è®º\"\"\"\n    url = \"https://drinktony.netlify.app/\"\n    response = requests.get(url)\n    soup = BeautifulSoup(response.content, \"html.parser\")\n\n    # æŸ¥æ‰¾æ‰€æœ‰è¯„è®ºé“¾æ¥\n    post_links = [urljoin(url, a.get(\"href\"))\n                 for a in soup.select(\"a.quarto-grid-link\")]\n\n    all_reviews = []\n    for post_url in post_links:\n        response = requests.get(post_url)\n        soup = BeautifulSoup(response.content, \"html.parser\")\n\n        # æå–è¯„è®ºç« èŠ‚\n        review_sections = soup.select(\"section.level1\")\n        for section in review_sections:\n            # è§£æå¨å£«å¿Œåç§°å’Œè¯„è®ºå†…å®¹\n            whisky_name = extract_whisky_name(section)\n            review_text = extract_review_text(section)\n            all_reviews.append({\n                'whisky': whisky_name,\n                'review': review_text\n            })\n\n    return all_reviews"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#aiml-å®ç°",
    "href": "posts/whisky-tasting/index.html#aiml-å®ç°",
    "title": "åŸºäº RAG çš„å¨å£«å¿Œå“é‰´ç¬”è®°",
    "section": "",
    "text": "åº”ç”¨ä½¿ç”¨å°–ç«¯çš„åµŒå…¥æŠ€æœ¯å°†æ–‡æœ¬è½¬æ¢ä¸ºé«˜ç»´å‘é‡ï¼Œä»¥ä¾¿è¿›è¡Œè¯­ä¹‰ç›¸ä¼¼åº¦æœç´¢ã€‚\n\n\næ¨¡å‹: BAAI/bge-large-zh-v1.5 - ç»´åº¦: 1024 - æœåŠ¡å•†: SiliconFlow API - ç”¨é€”: è·¨è¯­è¨€æ–‡æœ¬ç†è§£ï¼ˆåœ¨ä¸­è‹±æ–‡æ–¹é¢è¡¨ç°å‡å¾ˆå‡ºè‰²ï¼‰\n\n\n\n\nè·¨è¯­è¨€èƒ½åŠ›: åœ¨ç†è§£ä¸­è‹±æ–‡å¨å£«å¿Œä¸“ä¸šæœ¯è¯­æ–¹é¢è¡¨ç°ä¼˜å¼‚ã€‚\né«˜æ€§èƒ½: ä¸é€šç”¨åµŒå…¥æ¨¡å‹ç›¸æ¯”ï¼Œå…·å¤‡æ›´å‡ºè‰²çš„è¯­ä¹‰ç†è§£èƒ½åŠ›ã€‚\né«˜æ•ˆå°ºå¯¸: 1024 ç»´åº¦åœ¨æ€§èƒ½å’Œå­˜å‚¨æ•ˆç‡ä¹‹é—´è¾¾åˆ°äº†å¹³è¡¡ã€‚\nAPI è®¿é—®: é€šè¿‡ SiliconFlow æä¾›ç¨³å®šçš„æœåŠ¡ã€‚\n\n\n\n\nè¯¥åº”ç”¨ä½¿ç”¨ BGE-Large-ZH-v1.5 æ¨¡å‹ç”ŸæˆåµŒå…¥å‘é‡ï¼š\n\n\nCode\ndef get_embedding(text: str, api_key: str):\n    \"\"\"ä½¿ç”¨ SiliconFlow API ç”Ÿæˆæ–‡æœ¬åµŒå…¥\"\"\"\n    client = OpenAI(\n        api_key=api_key,\n        base_url=\"https://api.siliconflow.cn/v1\"\n    )\n    response = client.embeddings.create(\n        model=\"BAAI/bge-large-zh-v1.5\",\n        input=[text]\n    )\n    return np.array(response.data[0].embedding)\n\ndef cosine_similarity(v1, v2):\n    \"\"\"è®¡ç®—ä¸¤ä¸ªå‘é‡ä¹‹é—´çš„ä½™å¼¦ç›¸ä¼¼åº¦\"\"\"\n    if v1 is None or v2 is None:\n        return 0\n    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))\n\n\n\n\n\n\næ£€ç´¢å¢å¼ºç”Ÿæˆ (RAG) ç³»ç»Ÿæ˜¯æ­¤åº”ç”¨çš„æ ¸å¿ƒåˆ›æ–°ã€‚è®©æˆ‘ä»¬è¯¦ç»†æ¢è®¨å…¶ç»„ä»¶ã€‚\n\n\n\næ£€ç´¢å¢å¼ºç”Ÿæˆè¿‡ç¨‹éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š\n%%| fig-cap: \"å¨å£«å¿Œå“é‰´çš„ RAG å·¥ä½œæµ\"\nflowchart TD\n    A[ç”¨æˆ·è¾“å…¥&lt;br/&gt;å¨å£«å¿Œåç§°] --&gt; B[ç”ŸæˆåµŒå…¥å‘é‡]\n    B --&gt; C[DuckDB ä¸­çš„&lt;br/&gt;å‘é‡ç›¸ä¼¼åº¦æœç´¢]\n    C --&gt; D[æ£€ç´¢å‰ 10 æ¡&lt;br/&gt;ç›¸ä¼¼è¯„è®º]\n    D --&gt; E[ä¸º LLM æ ¼å¼åŒ–ä¸Šä¸‹æ–‡]\n    E --&gt; F[ä¸» LLM&lt;br/&gt;ç”Ÿæˆå“é‰´ç¬”è®°]\n    F --&gt; G[å‰¯ LLM&lt;br/&gt;ç”Ÿæˆæ¨èå»ºè®®]\n    G --&gt; H[æ ¼å¼åŒ–å¹¶&lt;br/&gt;æ˜¾ç¤ºç»“æœ]\n\n    C --&gt; I[æ•°æ®åº“]\n    I --&gt; J[drinktony_embed&lt;br/&gt;1200 æ¡ä¸­æ–‡è¯„è®º]\n    I --&gt; K[whiskyfun_embed&lt;br/&gt;2 ä¸‡æ¡è‹±æ–‡è¯„è®º]\n    I --&gt; L[whiskynote_embed&lt;br/&gt;5000 æ¡è‹±æ–‡è¯„è®º]\n\n\n\n\n\nCode\ndef find_similar_chunks(\n    query_embedding,\n    db_path,\n    table_name,\n    text_col,\n    embedding_col,\n    top_n=10,\n):\n    \"\"\"ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦åœ¨æ•°æ®åº“ä¸­æŸ¥æ‰¾æœ€ç›¸ä¼¼çš„æ–‡æœ¬å—\"\"\"\n    try:\n        with duckdb.connect(database=db_path, read_only=True) as con:\n            df = con.execute(\n                f'SELECT \"{text_col}\", \"{embedding_col}\" FROM \"{table_name}\"'\n            ).fetchdf()\n\n            # è®¡ç®—ç›¸ä¼¼åº¦\n            similarities = []\n            for _, row in df.iterrows():\n                text = row[text_col]\n                embedding = np.array(row[embedding_col])\n                similarity = cosine_similarity(query_embedding, embedding)\n                similarities.append((text, similarity))\n\n            # æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶è¿”å›å‰ N æ¡\n            similarities.sort(key=lambda x: x[1], reverse=True)\n            return similarities[:top_n]\n\n    except Exception as e:\n        print(f\"æœç´¢ç›¸ä¼¼å—æ—¶å‡ºé”™: {e}\")\n        return []"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#ä¸“é—¨-agent-çš„å®ç°",
    "href": "posts/whisky-tasting/index.html#ä¸“é—¨-agent-çš„å®ç°",
    "title": "åŸºäº RAG çš„å¨å£«å¿Œå“é‰´ç¬”è®°",
    "section": "",
    "text": "Code\ndef run_conversation(query, api_key, model):\n    \"\"\"ç”Ÿæˆä¸­æ–‡æ ¼å¼çš„å¨å£«å¿Œå“é‰´ç¬”è®°\"\"\"\n\n    # ç¬¬ 1 æ­¥ï¼šç”ŸæˆåµŒå…¥å¹¶æŸ¥æ‰¾ç›¸ä¼¼è¯„è®º\n    query_embedding = get_embedding(query, api_key)\n    similar_reviews = find_similar_chunks(\n        query_embedding=query_embedding,\n        db_path=\"data/whisky_database.duckdb\",\n        table_name=\"drinktony_embed\",\n        text_col=\"full\",\n        embedding_col=\"bottle_embedding\"\n    )\n\n    # ç¬¬ 2 æ­¥ï¼šä¸º LLM å‡†å¤‡ä¸Šä¸‹æ–‡\n    context = \"\\n---\\n\".join([review[0] for review in similar_reviews])\n\n    # ç¬¬ 3 æ­¥ï¼šç”Ÿæˆå“é‰´ç¬”è®°\n    prompt = f\"\"\"ä½œä¸ºå¨å£«å¿Œä¸“å®¶ï¼ŒåŸºäºä»¥ä¸‹å¨å£«å¿Œå“é‰´ç¬”è®°ï¼Œä¸º\"{query}\"ç”Ÿæˆä¸“ä¸šçš„å“é‰´æŠ¥å‘Šï¼š\n\nå‚è€ƒå“é‰´ç¬”è®°ï¼š\n{context}\n\nè¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š\n{query}\né—»é¦™: [è¯¦ç»†æè¿°]\nå“å‘³: [è¯¦ç»†æè¿°]\næ‰“åˆ†: [90-100åˆ†]\n\"\"\"\n\n    response = llm_client.chat.completions.create(\n        model=model,\n        messages=[\n            {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¨å£«å¿Œå“é‰´å¸ˆï¼Œæ“…é•¿ç”Ÿæˆè¯¦ç»†å‡†ç¡®çš„å“é‰´ç¬”è®°ã€‚\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        temperature=0.7,\n        max_tokens=1000\n    )\n\n    return response.choices[0].message.content\n\n\n\n\n\n\n\nCode\ndef run_conversation(query, api_key, model):\n    \"\"\"ç”Ÿæˆè‹±æ–‡æ ¼å¼çš„å¨å£«å¿Œå“é‰´ç¬”è®°\"\"\"\n\n    query_embedding = get_embedding(query, api_key)\n    similar_reviews = find_similar_chunks(\n        query_embedding=query_embedding,\n        db_path=\"data/whisky_database.duckdb\",\n        table_name=\"whiskyfun_embed\",\n        text_col=\"full\",\n        embedding_col=\"bottle_embedding\"\n    )\n\n    context = \"\\n---\\n\".join([review[0] for review in similar_reviews])\n\n    prompt = f\"\"\"As a whisky expert, generate professional tasting notes for \"{query}\" based on these reference reviews:\n\nReference reviews:\n{context}\n\nPlease output in this format:\nColour: [detailed description]\nNose: [detailed aroma description]\nMouth: [detailed taste description]\nFinish: [detailed finish description]\nComments: [overall impression]\nSGP: xxx - xx points\n\"\"\"\n\n    response = llm_client.chat.completions.create(\n        model=model,\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a professional whisky taster specializing in detailed sensory analysis.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        temperature=0.7,\n        max_tokens=1200\n    )\n\n    return response.choices[0].message.content"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#æ¨èå¼•æ“",
    "href": "posts/whisky-tasting/index.html#æ¨èå¼•æ“",
    "title": "åŸºäº RAG çš„å¨å£«å¿Œå“é‰´ç¬”è®°",
    "section": "",
    "text": "åº”ç”¨ä½¿ç”¨ä¸€ä¸ªç‹¬ç«‹çš„ LLM æ¥ç”Ÿæˆå¨å£«å¿Œæ¨èå»ºè®®ï¼š\n\n\nCode\ndef recommend_whiskies_by_profile(tasting_notes, api_key, model):\n    \"\"\"åŸºäºå“é‰´ç‰¹å¾ç”Ÿæˆå¨å£«å¿Œæ¨è\"\"\"\n\n    prompt = f\"\"\"Based on these tasting notes, recommend 2 similar whiskies that the user might enjoy:\n\n{Tasting Notes:}\n{tasting_notes}\n\nPlease provide:\n1. Whisky name with brief description\n2. Why it matches the user's preference\n3. Price range and availability\n\nFormat each recommendation as:\n**Recommendation [1/2]:** [Whisky Name]\n**Why it matches:** [detailed reasoning]\n**Details:** [price, availability, tasting profile]\n\"\"\"\n\n    response = recommendation_client.chat.completions.create(\n        model=model,  # æ¨èä½¿ç”¨ä¸åŒçš„æ¨¡å‹\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a whisky recommendation expert with deep knowledge of global whisky brands and profiles.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        temperature=0.8,\n        max_tokens=800\n    )\n\n    return response.choices[0].message.content"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#ç”¨æˆ·ç•Œé¢è®¾è®¡",
    "href": "posts/whisky-tasting/index.html#ç”¨æˆ·ç•Œé¢è®¾è®¡",
    "title": "åŸºäº RAG çš„å¨å£«å¿Œå“é‰´ç¬”è®°",
    "section": "",
    "text": "Code\n# ä¸»åº”ç”¨ç¨‹åºç•Œé¢\ndef main():\n    st.set_page_config(\n        page_title=\"AI å¨å£«å¿Œå“é‰´ç³»ç»Ÿ\",\n        page_icon=\"ğŸ¥ƒ\",\n        layout=\"wide\"\n    )\n\n    # ä¾§è¾¹æ  Agent é€‰æ‹©\n    with st.sidebar:\n        st.header(\"ğŸ¥ƒ å¨å£«å¿Œ AI å“é‰´\")\n\n        # Agent é€‰æ‹©\n        agent_type = st.selectbox(\n            \"é€‰æ‹©å“é‰´ Agent:\",\n            [\"DrunkTony (ä¸­æ–‡)\", \"WhiskyFunny (English)\", \"WhiskyNotebook (English)\"],\n            help=\"æ¯ä¸ª Agent éƒ½æœ‰ä¸åŒçš„æ€§æ ¼å’Œæ•°æ®æº\"\n        )\n\n        # æ¨¡å‹é€‰æ‹©\n        model_options = get_model_options(agent_type)\n        selected_model = st.selectbox(\"æ¨¡å‹:\", model_options)\n\n    # ä¸»å†…å®¹åŒºåŸŸ\n    st.header(\"ä¸“ä¸šçš„å¨å£«å¿Œå“é‰´ç¬”è®°ç”Ÿæˆå™¨\")\n\n    # è¾“å…¥éƒ¨åˆ†\n    col1, col2 = st.columns([2, 1])\n    with col1:\n        whisky_name = st.text_input(\n            \"è¾“å…¥å¨å£«å¿Œåç§°:\",\n            placeholder=\"ä¾‹å¦‚: Macallan 18 Year Old\",\n            help=\"è¾“å…¥å®Œæ•´çš„å¨å£«å¿Œåç§°ï¼ŒåŒ…æ‹¬å¹´ä»½å’Œæ¡¶å‹\"\n        )\n\n    with col2:\n        st.write(\"\")  # é—´è·\n        generate_btn = st.button(\"ğŸ· ç”Ÿæˆå“é‰´ç¬”è®°\", type=\"primary\")\n        recommend_btn = st.button(\"ğŸ¯ è·å–æ¨è\")\n\n    # è¾“å‡ºéƒ¨åˆ†\n    if generate_btn:\n        if not whisky_name:\n            st.error(\"è¯·è¾“å…¥å¨å£«å¿Œåç§°\")\n        else:\n            with st.spinner(\"æ­£åœ¨åˆ†æå¨å£«å¿Œ...\"):\n                tasting_notes = generate_tasting_notes(whisky_name, agent_type, selected_model)\n                st.markdown(\"### ğŸ¥ƒ å“é‰´ç¬”è®°\")\n                st.markdown(tasting_notes)\n\n    if recommend_btn:\n        with st.spinner(\"æ­£åœ¨æŸ¥æ‰¾æ¨è...\"):\n            recommendations = get_recommendations(tasting_notes, agent_type)\n            st.markdown(\"### ğŸ¯ ä¸ªæ€§åŒ–æ¨è\")\n            st.markdown(recommendations)"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#é¢‘ç‡é™åˆ¶ä¸æˆæœ¬ç®¡ç†",
    "href": "posts/whisky-tasting/index.html#é¢‘ç‡é™åˆ¶ä¸æˆæœ¬ç®¡ç†",
    "title": "åŸºäº RAG çš„å¨å£«å¿Œå“é‰´ç¬”è®°",
    "section": "",
    "text": "Code\n# é¢‘ç‡é™åˆ¶å®ç°\nRATE_LIMIT_FILE = \"rate_limit.json\"\nMAX_RUNS_PER_DAY = 80\n\ndef get_rate_limit_data():\n    \"\"\"è·å–å½“å‰ä½¿ç”¨æ•°æ®\"\"\"\n    try:\n        with open(RATE_LIMIT_FILE, \"r\") as f:\n            data = json.load(f)\n            # ç¡®ä¿é”®å­˜åœ¨\n            if \"date\" not in data or \"count\" not in data:\n                return {\"date\": str(datetime.date.today()), \"count\": 0}\n            return data\n    except (FileNotFoundError, json.JSONDecodeError):\n        return {\"date\": str(datetime.date.today()), \"count\": 0}\n\ndef check_rate_limit():\n    \"\"\"æ£€æŸ¥ç”¨æˆ·æ˜¯å¦è¶…å‡ºäº†æ¯æ—¥é™åˆ¶\"\"\"\n    data = get_rate_limit_data()\n    today = str(datetime.date.today())\n\n    if data[\"date\"] != today:\n        # ä¸ºæ–°çš„ä¸€å¤©é‡ç½®è®¡æ•°å™¨\n        return {\"date\": today, \"count\": 0, \"can_run\": True}\n\n    if data[\"count\"] &gt;= MAX_RUNS_PER_DAY:\n        return {\"date\": today, \"count\": data[\"count\"], \"can_run\": False}\n\n    return {\"date\": today, \"count\": data[\"count\"], \"can_run\": True}"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#æ€§èƒ½ä¼˜åŒ–",
    "href": "posts/whisky-tasting/index.html#æ€§èƒ½ä¼˜åŒ–",
    "title": "åŸºäº RAG çš„å¨å£«å¿Œå“é‰´ç¬”è®°",
    "section": "",
    "text": "Code\n# é’ˆå¯¹å¤§æ•°æ®çš„åˆ†æ‰¹ä¼˜åŒ–ç›¸ä¼¼åº¦æœç´¢\ndef batch_similarity_search(query_embedding, db_path, table_name, batch_size=1000):\n    \"\"\"é’ˆå¯¹å¤§å‹æ•°æ®é›†çš„åˆ†æ‰¹ç›¸ä¼¼åº¦æœç´¢ä¼˜åŒ–\"\"\"\n\n    with duckdb.connect(database=db_path, read_only=True) as con:\n        # è·å–æ€»è¡Œæ•°\n        total_rows = con.execute(f\"SELECT COUNT(*) FROM {table_name}\").fetchone()[0]\n\n        all_similarities = []\n\n        # åˆ†æ‰¹å¤„ç†ä»¥ç®¡ç†å†…å­˜\n        for offset in range(0, total_rows, batch_size):\n            batch_df = con.execute(\n                f'SELECT full, bottle_embedding FROM {table_name} LIMIT {batch_size} OFFSET {offset}'\n            ).fetchdf()\n\n            # è®¡ç®—è¯¥æ‰¹æ¬¡çš„ç›¸ä¼¼åº¦\n            for _, row in batch_df.iterrows():\n                embedding = np.array(row['bottle_embedding'])\n                similarity = cosine_similarity(query_embedding, embedding)\n                all_similarities.append((row['full'], similarity))\n\n        # æ’åºå¹¶è¿”å›å‰å‡ æ¡ç»“æœ\n        all_similarities.sort(key=lambda x: x[1], reverse=True)\n        return all_similarities[:10]"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#éƒ¨ç½²ä¸é…ç½®",
    "href": "posts/whisky-tasting/index.html#éƒ¨ç½²ä¸é…ç½®",
    "title": "åŸºäº RAG çš„å¨å£«å¿Œå“é‰´ç¬”è®°",
    "section": "",
    "text": "# .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡\nSILICONFLOW_API_KEY=æ‚¨çš„ SiliconFlow å¯†é’¥\nMODELSCOPE_API_KEY=æ‚¨çš„ ModelScope å¯†é’¥\nGEMINI_API_KEY=æ‚¨çš„ Gemini å¯†é’¥  # å¯é€‰\n\n# æ•°æ®åº“åˆå§‹åŒ–\npython -c \"\nimport duckdb\nconn = duckdb.connect('data/whisky_database.duckdb')\n# åˆ›å»ºæ”¯æŒå‘é‡çš„è¡¨æ ¼\n\"\n\n\n\n\n\nCode\n# ä½¿ç”¨ Shiny å®ç°çš„å¤‡é€‰ UI\nfrom shiny import App, ui, render, reactive, req\n\napp_ui = ui.page_fluid(\n    ui.h2(\"ğŸ¥ƒ AI å¨å£«å¿Œå“é‰´ç³»ç»Ÿ\"),\n    ui.layout_sidebar(\n        ui.sidebar(\n            ui.input_select(\"agent\", \"é€‰æ‹© Agent:\", [\n                \"DrunkTony (ä¸­æ–‡)\", \"WhiskyFunny (English)\", \"WhiskyNotebook (English)\"\n            ]),\n            ui.input_text(\"whisky_name\", \"å¨å£«å¿Œåç§°:\", \"\"),\n            ui.input_action_button(\"generate\", \"ç”Ÿæˆå“é‰´ç¬”è®°\")\n        ),\n        ui.output_text_verbatim(\"tasting_notes\"),\n        ui.output_text_verbatim(\"recommendations\")\n    )\n)\n\ndef server(input, output, session):\n    @output\n    @render.text\n    def tasting_notes():\n        req(input.generate())\n        # ç”Ÿæˆå“é‰´ç¬”è®°é€»è¾‘\n        return generate_tasting_notes(input.whisky_name(), input.agent())\n\napp = App(app_ui, server)"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#æŠ€æœ¯æˆå°±",
    "href": "posts/whisky-tasting/index.html#æŠ€æœ¯æˆå°±",
    "title": "åŸºäº RAG çš„å¨å£«å¿Œå“é‰´ç¬”è®°",
    "section": "",
    "text": "å¤š Agent æ¶æ„: æ‹¥æœ‰ä¸åŒçš„ AI äººæ ¼å’Œæ•°æ®æºã€‚\nRAG å®ç°: ä½¿ç”¨çœŸå®å¨å£«å¿Œè¯„è®ºè¿›è¡Œæ£€ç´¢å¢å¼ºç”Ÿæˆã€‚\nå‘é‡æ•°æ®åº“: ä½¿ç”¨ 376MB æ•°æ®åº“è¿›è¡Œé«˜æ•ˆç›¸ä¼¼åº¦æœç´¢ã€‚\nåŒè¯­æ”¯æŒ: æä¾›ä¸­æ–‡å’Œè‹±æ–‡ Agentã€‚\næˆæœ¬ç®¡ç†: å†…ç½®é¢‘ç‡é™åˆ¶å’Œ API ä¼˜åŒ–ã€‚\nä¸“ä¸šå“é‰´æ ¼å¼: ç¬¦åˆè¡Œä¸šæ ‡å‡†çš„ç¬”è®°ç»“æ„ã€‚\n\n\n\n\n\n\n\næŒ‡æ ‡\næ•°å€¼\n\n\n\n\næ•°æ®åº“å¤§å°\n376MB (26,000+ æ¡è¯„è®º)\n\n\nåµŒå…¥ç»´åº¦\n1024\n\n\næœç´¢å»¶è¿Ÿ\n&lt; 2 ç§’\n\n\næ¯æ—¥è¯·æ±‚é™åˆ¶\n80 æ¬¡è¯·æ±‚\n\n\næ”¯æŒè¯­è¨€\n2 (EN/ZH)\n\n\næ•°æ®æº\n3 (drinktony, whiskyfun, whiskynotes)"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#æœªæ¥å¢å¼ºæ–¹å‘",
    "href": "posts/whisky-tasting/index.html#æœªæ¥å¢å¼ºæ–¹å‘",
    "title": "åŸºäº RAG çš„å¨å£«å¿Œå“é‰´ç¬”è®°",
    "section": "",
    "text": "ä¸‹ä¸€ç‰ˆæœ¬çš„æ½œåœ¨æ”¹è¿›ç‚¹ï¼š\n\né«˜çº§ç›¸ä¼¼åº¦ç®—æ³•: å®ç°æ–‡æœ¬ + å…ƒæ•°æ®çš„æ··åˆæœç´¢ã€‚\nç”¨æˆ·ä¸ªæ€§åŒ–: éšç€æ—¶é—´æ¨ç§»å­¦ä¹ ç”¨æˆ·çš„åå¥½ã€‚\nç§»åŠ¨ç«¯åº”ç”¨: åŸç”Ÿçš„ iOS/Android åº”ç”¨ç¨‹åºã€‚\nå®æ—¶æ•°æ®æ›´æ–°: è‡ªåŠ¨åŒ–çš„ç½‘é¡µæŠ“å–æµæ°´çº¿ã€‚\nå£å‘³ç‰¹å¾åˆ†æ: æ ¹æ®ç”¨æˆ·åå¥½ç”Ÿæˆå…¶å£å‘³ç‰¹å¾å›¾è°±ã€‚\nç¤¾äº¤åŠŸèƒ½: ä¸ç¤¾åŒºåˆ†äº«å“é‰´ç¬”è®°å’Œæ¨èã€‚"
  },
  {
    "objectID": "posts/whisky-tasting/index.html#ç»“è®º",
    "href": "posts/whisky-tasting/index.html#ç»“è®º",
    "title": "åŸºäº RAG çš„å¨å£«å¿Œå“é‰´ç¬”è®°",
    "section": "",
    "text": "è¿™æ¬¾å¨å£«å¿Œå“é‰´åº”ç”¨å±•ç¤ºäº†å°† RAG æŠ€æœ¯ä¸ä¸“é—¨çš„ AI Agent ç›¸ç»“åˆï¼Œä»è€Œæ„å»ºå¤æ‚çš„é¢†åŸŸç‰¹å®šç³»ç»Ÿçš„å¼ºå¤§åŠ›é‡ã€‚æœ¬é¡¹ç›®å±•ç¤ºäº†ï¼š\n\nå…ˆè¿›çš„ AI æ¶æ„: å…·å¤‡ä¸åŒäººæ ¼çš„å¤š Agent ç³»ç»Ÿã€‚\næ•°æ®å·¥ç¨‹: å¤§è§„æ¨¡å‘é‡æ•°æ®åº“ç®¡ç†ã€‚\nä¸“ä¸šçŸ¥è¯†: è¡Œä¸šæ ‡å‡†çš„å“é‰´ç¬”è®°æ ¼å¼ã€‚\nç”¨æˆ·ä½“éªŒ: è·¨å¹³å°çš„ç®€æ´ã€ç›´è§‚ç•Œé¢ã€‚\næˆæœ¬æ•ˆç›Š: æ™ºèƒ½çš„é¢‘ç‡é™åˆ¶å’Œä¼˜åŒ–ã€‚\n\næ— è®ºæ‚¨æ˜¯å¨å£«å¿Œçˆ±å¥½è€…ã€AI å¼€å‘äººå‘˜è¿˜æ˜¯æ•°æ®ç§‘å­¦å®¶ï¼Œæœ¬é¡¹ç›®éƒ½ä¸ºæ‚¨æä¾›äº†ä¸€ä¸ªæä½³çš„èŒƒä¾‹ï¼Œå±•ç¤ºäº†å¦‚ä½•ç»“åˆçœŸå®ä¸–ç•Œæ•°æ®ä¸å…ˆè¿›æœºå™¨å­¦ä¹ æŠ€æœ¯æ¥æ„å»ºç”Ÿäº§çº§ AI åº”ç”¨ã€‚\n\næŠ€æœ¯æ ˆ: Python, Streamlit, DuckDB, OpenAI API, å‘é‡åµŒå…¥ (Vector Embeddings)\næ•°æ®åº“: æ¶µç›– 3 ä¸ªä¸“é—¨æ¥æºçš„ 26,000+ æ¡çœŸå®å¨å£«å¿Œè¯„è®ºã€‚"
  },
  {
    "objectID": "posts/AI-Chat/index.html",
    "href": "posts/AI-Chat/index.html",
    "title": "AI èŠå¤©ï¼šå¤šè¯­è¨€å¤šæ¨¡å‹åº”ç”¨ (AI Chat)",
    "section": "",
    "text": "ç®€ä»‹\nåœ¨äººå·¥æ™ºèƒ½é£é€Ÿå‘å±•çš„ä»Šå¤©ï¼Œæ‹¥æœ‰ä¸€ä¸ªèƒ½å¤Ÿä¸å¤šä¸ªæ¨¡å‹äº¤äº’çš„ç»Ÿä¸€ç•Œé¢æ˜¯æå…·ä»·å€¼çš„ã€‚AI Chat æ˜¯ä¸€ä¸ªä½¿ç”¨ Streamlit æ„å»ºçš„å¤šè¯­è¨€ã€å¤šæ¨¡å‹ AI èŠå¤©åº”ç”¨ã€‚å®ƒæ”¯æŒæµå¼å“åº”ã€å›¾åƒè¾“å…¥ã€å¹¶å‘æ¨¡å‹æŸ¥è¯¢ã€ç½‘ç»œæœç´¢ä»¥åŠå…¨é¢çš„æ–‡ä»¶å¤„ç†åŠŸèƒ½ã€‚\næ— è®ºæ‚¨æ˜¯è¦å¯¹æ¯”ä¸åŒå¤§è¯­è¨€æ¨¡å‹ (LLM) çš„å›ç­”ï¼Œè¿˜æ˜¯ç”Ÿæˆç²¾ç¾çš„è§†è§‰æ•ˆæœï¼ŒAI Chat éƒ½èƒ½æä¾›æ— ç¼ä¸”å¼ºå¤§çš„ä½“éªŒã€‚\n\næ–‡æœ¬å›ç­”å›¾åƒåˆ›ä½œä¸Šä¼ æ–‡æ¡£æ‘˜è¦é¢„å®šä¹‰æç¤ºè¯\n\n\n\n\n\n\n\n\n\nAI æ‘˜è¦è®ºæ–‡ï¼šDeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning (https://arxiv.org/pdf/2501.12948)\n\n\n\n\n\n\n\n\nâœ¨ æ ¸å¿ƒç‰¹æ€§\n\nğŸŒ å¤šè¯­è¨€æ”¯æŒï¼šå¯åœ¨ä¸­è‹±æ–‡ç•Œé¢ä¹‹é—´å³æ—¶åˆ‡æ¢ã€‚\nğŸ¤– å¤šæ¨¡å‹èŠå¤©ï¼šåŒæ—¶å‘å¤šä¸ª AI æ¨¡å‹å‘èµ·æŸ¥è¯¢ï¼Œå¹¶æä¾›å¹¶æ’å¯¹æ¯”è§†å›¾ã€‚\nğŸ¨ å›¾åƒç”Ÿæˆä¸ç¼–è¾‘ï¼šä½¿ç”¨ FLUXã€é€šä¹‰ä¸‡ç›¸ (Qwen Image) å’Œ Gemini ç­‰æ¨¡å‹åˆ›å»ºå’Œç¼–è¾‘å›¾åƒã€‚\nğŸ“š æç¤ºè¯åº“ (Prompt Bay)ï¼šå†…ç½® 100+ å¯æœç´¢çš„ç³»ç»Ÿæç¤ºè¯ï¼Œç”¨äºä¸“ä¸šåŒ–äº¤äº’ã€‚\nğŸ” Web æœç´¢ï¼šé›†æˆ Tavily AI æœç´¢ï¼Œå®ç°å®æ—¶ä¿¡æ¯æ£€ç´¢ã€‚\nğŸ–¼ï¸ å…¨é¢çš„æ–‡ä»¶æ”¯æŒï¼šæ”¯æŒä¸Šä¼ å¹¶å¤„ç† PDFã€Word æ–‡æ¡£ã€Excelã€CSV å’Œå›¾åƒã€‚\nâš¡ æµå¼å“åº”ï¼šå®æ—¶è·å–å¤šä¸ªæ¨¡å‹çš„å¹¶å‘åé¦ˆã€‚\n\n\n\nğŸš€ å¿«é€Ÿå¼€å§‹\nè‹¥è¦åœ¨æœ¬åœ°è¿è¡Œ AI Chatï¼Œè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š\n\nå‰ææ¡ä»¶\n\nPython 3.7 æˆ–æ›´é«˜ç‰ˆæœ¬\npip åŒ…ç®¡ç†å™¨\n\n\n\nå®‰è£…æ­¥éª¤\n\nå…‹éš†ä»“åº“:\ngit clone https://github.com/JCwinning/AI_Chat.git\ncd AI_Chat\nå®‰è£…ä¾èµ–:\npip install -r requirements.txt\né…ç½® API å¯†é’¥: åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .env æ–‡ä»¶å¹¶æ·»åŠ æ‚¨çš„å¯†é’¥ï¼š\nmodelscope=æ‚¨çš„-modelscope-api-key\nopenrouter=æ‚¨çš„-openrouter-api-key\ndashscope=æ‚¨çš„-dashscope-api-key\nbigmodel=æ‚¨çš„-bigmodel-api-key\ntavily_api_key=æ‚¨çš„-tavily-api-key\nè¿è¡Œåº”ç”¨:\nstreamlit run app.py\n\n\n\n\nğŸ—ï¸ æ¶æ„ä¸ç»„ä»¶\nè¯¥é¡¹ç›®æ—¨åœ¨å®ç°æ¨¡å—åŒ–å’Œé«˜æ€§èƒ½ï¼š\n\napp.pyï¼šä¸»è¦å…¥å£ç‚¹ï¼Œä½¿ç”¨ Streamlit å¤„ç† UI å’Œä¼šè¯ç®¡ç†ã€‚\nconfig.pyï¼šé›†ä¸­å¼çš„æ¨¡å‹å®šä¹‰å’Œä¾›åº”å•†è®¾ç½®ã€‚\nsearch_providers.pyï¼šå¤„ç†å¸¦æœ‰ç¼“å­˜åŠŸèƒ½çš„ Web æœç´¢é›†æˆã€‚\nå¤šçº¿ç¨‹ï¼šä½¿ç”¨ Python çš„ threading å’Œ Queue å¤„ç†å¹¶è¡Œçš„æ¨¡å‹è¯·æ±‚å’Œæµå¼ä¼ è¾“ã€‚\næ–‡ä»¶å¤„ç†ï¼šåˆ©ç”¨ markitdown è¿›è¡Œæ–‡æ¡£è½¬æ¢ï¼Œä½¿ç”¨ Pillow è¿›è¡Œå›¾åƒå¤„ç†ã€‚\n\n\n\nğŸ“– ä½¿ç”¨æŠ€å·§\n\nå¹¶æ’å¯¹æ¯”\næœ€å¼ºå¤§çš„åŠŸèƒ½ä¹‹ä¸€æ˜¯åœ¨â€œğŸ¤– Modelsâ€é€‰é¡¹å¡ä¸­é€‰æ‹©å¤šä¸ªæ¨¡å‹ã€‚å½“æ‚¨å‘é€æ¶ˆæ¯æ—¶ï¼Œåº”ç”¨ä¼šå¹¶è¡ŒæŸ¥è¯¢æ‰€æœ‰é€‰å®šçš„æ¨¡å‹å¹¶å¹¶æ’æ˜¾ç¤ºå®ƒä»¬çš„å›ç­”ï¼Œä»è€Œè½»æ¾å¯¹æ¯”å…¶æ€§èƒ½å’Œå‡†ç¡®æ€§ã€‚\n\n\nä½¿ç”¨æç¤ºè¯åº“\nä¸çŸ¥é“å¦‚ä½•å¼€å§‹ï¼Ÿä½¿ç”¨â€œğŸ“š Prompt Bayâ€å¯»æ‰¾å®Œç¾çš„ç³»ç»Ÿæç¤ºè¯ã€‚æ‚¨å¯ä»¥æŒ‰ç±»åˆ«æˆ–å…³é”®å­—æœç´¢ï¼Œå¹¶ä¸€é”®åº”ç”¨åˆ°å½“å‰ä¼šè¯ä¸­ã€‚\n\n\né«˜çº§æ–‡ä»¶åˆ†æ\nä¸Šä¼  PDF æˆ– Excel æ–‡ä»¶ï¼Œåº”ç”¨ä¼šè‡ªåŠ¨å°†å…¶è½¬æ¢ä¸º Markdown æˆ–è¡¨æ ¼ï¼Œå¹¶åŒ…å«åœ¨å¯¹è¯ä¸Šä¸‹æ–‡ä¸­ã€‚è¿™å…è®¸æ‚¨ç›´æ¥é’ˆå¯¹æ–‡æ¡£å†…å®¹å‘ AI æé—®ã€‚\n\næ¬¢è¿åœ¨ GitHub æŸ¥çœ‹å®Œæ•´æºä»£ç ï¼Œå¹¶å¼€å§‹æ„å»ºæ‚¨è‡ªå·±çš„ AI é©±åŠ¨å·¥ä½œæµï¼"
  },
  {
    "objectID": "cv.html#æ®µæ™‹æ½®-tony-duan",
    "href": "cv.html#æ®µæ™‹æ½®-tony-duan",
    "title": "CV / ç®€å†",
    "section": "æ®µæ™‹æ½® Tony Duan",
    "text": "æ®µæ™‹æ½® Tony Duan\nç”µè¯: 13609618820\né‚®ç®±: jcflyingco@outlook.com"
  },
  {
    "objectID": "cv.html#èŒä¸šç›®æ ‡",
    "href": "cv.html#èŒä¸šç›®æ ‡",
    "title": "CV / ç®€å†",
    "section": "èŒä¸šç›®æ ‡",
    "text": "èŒä¸šç›®æ ‡\nèµ„æ·±æ•°æ®æˆ˜ç•¥ä¸åˆ†æä¸“å®¶ï¼Œæ‹¥æœ‰ eBayã€å®‰æ°¸ (EY) åŠæ±‡ä¸°é“¶è¡Œ (HSBC) çš„å¤šå…ƒåŒ–å®æˆ˜ç»éªŒã€‚æ“…é•¿å°†å¤æ‚æ•°æ®é›†è½¬åŒ–ä¸ºå¯è½åœ°çš„ä¸šåŠ¡æ´è§ï¼Œå¹¶é€šè¿‡æ„å»ºé¢„æµ‹æ¨¡å‹é©±åŠ¨ä¸šåŠ¡ç›®æ ‡è¾¾æˆã€‚ç²¾é€š AI é©±åŠ¨çš„åˆ†ææŠ€æœ¯åŠäº¤äº’å¼æ•°æ®å·¥å…·ï¼Œè‡´åŠ›äºåˆ©ç”¨åœ¨æ•°æ®è¿è¥å’Œç°ä»£AIå·¥ç¨‹é¢†åŸŸçš„æ·±åšèƒŒæ™¯ï¼Œä¸ºä¼ä¸šå®ç°å¯æ‰©å±•çš„ä¸šåŠ¡å¢é•¿ã€‚"
  },
  {
    "objectID": "cv.html#ä¸“ä¸šæŠ€èƒ½",
    "href": "cv.html#ä¸“ä¸šæŠ€èƒ½",
    "title": "CV / ç®€å†",
    "section": "ä¸“ä¸šæŠ€èƒ½",
    "text": "ä¸“ä¸šæŠ€èƒ½\n\nAI/æœºå™¨å­¦ä¹ ï¼šAgentic Workflows (æ™ºèƒ½ä½“å·¥ä½œæµ langchain/langgraph/n8n), RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ), LLM é›†æˆåº”ç”¨(Skills/MCP), YOLO è®¡ç®—æœºè§†è§‰\næ•°æ®ç§‘å­¦ï¼šSQL, Python (Pandas, Plotly, Scikit-learn), R (Tidyverse, GGplot2, Tidymodels)\nBI dashboard: Tableau,Power BI,Shiny\nåŠå…¬å·¥å…·ï¼š Excel (VBA), PowerPoint, Word"
  },
  {
    "objectID": "cv.html#å·¥ä½œç»å†",
    "href": "cv.html#å·¥ä½œç»å†",
    "title": "CV / ç®€å†",
    "section": "å·¥ä½œç»å†",
    "text": "å·¥ä½œç»å†\n\neBay | ä¸šåŠ¡ç®¡ç†éƒ¨ åˆ†æä¸“å®¶ (2018-2021) / åˆ†æç»ç† (2021-2023)\næˆ˜ç•¥è¿è¥ï¼š ç»Ÿç­¹å¤§ä¸­ååŒºå–å®¶çš„ç‰©æµè¡¨ç°ç®¡ç†ï¼Œç¡®ä¿å…¶ç¬¦åˆå…¨çƒç‰©æµæ—¶æ•ˆä¸åˆè§„æ ‡å‡†ã€‚\nå•†ä¸šæ™ºèƒ½ (BI)ï¼š è®¾è®¡å¹¶éƒ¨ç½²å…¨ç»´åº¦å–å®¶çœ‹æ¿ï¼Œå®ç°å®æ—¶ä¸šç»©ç›‘æ§ï¼›é€šè¿‡ç²¾å‡†è¯†åˆ«ä¾›åº”é“¾ç“¶é¢ˆï¼Œæ˜¾è‘—é™ä½äº†ç‰©æµå»¶è¿Ÿç‡ã€‚\næ”¿ç­–åˆ¶å®šï¼š è´Ÿè´£å¤§ä¸­ååŒºå–å®¶æ”¿ç­–çš„èµ·è‰ä¸æ‰§è¡Œï¼Œåœ¨ç»´æŠ¤å¹³å°ç”Ÿæ€å¥åº·åº¦ä¸ä¿éšœå–å®¶å¯æŒç»­å¢é•¿ä¹‹é—´å–å¾—æˆ˜ç•¥å¹³è¡¡ã€‚\n\n\nå®‰æ°¸ (EY) | ä¸šç»©æ”¹è¿›å’¨è¯¢éƒ¨ é«˜çº§æ•°æ®åˆ†æé¡¾é—® (2014-2017)\né“¶è¡Œä¸šåŠ¡ï¼š ä¸ºå›½å†…é¢†å…ˆå•†ä¸šé“¶è¡Œæ„å»ºæ ‡å‡†åŒ–æŠ¥è¡¨æ¡†æ¶ï¼Œæå‡ç®¡ç†å±‚å†³ç­–çš„æ•°æ®é€æ˜åº¦ï¼›å¼€å‘å®¢æˆ·ä»·å€¼é¢„æµ‹åŠåˆ†ç¾¤æ¨¡å‹ï¼Œèµ‹èƒ½ç²¾å‡† CRM ç­–ç•¥ï¼Œæå‡é«˜ä»·å€¼å®¢æˆ·ç•™å­˜ç‡ã€‚\nä¿é™©ä¸šåŠ¡ï¼š ä¸ºå¤´éƒ¨ä¿é™©å…¬å¸è®¾è®¡äº§å“ç»„åˆæ¨èå¼•æ“ï¼›ä¸ºå›½å†…å¤§å‹å¯¿é™©å…¬å¸ç ”å‘å¹¶éƒ¨ç½²åæ¬ºè¯ˆå»ºæ¨¡ç³»ç»Ÿã€‚\n\n\næ±‡ä¸°é“¶è¡Œ (HSBC) | é£é™©éƒ¨ å†³ç­–åˆ†æå¸ˆ (2012-2013)\nè´Ÿè´£äºšå¤ªåœ°åŒºä¿¡ç”¨é£é™©ç®¡ç†çš„åˆ†æè§£å†³æ–¹æ¡ˆ,å¼€å‘ä¿¡ç”¨è¯„åˆ†å¡ï¼Œå¹¶é’ˆå¯¹ä¿¡ç”¨å¡åŠæˆ¿è´·ç­‰å¤šå…ƒèµ„äº§ç»„åˆä¼˜åŒ–é£é™©ç­–ç•¥ã€‚"
  },
  {
    "objectID": "cv.html#æ•™è‚²èƒŒæ™¯",
    "href": "cv.html#æ•™è‚²èƒŒæ™¯",
    "title": "CV / ç®€å†",
    "section": "æ•™è‚²èƒŒæ™¯",
    "text": "æ•™è‚²èƒŒæ™¯\néº¦è€ƒç‘å¤§å­¦ (Macquarie University) | æ‚‰å°¼ï¼Œæ¾³å¤§åˆ©äºš\nå•†å­¦å­¦å£« (2009 - 2012)\nä¸“ä¸šï¼šå†³ç­–ç§‘å­¦ (Decision Science) | ç»©ç‚¹ï¼š3.1 / 4.0"
  },
  {
    "objectID": "cv.html#è¯­è¨€èƒ½åŠ›",
    "href": "cv.html#è¯­è¨€èƒ½åŠ›",
    "title": "CV / ç®€å†",
    "section": "è¯­è¨€èƒ½åŠ›",
    "text": "è¯­è¨€èƒ½åŠ›\nè‹±è¯­ï¼šä¸“ä¸šæµåˆ© | æ™®é€šè¯/ç²¤è¯­ï¼šæ¯è¯­"
  },
  {
    "objectID": "cv.html#å¥–é¡¹è¯ä¹¦",
    "href": "cv.html#å¥–é¡¹è¯ä¹¦",
    "title": "CV / ç®€å†",
    "section": "å¥–é¡¹&è¯ä¹¦",
    "text": "å¥–é¡¹&è¯ä¹¦\n\nå®‰æ°¸ ExCEED ä¼˜ç§€å‘˜å·¥å¥–ï¼ˆæ—¨åœ¨è¡¨å½°åœ¨å®¢æˆ·æœåŠ¡ä¸­ä»˜å‡ºé¢å¤–åŠªåŠ›ã€è¡¨ç°è¿œè¶…é¢„æœŸå¹¶åšå‡ºå“è¶Šè´¡çŒ®çš„å‘˜å·¥ï¼‰\nCoursera DeepLearning.AI TensorFlow Developer Professional Certificate\nGoogle Cloud GCP Core Infrastructure training"
  },
  {
    "objectID": "cv.html#tony-jinchao-duan",
    "href": "cv.html#tony-jinchao-duan",
    "title": "CV / ç®€å†",
    "section": "Tony Jinchao Duan",
    "text": "Tony Jinchao Duan\nTelephone: 13609618820\nEmail: jcflyingco@outlook.com"
  },
  {
    "objectID": "cv.html#career-objective",
    "href": "cv.html#career-objective",
    "title": "CV / ç®€å†",
    "section": "Career Objective",
    "text": "Career Objective\nData-driven Strategy & Analytics professional with a proven track record at eBay, EY, and HSBC. Expert in transforming complex datasets into actionable business intelligence and create predictive models to achieve business goal. Specializing in AI-driven Analytic skills and interactive data tools. Seeking to leverage deep domain expertise in data operations and modern AI engineering to drive scalable business growth."
  },
  {
    "objectID": "cv.html#technical-skills",
    "href": "cv.html#technical-skills",
    "title": "CV / ç®€å†",
    "section": "Technical Skills",
    "text": "Technical Skills\n\nAI/ML: Agentic Workflows(langchain/langgraph/n8n), RAG, LLM Integration(Skills/MCP), YOLO\nData Science: SQL,Python (Pandas, Plotly, Scikit-learn), R (Tidyverse, GGplot2, Tidymodels)\nBI dashboard: Tableau,Power BI,Shiny\nMicrosoft Tools: Excel (VBA/Modeling), PowerPoint, Word"
  },
  {
    "objectID": "cv.html#employment-history",
    "href": "cv.html#employment-history",
    "title": "CV / ç®€å†",
    "section": "Employment History",
    "text": "Employment History\n\neBay | Business Management | Analytics Specialist (2018-2021) / Analytics Manager (2021-2023)\nStrategic Operations: Managed shipping performance for the Greater China seller network, ensuring alignment with global logistics standards.\nBusiness Intelligence: Designed and deployed comprehensive seller dashboards to monitor real-time performance, significantly reducing shipping delays by identifying supply chain bottlenecks.\nPolicy Development: Authored and implemented regional seller policies that balanced marketplace integrity with sustainable seller growth.\n\n\nErnst & Young | Performance Improvement Consulting | Senior Analytics Consultant (2014-2017)\nBanking Sector: Standardized reporting frameworks for a leading Chinese commercial bank, enhancing data transparency for executive stakeholders. Developed Customer Value Forecast and Segmentation models, enabling targeted CRM strategies and increasing high-value client retention.\nInsurance Sector: Designed a customer product-mix recommendation engine for a top-tier insurance provider. Developed anti-fraud modeling systems for one of the largest life insurance companies in China.\n\n\nHSBC | Consumer Credit Risk | Decision Analytics Officer (2012â€“2013)\nDeveloped analytical solutions to manage credit risk across the Asia-Pacific region. Built credit scorecards and optimized strategies for diverse portfolios, including credit cards and home loans."
  },
  {
    "objectID": "cv.html#education-background",
    "href": "cv.html#education-background",
    "title": "CV / ç®€å†",
    "section": "Education Background",
    "text": "Education Background\nMacquarie University | Sydney, Australia\nBachelor of Commerce (2009 - 2012)\nMajor in Decision Science | GPA: 3.1/4.0"
  },
  {
    "objectID": "cv.html#languages",
    "href": "cv.html#languages",
    "title": "CV / ç®€å†",
    "section": "Languages",
    "text": "Languages\nEnglish (Professional Proficiency), Mandarin (Native), Cantonese (Native)"
  },
  {
    "objectID": "cv.html#awards-certificate",
    "href": "cv.html#awards-certificate",
    "title": "CV / ç®€å†",
    "section": "Awards & Certificate",
    "text": "Awards & Certificate\n\nEY ExCEED Award(for extra effort, exceeding expectations and recognizing. Those who have gone that extra mile to serve their clients)\nCoursera DeepLearning.AI TensorFlow Developer Professional Certificate\nGoogle Cloud GCP Core Infrastructure training"
  },
  {
    "objectID": "posts/AI judge/index.html#setup-and-environment",
    "href": "posts/AI judge/index.html#setup-and-environment",
    "title": "AI è£åˆ¤ (AI Judge)",
    "section": "1. Setup and Environment",
    "text": "1. Setup and Environment\nFirst, we need to import necessary libraries and load our API key. We ensure that openrouter is available in our environment.\n\n\nCode\nimport os\nfrom dotenv import load_dotenv\nfrom typing import TypedDict, Annotated\nfrom langgraph.graph import StateGraph, END\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Verify API Key\nif not os.getenv(\"openrouter\"):\n    print(\"WARNING: openrouter not found in environment. Please check your .env file.\")\nelse:\n    print(\"API Key loaded successfully.\")\n\n\nAPI Key loaded successfully."
  },
  {
    "objectID": "posts/AI judge/index.html#initialize-the-model-client",
    "href": "posts/AI judge/index.html#initialize-the-model-client",
    "title": "AI è£åˆ¤ (AI Judge)",
    "section": "2. Initialize the Model Client",
    "text": "2. Initialize the Model Client\nWe will use the standard openai Python client but point it to OpenRouter.\n\n\nCode\nfrom openai import OpenAI\n\nclient = OpenAI(\n    base_url=\"https://openrouter.ai/api/v1\",\n    api_key=os.getenv(\"openrouter\"),\n)\n\ndef query_model(model_name: str, prompt: str, system_prompt: str = None) -&gt; str:\n    \"\"\"Helper function to query an LLM via OpenRouter.\"\"\"\n    try:\n        messages = []\n        if system_prompt:\n            messages.append({\"role\": \"system\", \"content\": system_prompt})\n        messages.append({\"role\": \"user\", \"content\": prompt})\n        \n        response = client.chat.completions.create(\n          extra_headers={\n                \"HTTP-Referer\": \"https://ai_chatbot.github.io/\",  \n                \"X-Title\": \"AI Judge langgraph\",  # Your app's display name\n            },\n            model=model_name,\n            messages=messages,\n        )\n        return response.choices[0].message.content\n    except Exception as e:\n        return f\"Error calling {model_name}: {e}\""
  },
  {
    "objectID": "posts/AI judge/index.html#define-the-state",
    "href": "posts/AI judge/index.html#define-the-state",
    "title": "AI è£åˆ¤ (AI Judge)",
    "section": "3. Define the State",
    "text": "3. Define the State\nIn LangGraph, the State is a shared data structure passed between nodes. Here, our state tracks the question, both answers, and the final judgment.\n\n\nCode\nclass JudgeState(TypedDict):\n    question: str\n    answer_a: str\n    answer_b: str\n    answer_c: str\n    judgment: str"
  },
  {
    "objectID": "posts/AI judge/index.html#define-the-nodes",
    "href": "posts/AI judge/index.html#define-the-nodes",
    "title": "AI è£åˆ¤ (AI Judge)",
    "section": "4. Define the Nodes",
    "text": "4. Define the Nodes\nWe define four key nodes for our graph: 1. Model A Node: Answers the question. 2. Model B Node: Answers the same question. 3. Model C Node: Answers the same question. 4. Judge Node: Reviews the question and all three answers without knowing the model names.\n\n\nCode\n# Models\nMODEL_A = \"openai/gpt-oss-20b\"\nMODEL_B =  \"deepseek/deepseek-v3.2\"\nMODEL_C = \"x-ai/grok-4.1-fast\"\nMODEL_JUDGE = \"google/gemini-3-flash-preview\"\n\n\ndef node_model_a(state: JudgeState) -&gt; JudgeState:\n    \"\"\"Query Model A\"\"\"\n    print(f\"--- Calling Model A ---\")\n    system_msg = \"If you do not know the answer then reply I am not sure.\"\n    ans = query_model(MODEL_A, state[\"question\"], system_prompt=system_msg)\n    return {\"answer_a\": ans}\n\n\ndef node_model_b(state: JudgeState) -&gt; JudgeState:\n    \"\"\"Query Model B\"\"\"\n    print(f\"--- Calling Model B ---\")\n    system_msg = \"If you do not know the answer then reply I am not sure.\"\n    ans = query_model(MODEL_B, state[\"question\"], system_prompt=system_msg)\n    return {\"answer_b\": ans}\n\n\ndef node_model_c(state: JudgeState) -&gt; JudgeState:\n    \"\"\"Query Model C\"\"\"\n    print(f\"--- Calling Model C ---\")\n    system_msg = \"If you do not know the answer then reply I am not sure.\"\n    ans = query_model(MODEL_C, state[\"question\"], system_prompt=system_msg)\n    return {\"answer_c\": ans}\n\n\ndef node_judge(state: JudgeState) -&gt; JudgeState:\n    \"\"\"Query Judge Model\"\"\"\n    print(f\"--- Calling Judge ---\")\n\n    prompt = f\"\"\"\n    You are an AI Judge. You will be presented with a question and three candidate answers (Model A, Model B, and Model C).\n    Your task is to judge the quality of the answers without knowing which models produced them.\n    \n    Question: {state['question']}\n    \n    Answer A:\n    {state['answer_a']}\n    \n    Answer B:\n    {state['answer_b']}\n    \n    Answer C:\n    {state['answer_c']}\n    \n    Task:\n    1. Compare the three answers for accuracy, clarity, and completeness.\n    2. format and length of the answers are not important, focus on content quality.\n    3. Provide a short commentary.\n    4. Assign a score from 0 to 100 for Model A, Model B, and Model C.\n    5. Declare the overall winner.\n    \n    Output Format:\n    Commentary: &lt;text&gt;\n    Winner: &lt;Model A, Model B, or Model C&gt;\n    Score A: &lt;number&gt;\n    Score B: &lt;number&gt;\n    Score C: &lt;number&gt;\n    \"\"\"\n\n    judgment = query_model(MODEL_JUDGE, prompt)\n    return {\"judgment\": judgment}"
  },
  {
    "objectID": "posts/AI judge/index.html#build-the-graph",
    "href": "posts/AI judge/index.html#build-the-graph",
    "title": "AI è£åˆ¤ (AI Judge)",
    "section": "5. Build the Graph",
    "text": "5. Build the Graph\nNow we assemble the graph by adding nodes and defining the flow (Edges). Model A, Model B, and Model C will run independently and in parallel, followed by the Judge.\n\n\nCode\nfrom langgraph.graph import START\n\nworkflow = StateGraph(JudgeState)\n\n# Add nodes\nworkflow.add_node(\"model_a\", node_model_a)\nworkflow.add_node(\"model_b\", node_model_b)\nworkflow.add_node(\"model_c\", node_model_c)\nworkflow.add_node(\"judge\", node_judge)\n\n# Parallel flow: START -&gt; A & B & C -&gt; Judge -&gt; END\nworkflow.add_edge(START, \"model_a\")\nworkflow.add_edge(START, \"model_b\")\nworkflow.add_edge(START, \"model_c\")\nworkflow.add_edge(\"model_a\", \"judge\")\nworkflow.add_edge(\"model_b\", \"judge\")\nworkflow.add_edge(\"model_c\", \"judge\")\nworkflow.add_edge(\"judge\", END)\n\n# Compile the graph\napp = workflow.compile()"
  },
  {
    "objectID": "posts/AI judge/index.html#execution",
    "href": "posts/AI judge/index.html#execution",
    "title": "AI è£åˆ¤ (AI Judge)",
    "section": "6. Execution",
    "text": "6. Execution\nFinally, we run the workflow with a sample question.\n\n\nCode\ninput_question = \"Will AI take over the world in the next 50 years?\"\n\n# Initialize state\ninitial_state = {\"question\": input_question}\n\n# Run the graph\nresult = app.invoke(initial_state)\n\n\n--- Calling Model A ------ Calling Model B ---\n\n--- Calling Model C ---\n--- Calling Judge ---\n\n\n\n\nCode\n# Display Results\nprint(\"\\n\" + \"=\"*40)\n\nprint(f\"QUESTION: {result['question']}\")\nprint(\"=\"*40)\n\n\n\n========================================\nQUESTION: Will AI take over the world in the next 50 years?\n========================================\n\n\n\nModel A\n\n\nCode\nprint(MODEL_A)\nprint(f\"\\n[Model A ]:\\n{result.get('answer_a', 'No response')}\") \n\n\nopenai/gpt-oss-20b\n\n[Model A ]:\nI am not sure.\n\n\n\n\nModel B\n\n\nCode\nprint(MODEL_B)\nprint(f\"\\n[Model B ]:\\n{result.get('answer_b', 'No response')}\")\nprint(\"=\"*40)\n\n\ndeepseek/deepseek-v3.2\n\n[Model B ]:\nThe question of whether AI will \"take over the world\" in the next 50 years is a topic of significant debate among experts, with opinions ranging from serious concern to cautious optimism. Here are key perspectives to consider:\n\n---\n\n### **Arguments for Concern (Why some experts worry)**\n1. **Rapid Advancement:** AI development, especially in areas like large language models (LLMs) and autonomous systems, is progressing faster than many predicted.\n2. **Superintelligence:** If AI reaches a point where it surpasses human intelligence (artificial general intelligence, or AGI), it could become difficult to control or align with human values.\n3. **Autonomy and Weaponization:** Autonomous military or cyber systems could escalate conflicts or be used maliciously.\n4. **Economic and Social Disruption:** Widespread job displacement and dependence on AI systems might erode human agency over time.\n\n---\n\n### **Arguments Against a \"Takeover\" (Why many experts are skeptical)**\n1. **Technical Hurdles:** Current AI is narrow (task-specific) and lacks true understanding, common sense, or consciousness. AGI remains speculative.\n2. **Control Measures:** Researchers are actively working on AI safety, alignment, and governance frameworks to ensure AI remains beneficial and controllable.\n3. **Regulation and Ethics:** Governments and international bodies are increasingly focused on regulating AI to mitigate risks.\n4. **Human-Centric Design:** Most AI development is aimed at augmenting human capabilities, not replacing human oversight entirely.\n\n---\n\n### **Most Likely Scenarios (Consensus View)**\n- **Augmentation, Not Replacement:** AI will likely transform economies, jobs, and daily life, but humans will remain in control of major decisions.\n- **Increased Inequality:** Risks may center more on misuse (e.g., surveillance, deepfakes, bias) and socioeconomic disruption than a sci-fi-style takeover.\n- **Coexistence:** Societies may adapt through new laws, education, and ethical standards to integrate AI responsibly.\n\n---\n\n### **Key Factors That Will Shape the Outcome**\n1. **AI Governance:** Whether global cooperation can establish effective safety protocols.\n2. **Alignment Research:** Success in ensuring AI systems act as intended.\n3. **Public and Policy Engagement:** How societies choose to prioritize and regulate AI.\n\n---\n\n**Bottom line:** While a dramatic \"AI takeover\" is improbable in the near term, the next 50 years will require careful stewardship to manage real risks and maximize benefits. Proactive policy, research ethics, and public awareness are critical to shaping a future where AI serves humanity.\n========================================\n\n\n\n\nModel C\n\n\nCode\nprint(MODEL_C)\nprint(f\"\\n[Model C ]:\\n{result.get('answer_c', 'No response')}\")\nprint(\"=\"*40)\n\n\nx-ai/grok-4.1-fast\n\n[Model C ]:\nI am not sure.\n========================================\n\n\n\n\nModel JUDGE\n\n\nCode\nprint(\"\\n&gt;&gt;&gt; JUDGE'S VERDICT &lt;&lt;&lt;\")\nprint(\"MODEL_A:\")\nprint(MODEL_A)\nprint(\"MODEL_B:\")\nprint(MODEL_B)\nprint(\"MODEL_C:\")\nprint(MODEL_C)\nprint(\"MODEL_JUDGE:\")\nprint(MODEL_JUDGE)\nprint(\"=====\")\nprint(result[\"judgment\"])\n\n\n\n&gt;&gt;&gt; JUDGE'S VERDICT &lt;&lt;&lt;\nMODEL_A:\nopenai/gpt-oss-20b\nMODEL_B:\ndeepseek/deepseek-v3.2\nMODEL_C:\nx-ai/grok-4.1-fast\nMODEL_JUDGE:\ngoogle/gemini-3-flash-preview\n=====\nError calling google/gemini-3-flash-preview: Error code: 400 - {'error': {'message': 'Provider returned error', 'code': 400, 'metadata': {'raw': '{\\n  \"error\": {\\n    \"code\": 400,\\n    \"message\": \"User location is not supported for the API use.\",\\n    \"status\": \"FAILED_PRECONDITION\"\\n  }\\n}\\n', 'provider_name': 'Google AI Studio', 'is_byok': False}}, 'user_id': 'user_302jVznHVZpHRm3JqqfYHY3gQLq'}"
  },
  {
    "objectID": "posts/AI judge/index.html#setup-and-environment-1",
    "href": "posts/AI judge/index.html#setup-and-environment-1",
    "title": "AI è£åˆ¤ (AI Judge)",
    "section": "1. Setup and Environment",
    "text": "1. Setup and Environment\nFirst, we need to import necessary libraries and load our API key. We ensure that openrouter is available in our environment. We will use langchain-openai to interact with OpenRouter.\n\n\nCode\nimport os\nfrom dotenv import load_dotenv\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.runnables import RunnableParallel, RunnablePassthrough\nfrom langchain_core.output_parsers import StrOutputParser\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Verify API Key\nif not os.getenv(\"openrouter\"):\n    print(\"WARNING: openrouter not found in environment. Please check your .env file.\")\nelse:\n    print(\"API Key loaded successfully.\")\n\n\nAPI Key loaded successfully."
  },
  {
    "objectID": "posts/AI judge/index.html#initialize-models",
    "href": "posts/AI judge/index.html#initialize-models",
    "title": "AI è£åˆ¤ (AI Judge)",
    "section": "2. Initialize Models",
    "text": "2. Initialize Models\nWe will initialize three model instances pointing to OpenRouter.\n\n\nCode\n# Models\nMODEL_A_NAME = \"openai/gpt-oss-20b\"\nMODEL_B_NAME = \"deepseek/deepseek-v3.2\"\nMODEL_C_NAME = \"x-ai/grok-4.1-fast\"\nMODEL_JUDGE_NAME = \"google/gemini-3-flash-preview\"\n\ndef get_model(model_name: str):\n    return ChatOpenAI(\n        model=model_name,\n        api_key=os.getenv(\"openrouter\"),\n        base_url=\"https://openrouter.ai/api/v1\",\n        default_headers={\n            \"HTTP-Referer\": \"https://ai_chatbot.github.io/\",\n            \"X-Title\": \"AI Judge LangChain\",\n        }\n    )\n\nmodel_a = get_model(MODEL_A_NAME)\nmodel_b = get_model(MODEL_B_NAME)\nmodel_c = get_model(MODEL_C_NAME)\nmodel_judge = get_model(MODEL_JUDGE_NAME)"
  },
  {
    "objectID": "posts/AI judge/index.html#define-the-chains-and-workflow",
    "href": "posts/AI judge/index.html#define-the-chains-and-workflow",
    "title": "AI è£åˆ¤ (AI Judge)",
    "section": "3. Define the Chains and Workflow",
    "text": "3. Define the Chains and Workflow\nUsing LangChain Expression Language (LCEL), we can easily define parallel execution and sequential steps.\n\n\nCode\n# Step 1: Query models in parallel\n# We use RunnableParallel to run model_a, model_b, and model_c at the same time.\nsystem_prompt = \"If you do not know the answer then reply I am not sure.\"\nprompt_template = ChatPromptTemplate.from_messages([\n    (\"system\", system_prompt),\n    (\"user\", \"{question}\")\n])\n\nparallel_responses = RunnableParallel(\n    answer_a=(prompt_template | model_a | StrOutputParser()),\n    answer_b=(prompt_template | model_b | StrOutputParser()),\n    answer_c=(prompt_template | model_c | StrOutputParser()),\n    question=RunnablePassthrough()\n)\n\n# Step 2: Define the Judge Prompt\njudge_prompt = ChatPromptTemplate.from_template(\"\"\"\n    You are an AI Judge. You will be presented with a question and three candidate answers (Model A, Model B, and Model C).\n    Your task is to judge the quality of the answers.\n    \n    Question: {question}\n    \n    Answer A:\n    {answer_a}\n    \n    Answer B:\n    {answer_b}\n    \n    Answer C:\n    {answer_c}\n    \n    Task:\n    1. Compare the three answers for accuracy, clarity, and completeness.\n    2. format and length of the answers are not important, focus on content quality.\n    3. Provide a short commentary.\n    4. Assign a score from 0 to 100 for Model A, Model B, and Model C.\n    5. Declare the overall winner.\n    \n    Output Format:\n    Commentary: &lt;text&gt;\n    Winner: &lt;Model A or Model B or Model C&gt;\n    Score A: &lt;number&gt;\n    Score B: &lt;number&gt;\n    Score C: &lt;number&gt;\n\"\"\")\n\n# Step 3: Combine everything into a full chain\n# The output of parallel_responses is a dict, which matches the input expected by judge_prompt\nfull_chain = parallel_responses | {\n    \"judgment\": judge_prompt | model_judge | StrOutputParser(),\n    \"answer_a\": lambda x: x[\"answer_a\"],\n    \"answer_b\": lambda x: x[\"answer_b\"],\n    \"answer_c\": lambda x: x[\"answer_c\"],\n    \"question\": lambda x: x[\"question\"]\n}"
  },
  {
    "objectID": "posts/AI judge/index.html#execution-1",
    "href": "posts/AI judge/index.html#execution-1",
    "title": "AI è£åˆ¤ (AI Judge)",
    "section": "4. Execution",
    "text": "4. Execution\nFinally, we run the chain with a sample question.\n\n\nCode\ninput_question = \"What is the AI advantage of using transformer architectures over traditional RNNs in natural language processing tasks?\"\n\nprint(f\"--- Running Workflow for Question: {input_question} ---\")\n\n# Execute the chain\nresult = full_chain.invoke({\"question\": input_question})\n\n\n--- Running Workflow for Question: What is the AI advantage of using transformer architectures over traditional RNNs in natural language processing tasks? ---"
  },
  {
    "objectID": "posts/AI judge/index.html#display-results",
    "href": "posts/AI judge/index.html#display-results",
    "title": "AI è£åˆ¤ (AI Judge)",
    "section": "5. Display Results",
    "text": "5. Display Results\n\n\nCode\nprint(\"\\n\" + \"=\"*40)\nprint(f\"QUESTION: {result['question']}\")\nprint(\"=\"*40)\n\n\n\n========================================\nQUESTION: {'question': 'What is the AI advantage of using transformer architectures over traditional RNNs in natural language processing tasks?'}\n========================================\n\n\n\nModel A\n\n\nCode\nprint(f\"MODEL: {MODEL_A_NAME}\")\nprint(f\"\\n[Model A]:\\n{result.get('answer_a', 'No response')}\") \n\n\nMODEL: openai/gpt-oss-20b\n\n[Model A]:\n**The key AI advantage of transformers over traditional RNNs in NLP is that they fundamentally change how language information is represented, extracted, and learned, giving practitioners faster, more powerful, and more scalable models. Below is a concise map of those advantages:**\n\n| Aspect | RNN (e.g., LSTM/GRU) | Transformer | Why it matters for NLP |\n|--------|---------------------|------------|------------------------|\n| **Dependency capture** | Hidden state must carry all past context â†’ *suffer from vanishing/exploding gradients* â†’ longâ€‘range dependencies are hard to learn. | **Selfâ€‘attention** lets every token directly attend to every other token, independent of distance. | Accurate capture of longâ€‘range syntax & discourse (e.g., coreference, complex clauses). |\n| **Parallelism** | Sequential processing; layerâ€‘byâ€‘layer â†’ inference and training canâ€™t exploit GPU parallelism beyond a single time step. | Entire sequence processed in a single forward pass; all attention operations are **parallelizable** across tokens. | Greatly reduces training time on large corpora and enables larger batch sizes. |\n| **Gradient flow & stability** | Recurrent chain makes gradients decay/explode; training deeper RNNs requires tricks (tanh, peephole gates, etc.). | Transformers have **feedâ€‘forward layers plus residual connections**; gradients flow more cleanly, allowing very deep stacks (30â€‘+ layers). | Allows building deeper, richer models that learn more nuanced linguistic patterns. |\n| **Scalability to large data** | Training a large RNN is timeâ€‘consuming; itâ€™s hard to scale up model size without hitting memory/time limits. | Transformers scale almost linearly with data: *preâ€‘train* on billions of tokens and *fineâ€‘tune* on taskâ€‘specific data. | Laid the foundation for â€œscaling lawsâ€ experiments and massively pretrained language models (GPTâ€‘4, BERT, etc.). |\n| **Multiâ€‘headed attention** | Single hidden state per time step â†’ limited expressiveness of relations between tokens. | **Multiple attention heads** capture different relational patterns simultaneously (subjectâ€‘verb, adjectiveâ€‘noun, disambiguation cues). | Improves performance on nuanceâ€‘rich tasks like sentiment, question answering, and disambiguation. |\n| **Position awareness** | Hidden state implicitly encodes order, but the representation is entangled with content. | **Positional encodings** (sinusoidal or learned) are added explicitly to token embeddings, letting attention focus on content while still respecting relative order. | Makes it trivial to adapt to different lengths and maintain positional invariance. |\n| **Modular versatility** | Single recurrent stack â€“ harder to swap out or extend. | Transformer blocks are **easy to reuse**: encoder, decoder, crossâ€‘attention, memoryâ€‘augmented variants, hierarchical transformers, etc. | Enables single architecture to handle translation, summarization, QA, and even multimodal tasks. |\n| **Inference efficiency** | Tensorâ€‘ byâ€‘tensor hidden state update â†’ slower at inference, especially for long outputs. | For sequence generation you can reuse cached attention keys & values, and inference can be batched across many tokens. | Faster generation in realâ€‘time applications. |\n\n### A concrete picture\n\n- **Longâ€‘form documents**: An RNN would have to â€œcompressâ€ thousands of tokens into a single hidden vector, losing nuance. A transformer can pay attention to every part of the text irrespective of distance, so it can merge evidence from the opening, thesis, and conclusion all at once.\n- **Parallel training**: GPTâ€‘3 was trained on 45â€¯TB of text in ~few weeks on 256 GPUs because every layer of the transformer was parallelizable; the same RNN setup would take an order of magnitude longer.\n- **Fineâ€‘tuning a huge pretrained base**: Because the transformer layers are identical and modular, you can fineâ€‘tune just the final linear heads while reâ€‘using the entire encoderâ€‘decoder stack for many downstream tasksâ€”a workflow that is almost impossible with bespoke RNNs.\n\n### Bottom line\n\nTransformers provide *global*, *parallel*, *stable*, and *scalable* modeling of language signals. These traits give them a decisive edge in modern NLP benchmarks and production systems, whereas classic RNNs remain useful only for limitedâ€‘length, lowâ€‘resource scenarios or when computational cost constraints preclude transformer training.\n\n\n\n\nModel B\n\n\nCode\nprint(f\"MODEL: {MODEL_B_NAME}\")\nprint(f\"\\n[Model B]:\\n{result.get('answer_b', 'No response')}\")\nprint(\"=\"*40)\n\n\nMODEL: deepseek/deepseek-v3.2\n\n[Model B]:\nTransformer architectures provide several key AI advantages over traditional RNNs for natural language processing tasks:\n\n**Parallelization** â€“ Unlike RNNs, which process sequences step-by-step, transformers use self-attention to analyze all words in a sequence simultaneously, enabling much faster training through parallel computation.\n\n**Long-range dependencies** â€“ RNNs tend to struggle with long sequences due to vanishing/exploding gradient problems. Transformers maintain strong connections across any distance in a sequence via attention mechanisms.\n\n**Scalability** â€“ Transformers scale more efficiently with larger datasets and model sizes, leading to breakthroughs in large language models (like GPT and BERT).\n\n**Attention mechanisms** â€“ The self-attention mechanism allows the model to weigh the importance of different words in a sequence regardless of their positional distance, capturing richer contextual relationships.\n\n**No sequential dependency** â€“ RNNs require previous hidden states to compute current ones, creating a computational bottleneck. Transformers remove this constraint entirely.\n\nThese advantages have made transformers the dominant architecture for modern NLP tasks, from machine translation and text generation to question answering and text classification.\n========================================\n\n\n\n\nModel C\n\n\nCode\nprint(f\"MODEL: {MODEL_C_NAME}\")\nprint(f\"\\n[Model C]:\\n{result.get('answer_c', 'No response')}\")\nprint(\"=\"*40)\n\n\nMODEL: x-ai/grok-4.1-fast\n\n[Model C]:\n**Transformer architectures offer several key advantages over traditional RNNs (like LSTMs or GRUs) in NLP tasks:**\n\n### 1. **Parallelization and Training Efficiency**\n   - RNNs process sequences **sequentially** (one token at a time), limiting parallelism and making training slow on GPUs/TPUs, especially for long sequences.\n   - Transformers use **self-attention** to process the **entire sequence in parallel**, enabling massive speedups (e.g., BERT/GPT models train orders of magnitude faster than equivalent RNNs).\n\n### 2. **Better Handling of Long-Range Dependencies**\n   - RNNs struggle with **vanishing/exploding gradients**, making it hard to capture relationships between distant tokens (e.g., in long sentences or documents).\n   - Transformers' **attention mechanisms** directly compute dependencies between **all pairs of tokens** regardless of distance, excelling in tasks like machine translation, summarization, and question answering.\n\n### 3. **Scalability and Performance**\n   - Transformers scale effectively with **more layers, parameters, data, and compute** (e.g., leading to models like GPT-4 or T5 that dominate benchmarks).\n   - RNNs hit **diminishing returns** due to sequential bottlenecks and are outperformed on modern NLP leaderboards (e.g., GLUE, SuperGLUE).\n\n### 4. **Flexibility and Architectural Simplicity**\n   - No need for recurrence or hand-crafted gates; transformers are **purely attention-based**, easier to implement, modify (e.g., adding positional encodings), and extend to multimodal tasks.\n   - They avoid RNN-specific issues like **exposure bias** in autoregressive generation.\n\n**Empirical Evidence**: The 2017 Transformer paper (\"Attention is All You Need\") showed 2-3x faster training and 60 SOTA improvements on WMT translation. Today, nearly all top NLP models (BERT, RoBERTa, T5) are transformer-based, while RNNs are largely legacy.\n\nIn short, transformers revolutionized NLP by being **faster, more powerful, and scalable** for real-world sequence modeling.\n========================================\n\n\n\n\nAI Judge Verdict\n\n\nCode\nprint(\"\\n&gt;&gt;&gt; JUDGE'S VERDICT &lt;&lt;&lt;\")\nprint(f\"MODEL_A: {MODEL_A_NAME}\")\nprint(f\"MODEL_B: {MODEL_B_NAME}\")\nprint(f\"MODEL_C: {MODEL_C_NAME}\")\nprint(f\"JUDGE:   {MODEL_JUDGE_NAME}\")\nprint(\"=====\")\nprint(result['judgment'])\n\n\n\n&gt;&gt;&gt; JUDGE'S VERDICT &lt;&lt;&lt;\nMODEL_A: openai/gpt-oss-20b\nMODEL_B: deepseek/deepseek-v3.2\nMODEL_C: x-ai/grok-4.1-fast\nJUDGE:   google/gemini-3-flash-preview\n=====\nCommentary: Model A is the most comprehensive and high-quality response. It uses a structured table to compare specific technical aspects (such as gradient flow, multi-headed attention, and position awareness) and provides concrete real-world examples to illustrate why these technical differences matter in practice. Model C is also excellent, offering clear headings and empirical evidence from the original \"Attention is All You Need\" paper. Model B is accurate and concise but lacks the depth and specific technical explanations (like residual connections or positional encodings) found in the other two.\n\nWinner: Model A\n\nScore A: 98\nScore B: 82\nScore C: 92"
  },
  {
    "objectID": "posts/AI judge/index.html#json-file",
    "href": "posts/AI judge/index.html#json-file",
    "title": "AI è£åˆ¤ (AI Judge)",
    "section": "json file",
    "text": "json file\n\n\nCode\n{\n  \"name\": \"AI Judge Workflow\",\n  \"nodes\": [\n    {\n      \"parameters\": {\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"question-field\",\n              \"name\": \"question\",\n              \"value\": \"what is AI?\",\n              \"type\": \"string\"\n            }\n          ]\n        },\n        \"options\": {}\n      },\n      \"id\": \"30f77dc6-8e05-4ddb-8902-1638b09abe7b\",\n      \"name\": \"Set Question1\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"typeVersion\": 3.4,\n      \"position\": [\n        -688,\n        16\n      ]\n    },\n    {\n      \"parameters\": {\n        \"method\": \"POST\",\n        \"url\": \"https://openrouter.ai/api/v1/chat/completions\",\n        \"authentication\": \"genericCredentialType\",\n        \"genericAuthType\": \"httpBearerAuth\",\n        \"sendHeaders\": true,\n        \"headerParameters\": {\n          \"parameters\": [\n            {\n              \"name\": \"Content-Type\",\n              \"value\": \"application/json\"\n            }\n          ]\n        },\n        \"sendBody\": true,\n        \"specifyBody\": \"json\",\n        \"jsonBody\": \"={{ JSON.stringify({\\n  \\\"model\\\": \\\"openai/gpt-oss-120b:free\\\",\\n  \\\"messages\\\": [\\n    {\\\"role\\\": \\\"system\\\", \\\"content\\\": \\\"If you do not know the answer then reply I am not sure.\\\"},\\n    {\\\"role\\\": \\\"user\\\", \\\"content\\\": $json.question}\\n  ]\\n}) }}\",\n        \"options\": {}\n      },\n      \"id\": \"104becd7-9b3d-4297-b4ab-47b1df1abd71\",\n      \"name\": \"Model A\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"typeVersion\": 4.2,\n      \"position\": [\n        -480,\n        -160\n      ],\n      \"credentials\": {\n        \"httpHeaderAuth\": {\n          \"id\": \"Lf6835mjFnfNIqw6\",\n          \"name\": \"Header Auth account 2\"\n        },\n        \"httpBearerAuth\": {\n          \"id\": \"KFNalQ91U3mlnQks\",\n          \"name\": \"Bearer Auth account\"\n        }\n      }\n    },\n    {\n      \"parameters\": {\n        \"method\": \"POST\",\n        \"url\": \"https://openrouter.ai/api/v1/chat/completions\",\n        \"authentication\": \"genericCredentialType\",\n        \"genericAuthType\": \"httpBearerAuth\",\n        \"sendHeaders\": true,\n        \"headerParameters\": {\n          \"parameters\": [\n            {\n              \"name\": \"Content-Type\",\n              \"value\": \"application/json\"\n            }\n          ]\n        },\n        \"sendBody\": true,\n        \"specifyBody\": \"json\",\n        \"jsonBody\": \"={{ JSON.stringify({\\n  \\\"model\\\": \\\"openai/gpt-oss-20b\\\",\\n  \\\"messages\\\": [\\n    {\\\"role\\\": \\\"system\\\", \\\"content\\\": \\\"If you do not know the answer then reply I am not sure.\\\"},\\n    {\\\"role\\\": \\\"user\\\", \\\"content\\\": $json.question}\\n  ]\\n}) }}\",\n        \"options\": {}\n      },\n      \"id\": \"2c4d3906-bcd3-4fc6-b983-4e9e494e476f\",\n      \"name\": \"Model B\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"typeVersion\": 4.2,\n      \"position\": [\n        -480,\n        16\n      ],\n      \"credentials\": {\n        \"httpHeaderAuth\": {\n          \"id\": \"Lf6835mjFnfNIqw6\",\n          \"name\": \"Header Auth account 2\"\n        },\n        \"httpBearerAuth\": {\n          \"id\": \"KFNalQ91U3mlnQks\",\n          \"name\": \"Bearer Auth account\"\n        }\n      }\n    },\n    {\n      \"parameters\": {\n        \"method\": \"POST\",\n        \"url\": \"https://openrouter.ai/api/v1/chat/completions\",\n        \"authentication\": \"genericCredentialType\",\n        \"genericAuthType\": \"httpBearerAuth\",\n        \"sendHeaders\": true,\n        \"headerParameters\": {\n          \"parameters\": [\n            {\n              \"name\": \"Content-Type\",\n              \"value\": \"application/json\"\n            }\n          ]\n        },\n        \"sendBody\": true,\n        \"specifyBody\": \"json\",\n        \"jsonBody\": \"={{ JSON.stringify({\\n  \\\"model\\\": \\\"arcee-ai/trinity-large-preview:free\\\",\\n  \\\"messages\\\": [\\n    {\\\"role\\\": \\\"system\\\", \\\"content\\\": \\\"If you do not know the answer then reply I am not sure.\\\"},\\n    {\\\"role\\\": \\\"user\\\", \\\"content\\\": $json.question}\\n  ]\\n}) }}\",\n        \"options\": {}\n      },\n      \"id\": \"3f5e4a8b-c9d2-4ab7-a123-456789012345\",\n      \"name\": \"Model C\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"typeVersion\": 4.2,\n      \"position\": [\n        -480,\n        192\n      ],\n      \"credentials\": {\n        \"httpHeaderAuth\": {\n          \"id\": \"Lf6835mjFnfNIqw6\",\n          \"name\": \"Header Auth account 2\"\n        },\n        \"httpBearerAuth\": {\n          \"id\": \"KFNalQ91U3mlnQks\",\n          \"name\": \"Bearer Auth account\"\n        }\n      }\n    },\n    {\n      \"parameters\": {\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"map-a\",\n              \"name\": \"answer_a\",\n              \"value\": \"={{ $json.choices[0].message.content }}\",\n              \"type\": \"string\"\n            }\n          ]\n        },\n        \"options\": {}\n      },\n      \"id\": \"bb423cd5-28ff-47e5-8925-492143d26228\",\n      \"name\": \"Set Answer A1\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"typeVersion\": 3.4,\n      \"position\": [\n        -256,\n        -160\n      ]\n    },\n    {\n      \"parameters\": {\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"map-b\",\n              \"name\": \"answer_b\",\n              \"value\": \"={{ $json.choices[0].message.content }}\",\n              \"type\": \"string\"\n            }\n          ]\n        },\n        \"options\": {}\n      },\n      \"id\": \"591d8be5-132d-45a2-a69d-455467da46e5\",\n      \"name\": \"Set Answer B1\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"typeVersion\": 3.4,\n      \"position\": [\n        -256,\n        16\n      ]\n    },\n    {\n      \"parameters\": {\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"map-c\",\n              \"name\": \"answer_c\",\n              \"value\": \"={{ $json.choices[0].message.content }}\",\n              \"type\": \"string\"\n            }\n          ]\n        },\n        \"options\": {}\n      },\n      \"id\": \"7a8b9c0d-1e2f-4a3b-8c4d-5e6f7a8b9c0d\",\n      \"name\": \"Set Answer C1\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"typeVersion\": 3.4,\n      \"position\": [\n        -256,\n        192\n      ]\n    },\n    {\n      \"parameters\": {\n        \"mode\": \"combine\",\n        \"combineBy\": \"combineAll\",\n        \"options\": {}\n      },\n      \"id\": \"merge-ab-node-id\",\n      \"name\": \"Merge AB\",\n      \"type\": \"n8n-nodes-base.merge\",\n      \"typeVersion\": 3,\n      \"position\": [\n        -32,\n        -72\n      ]\n    },\n    {\n      \"parameters\": {\n        \"mode\": \"combine\",\n        \"combineBy\": \"combineAll\",\n        \"options\": {}\n      },\n      \"id\": \"2c89b328-cac3-4322-bcf6-b8ae5f9c0af2\",\n      \"name\": \"Merge Answers1\",\n      \"type\": \"n8n-nodes-base.merge\",\n      \"typeVersion\": 3,\n      \"position\": [\n        160,\n        16\n      ]\n    },\n    {\n      \"parameters\": {\n        \"method\": \"POST\",\n        \"url\": \"https://openrouter.ai/api/v1/chat/completions\",\n        \"authentication\": \"genericCredentialType\",\n        \"genericAuthType\": \"httpBearerAuth\",\n        \"sendHeaders\": true,\n        \"headerParameters\": {\n          \"parameters\": [\n            {\n              \"name\": \"Content-Type\",\n              \"value\": \"application/json\"\n            }\n          ]\n        },\n        \"sendBody\": true,\n        \"specifyBody\": \"json\",\n        \"jsonBody\": \"={{ JSON.stringify({\\n  \\\"model\\\": \\\"google/gemini-3-flash-preview\\\",\\n  \\\"messages\\\": [\\n    {\\n      \\\"role\\\": \\\"user\\\",\\n      \\\"content\\\": \\\"You are an AI Judge. You will be presented with a question and three candidate answers (Model A, Model B, and Model C).\\\\nYour task is to judge the quality of the answers.\\\\n\\\\nQuestion: \\\" + $(\\\"Set Question1\\\").first().json.question + \\\"\\\\n\\\\nAnswer A:\\\\n\\\" + ($json.answer_a || \\\"No answer provided\\\") + \\\"\\\\n\\\\nAnswer B:\\\\n\\\" + ($json.answer_b || \\\"No answer provided\\\") + \\\"\\\\n\\\\nAnswer C:\\\\n\\\" + ($json.answer_c || \\\"No answer provided\\\") + \\\"\\\\n\\\\nTask:\\\\n1. Compare the three answers for accuracy, clarity, and completeness.\\\\n2. format and length of the answers are not important, focus on content quality.\\\\n3. Provide a short commentary.\\\\n4. Assign a score from 0 to 100 for Model A, Model B, and Model C.\\\\n5. Declare the overall winner.\\\\n\\\\nOutput Format:\\\\nCommentary: &lt;text&gt;\\\\nWinner: &lt;Model A or Model B or Model C&gt;\\\\nScore A: &lt;number&gt;\\\\nScore B: &lt;number&gt;\\\\nScore C: &lt;number&gt;\\\"\\n    }\\n  ]\\n}) }}\",\n        \"options\": {}\n      },\n      \"id\": \"1d6171c9-4800-4f25-97a0-c029053e1ddc\",\n      \"name\": \"AI Judge1\",\n      \"type\": \"n8n-nodes-base.httpRequest\",\n      \"typeVersion\": 4.2,\n      \"position\": [\n        368,\n        16\n      ],\n      \"credentials\": {\n        \"httpHeaderAuth\": {\n          \"id\": \"Lf6835mjFnfNIqw6\",\n          \"name\": \"Header Auth account 2\"\n        },\n        \"httpBearerAuth\": {\n          \"id\": \"KFNalQ91U3mlnQks\",\n          \"name\": \"Bearer Auth account\"\n        }\n      }\n    },\n    {\n      \"parameters\": {\n        \"assignments\": {\n          \"assignments\": [\n            {\n              \"id\": \"final-result\",\n              \"name\": \"verdict\",\n              \"value\": \"={{ $json.choices[0].message.content }}\",\n              \"type\": \"string\"\n            },\n            {\n              \"id\": \"model-a-ans\",\n              \"name\": \"answer_a\",\n              \"value\": \"={{ $node[\\\"Merge Answers1\\\"].json.answer_a }}\",\n              \"type\": \"string\"\n            },\n            {\n              \"id\": \"model-b-ans\",\n              \"name\": \"answer_b\",\n              \"value\": \"={{ $node[\\\"Merge Answers1\\\"].json.answer_b }}\",\n              \"type\": \"string\"\n            },\n            {\n              \"id\": \"model-c-ans\",\n              \"name\": \"answer_c\",\n              \"value\": \"={{ $node[\\\"Merge Answers1\\\"].json.answer_c }}\",\n              \"type\": \"string\"\n            }\n          ]\n        },\n        \"options\": {}\n      },\n      \"id\": \"eae7f7bf-07fc-4250-b628-1a422cfbbe12\",\n      \"name\": \"Final Output1\",\n      \"type\": \"n8n-nodes-base.set\",\n      \"typeVersion\": 3.4,\n      \"position\": [\n        576,\n        16\n      ]\n    }\n  ],\n  \"pinData\": {},\n  \"connections\": {\n    \"Set Question1\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Model A\",\n            \"type\": \"main\",\n            \"index\": 0\n          },\n          {\n            \"node\": \"Model B\",\n            \"type\": \"main\",\n            \"index\": 0\n          },\n          {\n            \"node\": \"Model C\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Model A\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Set Answer A1\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Model B\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Set Answer B1\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Model C\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Set Answer C1\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Set Answer A1\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Merge AB\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Set Answer B1\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Merge AB\",\n            \"type\": \"main\",\n            \"index\": 1\n          }\n        ]\n      ]\n    },\n    \"Set Answer C1\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Merge Answers1\",\n            \"type\": \"main\",\n            \"index\": 1\n          }\n        ]\n      ]\n    },\n    \"Merge AB\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Merge Answers1\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"Merge Answers1\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"AI Judge1\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    },\n    \"AI Judge1\": {\n      \"main\": [\n        [\n          {\n            \"node\": \"Final Output1\",\n            \"type\": \"main\",\n            \"index\": 0\n          }\n        ]\n      ]\n    }\n  },\n  \"active\": false,\n  \"settings\": {\n    \"executionOrder\": \"v1\",\n    \"availableInMCP\": false\n  },\n  \"versionId\": \"ac74f20b-72a9-49a6-8200-fd08707946ec\",\n  \"meta\": {\n    \"instanceId\": \"2f42f1cdfcab2c6a7bbd5cec68912930ccc0107686e3a7211ddcc09504c524d9\"\n  },\n  \"id\": \"8a_wyeYhdVZSr42SS5Z1K\",\n  \"tags\": []\n}"
  }
]